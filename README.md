# Enhancing the Results generated from LLMs using RAG

## Problem Statement
This project evaluates the performance of naive architecture with advanced RAG architectures like Contextual Compressor, Multi-Query Retriever and Sentence Window Retriever. The LLM model (llama 2) is also fine-tuned 
and the results are checked against baseline LLM used.

## Table of Contents
* [General Info](#general-information)
* [Technologies Used](#technologies-used)
* [Acknowledgements](#acknowledgements)

<!-- You can include any other section that is pertinent to your problem -->

## Dataset Information
The COVID dataset along with the embeddings stored in Chroma can be found out in the given link. 
(https://huggingface.co/datasets/rudranilgupta/COVID_Dataset)


## Technologies Used
- langchain
- llama-index
- huggingface
- openai

<!-- As the libraries versions keep on changing, it is recommended to mention the version of library used in this project -->

## Acknowledgements

- This project is done as part of Masters from LJMU


## Contact
Created by [@rudranils] - feel free to contact me!


<!-- Optional -->
<!-- ## License -->
<!-- This project is open source and available under the [... License](). -->

<!-- You don't have to include all sections - just the one's relevant to your project -->
