{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import PagedPDFSplitter\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "import warnings\n",
    "from langchain.chains import ConversationalRetrievalChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: 11303.txt\n",
      "Loading file: 3644.txt\n",
      "Loading file: 5235.txt\n",
      "Loading file: 1053.txt\n",
      "Loading file: 8711.txt\n",
      "Loading file: 7422.txt\n",
      "Loading file: 8077.txt\n",
      "Loading file: 7344.txt\n",
      "Loading file: 1735.txt\n",
      "Loading file: 9369.txt\n",
      "Loading file: 5553.txt\n",
      "Loading file: 4895.txt\n",
      "Loading file: 11465.txt\n",
      "Loading file: 3122.txt\n",
      "Loading file: 5547.txt\n",
      "Loading file: 4881.txt\n",
      "Loading file: 2228.txt\n",
      "Loading file: 11471.txt\n",
      "Loading file: 3136.txt\n",
      "Loading file: 4659.txt\n",
      "Loading file: 8063.txt\n",
      "Loading file: 7350.txt\n",
      "Loading file: 1721.txt\n",
      "Loading file: 6728.txt\n",
      "Loading file: 1047.txt\n",
      "Loading file: 8705.txt\n",
      "Loading file: 7436.txt\n",
      "Loading file: 11317.txt\n",
      "Loading file: 3650.txt\n",
      "Loading file: 10009.txt\n",
      "Loading file: 5221.txt\n",
      "Loading file: 3888.txt\n",
      "Loading file: 6700.txt\n",
      "Loading file: 9433.txt\n",
      "Loading file: 4117.txt\n",
      "Loading file: 3678.txt\n",
      "Loading file: 2566.txt\n",
      "Loading file: 10021.txt\n",
      "Loading file: 5209.txt\n",
      "Loading file: 2200.txt\n",
      "Loading file: 10747.txt\n",
      "Loading file: 11459.txt\n",
      "Loading file: 4671.txt\n",
      "Loading file: 7378.txt\n",
      "Loading file: 1709.txt\n",
      "Loading file: 6066.txt\n",
      "Loading file: 9355.txt\n",
      "Loading file: 289.txt\n",
      "Loading file: 6072.txt\n",
      "Loading file: 9341.txt\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# Assuming \"Covid Dataset\" is a directory in the current working directory\n",
    "directory = 'Covid Dataset'\n",
    "\n",
    "def load_text_files(folder_path: str) -> List[str]:\n",
    "    \"\"\" Load texts from a list of text files in the given folder \"\"\"\n",
    "    texts = \"\"\n",
    "\n",
    "    # List all files in the given directory\n",
    "    files = [file for file in os.listdir(folder_path) if file.endswith('.txt')][:50]\n",
    "\n",
    "    #print(len(files[:80]))\n",
    "    pages = []\n",
    "\n",
    "    for filename in files:\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(f\"Loading file: {filename}\")\n",
    "        # Create a TextLoader instance for the file\n",
    "        loader = TextLoader(file_path)\n",
    "        # Load the content of the file\n",
    "        content = loader.load()\n",
    "        #texts = texts+content[0].page_content\n",
    "        # print(\"====================\")\n",
    "        # print(content[0].page_content)\n",
    "        # print(\"======================\")\n",
    "        pages.extend(content)\n",
    "\n",
    "    return pages\n",
    "\n",
    "# Load all text files\n",
    "pages= load_text_files(directory)\n",
    "\n",
    "# Now `texts` variable contains the content of all `.txt` files from \"Covid Dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of pages 50 No of splits 1083\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_into_chunks(pages, chunk_size=1500, chunk_overlap=150):\n",
    "    \"\"\"\n",
    "    Split the documents into chunks.\n",
    "\n",
    "    Args:\n",
    "        pages (List[str]): List of pages to be split.\n",
    "        chunk_size (int): Size of each chunk.\n",
    "        chunk_overlap (int): Overlap between chunks.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of chunks.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "    print('No of pages', len(pages), 'No of splits', len(splits))\n",
    "    return splits\n",
    "\n",
    "# Usage\n",
    "splits = split_into_chunks(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'\n",
    "!rm -rf ./docs/chroma  # remove old database files if any\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupeshyadav/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory='docs/chroma/',embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupeshyadav/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4\",temperature=0)\n",
    "\n",
    "# multiquery retriever\n",
    "multi_query_retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(search_type = \"mmr\"), llm=llm\n",
    ")\n",
    "\n",
    "# # self query retriever\n",
    "# self_query_retriever = SelfQueryRetriever.from_llm(\n",
    "#     llm,\n",
    "#     vectordb,\n",
    "#     document_content_description=None,\n",
    "#     metadata_field_info=None,\n",
    "#     verbose=True,\n",
    "#     document_contents=None\n",
    "# )\n",
    "\n",
    "# compression retriever\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor = compressor,\n",
    "    base_retriever = vectordb.as_retriever(search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "conversational_retriever_chain = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversational chain for multiquery retriever\n",
    "qa_multi_query = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=multi_query_retriever_from_llm, verbose=True, return_source_documents=True)\n",
    "\n",
    "# conversational chain for compression retriever\n",
    "qa_compress_query = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=compression_retriever, verbose=True, return_source_documents=True)\n",
    "\n",
    "#conversational chain for self query retriever\n",
    "#qa_self_query = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, chain_type='stuff', retriever=self_query_retriever, verbose=True, return_source_documents=True)\n",
    "\n",
    "# conversational chain for vectordb retriever\n",
    "qa_vectordb_query = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=vectordb.as_retriever(), verbose=True, return_source_documents=True)\n",
    "\n",
    "# conversational chain for vectordb retriever with mmr\n",
    "qa_vectordb_mmr_query = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=vectordb.as_retriever(search_type = \"mmr\"), verbose=True, return_source_documents=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The coronavirus disease 2019 (COVID-19) is a high-impact widespread pandemic, with an imperfectly understood mode of transmission, poorly elucidated course, and a case fatality that has been ∼2% in South Africa (SA) and an estimated fatality rate of 5-20% worldwide, with country-specific rates varying from 0.5 to 3.6% (1) (2) (3) . Frontline health workers and policy makers have been left perplexed by this disease with regard to its evolution over time and the treatment approaches. We, irrespective of age, gender, or background, are all affected by this so-called invisible enemy. The COVID-19 pandemic, in addition to the mortality and physical morbidity, poses threats to the mental health of the entire population. The disease was first identified in a wholesale market in Wuhan, China, in December 2019 and runs a particularly aggressive course in those with underlying comorbidities such as obesity, diabetes, hypertension, cardiac disease, renal disease, and cancer (4, 5) . To this day, several millions of people worldwide have been infected, while a few millions have succumbed to this virus. COVID-19, compared to other epidemics such as HIV, severe acute respiratory syndrome (SARS), Middle East respiratory syndrome (MERS), Ebola, and H1N1, has run a more severe course because of a rapid spread that resulted in acute morbidity and mortality.With the current reports of new mutations that may affect vaccine efficacy in several countries (6) and predictions of possible surges or', metadata={'source': 'Covid Dataset/5221.txt'}),\n",
       " Document(page_content='The coronavirus disease 2019 (COVID-19) is a high-impact widespread pandemic, with an imperfectly understood mode of transmission, poorly elucidated course, and a case fatality that has been ∼2% in South Africa (SA) and an estimated fatality rate of 5-20% worldwide, with country-specific rates varying from 0.5 to 3.6% (1) (2) (3) . The disease was first identified in a wholesale market in Wuhan, China, in December 2019 and runs a particularly aggressive course in those with underlying comorbidities such as obesity, diabetes, hypertension, cardiac disease, renal disease, and cancer (4, 5) . To this day, several millions of people worldwide have been infected, while a few millions have succumbed to this virus. COVID-19, compared to other epidemics such as HIV, severe acute respiratory syndrome (SARS), Middle East respiratory syndrome (MERS), Ebola, and H1N1, has run a more severe course because of a rapid spread that resulted in acute morbidity and mortality.', metadata={'source': 'Covid Dataset/5221.txt'}),\n",
       " Document(page_content=\"Questions about concerns and precautionary measures related to COVID-19, validated in a previous study in a sample of the general population in China [19] were adopted. Questionnaires about concerns and precautionary measures for COVID-19 were provided by papers.Concerns about COVID-19 included four questions: (1) the likelihood of contracting COVID-19 during the current outbreak, (2) the level of confidence in own doctor's ability to diagnose or recognize COVID-19, (3) the likelihood of surviving if infected with COVID-19, and (4) concerns about other family members getting COVID-19 infections [19] .Precautionary measures taken against COVID-19 included: (1) covering mouth when coughing and sneezing; (2) avoiding sharing utensils(e.g., chopsticks) during meals; (3) washing hands immediately after coughing, rubbing the nose, or sneezing; (4) wearing a mask regardless of the presence or absence of symptoms; (5) the average number of hours staying at home per day to avoid COVID-19; and (6) feeling that too much unnecessary worry has been made about the COVID-19 outbreak [19] .Independent sample t-test was used to compare demographic and psychological characteristics between HD and PD groups. Chi-squared test or Fisher's exact test was used to compare categorical data. Correlation analyses were performed to examine the relationship between concerns and precautionary measures taken for COVID-19 and the psychological impact of the outbreak. We additionally conducted linear\", metadata={'source': 'Covid Dataset/1709.txt'}),\n",
       " Document(page_content='Technology Enabled Progress of Digital India-COVID-19 and Beyond!!!!', metadata={'source': 'Covid Dataset/10747.txt'}),\n",
       " Document(page_content='much as possible. Limiting or eliminating family attendance, while stressful, may be necessary in limited chemotherapy suite spaces. In such cases, portable technology such as smart phones or iPads could be loaned during the treatment session for patient and family support and subsequently disinfected between patient usage. Finally, more intensive surveillance during and in the recovery period should be considered when patients with cancer are infected with COVID-19, especially older patients and those with multiple co-morbidities [12] .People affected by cancer with family members or those in close contact who are infected, or suspected with COVID-19, should isolate from these contacts. Patients in such circumstances should be advised to inform their cancer care centre of any quarantine requirements. It is important that current health department recommendations regarding isolation and quarantine are followed. All cancer centres should display the symptoms of COVID-19 disease, criteria for when medical advice should be sought, and state the appropriate mode of presentation. For example, services may use a telephone triage, dedicated COVID-19 community assessment clinics [43] while some countries have built new COVID-19 hospitals within a very short timeframe with isolation and testing facilities.When facing a large-scale public health event, such as COVID-19, the physical and psychological strain on healthcare professionals cannot be underestimated [44] . It has been', metadata={'source': 'Covid Dataset/9369.txt'}),\n",
       " Document(page_content='Cancer and COVID-19: analysis of patient outcomes', metadata={'source': 'Covid Dataset/3650.txt'}),\n",
       " Document(page_content='Coronavirus disease 2019 , caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2), was first identified as an outbreak of respiratory illness in Wuhan City, China, in 2019. 1 Then, in March 2020, the World Health Organization (WHO) declared COVID-19 a global pandemic. 2 Since then, SARS-CoV-2 has caused worldwide fear because the infection spread quickly between countries and the clinical course ranged from mild to severe inflammatory disease resulting in multi-organ failure and death. 3, 4 Due to that, efforts for repurposing known drugs were the quickest way to help combat the disease. After screening FDA-approved chemical library, a group from France demonstrated that Azithromycin (AZM) exhibited the highest in vitro anti-SARS-CoV-2 activity. 5 AZM is a second-generation, broad-spectrum, synthetic macrolide antibiotic that inhibits protein synthesis. 6 However, it has been shown that AZM has anti-SARS-CoV-2 activities, 5, 7, 8 as well as anti-inflammatory properties, mainly by inhibiting dysregulated production of proinflammatory cytokines. 8, 9 Furthermore, AZM has been used for treating several previous SARS and Middle East Respiratory syndrome diseases. For example, AZM was associated with improved survival rate and time to discontinue mechanical ventilation in SARS. 10, 11 Although there was no clinical evidence, AZM was listed in many countries as part of the COVID-19 treatment protocol. 12 This led to the public misinformation gained from social', metadata={'source': 'Covid Dataset/1053.txt'}),\n",
       " Document(page_content='COVIDSum: A linguistically enriched SciBERT-based summarization model for COVID-19 scientific papers', metadata={'source': 'Covid Dataset/10009.txt'}),\n",
       " Document(page_content='reflecting the normal initiation of this signaling pathway in response to viral infections (33) (34) (35) (36) . However, in severe infections with SARS-CoV-2, the type-I IFN signaling is impaired, culminating in an altered development of adaptive immunity (15, (37) (38) (39) .The similar clinical symptoms and the range of disease severity of different respiratory viral infections tend to blur the accuracy of the initial diagnosis (40, 41) . Capturing a clear picture of the immune response triggered in each patient, early enough in infection remains challenging. It impairs the prevention of the severe form of the disease and, consequently, the potential onset of CRS. Defining the overlap and/or specificity in the patient immune cytokine signaling across CRS-causing viruses would help clinicians to develop a more tailored treatment strategy for future cases. Recent reviews have attempted to compare diseases caused by influenza A and β-coronaviruses (42) (43) (44) (45) . To provide mechanistic insight into the role of pro-and antiinflammatory cytokines in the development of severe diseases caused by SARS-CoV, SARS-CoV-2, MERS-CoV, and influenza viruses, understanding the differences in cytokine responses between the different viruses is vital.To identify the similarities and differences in the cytokine response, we collected and analyzed the patterns of cytokine changes caused by these CRS-causing respiratory viruses. By comparing available patient data from the literature, we', metadata={'source': 'Covid Dataset/1735.txt'}),\n",
       " Document(page_content='Radiological Imaging of Viral Pneumonia Cases Identified Before the COVİD-19 Pandemic Period and COVİD-19 Pneumonia Cases Comparison of Characteristics', metadata={'source': 'Covid Dataset/10021.txt'}),\n",
       " Document(page_content='Figure 3 , are useful in identifying distribution and determinants of health problems and suggestion of potential mitigation strategies (Centers for Disease Control, [24] . Efforts to solve health problems generally follow a four-step scientific approach involving data collection, assessment, hypothesis testing, and action. In the public health approach, data are collected, and an initial assessment (or hypothesis) is conducted. The hypothesis is tested, and resulting information is used to devise interventions. As in all sciences, epidemiology applies key terms -noted in Table 2 [24] .Of COVID-19, initially identified as a \"novel coronavirus\", Medical historian Howard Markel, known for his studies of the 1918 flu epidemic says: \"The key word about this coronavirus is \\'novel\\' -we don\\'t have any experience with COVID-19…*and+ we won\\'t know it\\'s over until long after it\\'s over\" [25, p 3] . Gaps remain in our understanding of its molecular structure, the infectious nature of this particular coronavirus, identifying characteristics of COVID-19 diagnoses, modes and rapidity of transmission, definition of contacts, and the public health management based on observations of similar coronaviruses.New and important data describing the biology, epidemiology, and clinical spectrum of COVID-19 appears almost daily: del Rio and Malani [26] note more than 400 articles listed in PubMed since the outbreak was first reported in late 2019 -challenging even the most attentive readers to stay', metadata={'source': 'Covid Dataset/9369.txt'}),\n",
       " Document(page_content=\"Since late December 2019, a novel coronavirus has resulted in an ongoing pandemic of viral pneumonia, which started in Wuhan, China [1, 2] . As of 13 th April 2020, COVID-19 has affected 213 countries worldwide [3] . In general, COVID-19 is an acute illness but it can be deadly, with an average case fatality of 2% [4] . COVID-19 causes severe respiratory illness associated with an Intensive Care Unit (ICU) admission, mechanical ventilation and high mortality [5] . The presenting symptoms of COVID-19 include: fever, chills, cough, fatigue and shortness of breath [1, 4, 5] . There is recent anecdotal evidence that anosmia with resultant dysgeusia are frequently reported symptoms with COVID-19.In this global critical care crisis and unparalleled health emergency, nurses are the largest healthcare professional group providing frontline care. Nurses' pivotal role in the care and management of the novel COVID-19 comes in the year landmarked as the International Year of the Nurse [6] . This global crisis is uncharted territory and the first of its kind for most nurses' living memory bringing along new challenges already recognised by international nursing boards [7] [8] [9] [10] . At the time of writing this critical reflection, global incidence passes 1, 699 595 with more than 106, 138 fatalities see Figure 1 .Early COVID-19 outcome data has suggested a fatality rate of 5.6% among those affected by cancer [11] . A further study identified that people affected by cancer had a 3.5\", metadata={'source': 'Covid Dataset/9369.txt'}),\n",
       " Document(page_content='Oncology Nursing During a Pandemic: Critical Re-flections in the Context of COVID-19', metadata={'source': 'Covid Dataset/9369.txt'}),\n",
       " Document(page_content='mortality.With the current reports of new mutations that may affect vaccine efficacy in several countries (6) and predictions of possible surges or waves in certain clusters, it is clear that this virus is likely to stay with us for some time. Therefore, non-pharmacological measures remain the most reliable longterm strategies to control the pandemic (7) . In order to reduce the rate of transmission, the strictest measures of public health prevention and infection control are being applied. These measures include strict hygiene routines, self-isolation, quarantine, movement restriction, and social distancing, which were introduced on various communities by most governments with little consideration to the mental, social, physical, and economic preparedness of individuals and families (8) . Several countries, including the UK and USA, have established procedures for psychological crisis interventions to deal with public health emergencies (9) . Similarly, our country needs to develop similar guidelines that can be used to strengthen mental health initiatives during a time of crisis without fuelling the spread of the virus. Such protocols should be relevant to the local context because sociocultural practices are the distinctive spiritual material that characterizes a society as a social group (10) .In this paper, we explore the COVID-19 pandemic from a South African perspective by highlighting the impact of this pandemic on certain social norms and linking the important role', metadata={'source': 'Covid Dataset/5221.txt'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[multi_query_retriever_from_llm,compression_retriever,retriever]\n",
    ")\n",
    "\n",
    "ensemble_retriever.invoke(\"What is covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.                   \n",
      "Generating: 100%|██████████| 50/50 [00:55<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "import ragas\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "# documents = load your documents\n",
    "\n",
    "# generator with openai models\n",
    "generator = TestsetGenerator.with_openai(critic_llm = \"gpt-4\")\n",
    "\n",
    "# Change resulting question type distribution\n",
    "distributions = {\n",
    "    simple: 0.3,\n",
    "    multi_context: 0.3,\n",
    "    reasoning: 0.4\n",
    "}\n",
    "\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(pages, 50, distributions) \n",
    "df =testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df.to_csv(\"test_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the timeframe of the COVID-19 pandemic...</td>\n",
       "      <td>['Radiological Imaging of Viral Pneumonia Case...</td>\n",
       "      <td>The COVID-19 pandemic period reached the pande...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What effect does IL-1β have on the adhesion of...</td>\n",
       "      <td>['RA (Figure 6(h) ). As shown in Figure 6 (i),...</td>\n",
       "      <td>IL-1β strongly enhances the adhesion of A549 c...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How does PHC facility attendance relate to bre...</td>\n",
       "      <td>[\" formula milk or other foods. Of the sample ...</td>\n",
       "      <td>There is a significant relationship between PH...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What are the natural hosts of Influenza A viru...</td>\n",
       "      <td>['The Role of Animal Models In Influenza Vacci...</td>\n",
       "      <td>Waterfowl and shorebirds are the natural reser...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the importance of component detection ...</td>\n",
       "      <td>[\" two main optimization criteria are the accu...</td>\n",
       "      <td>Component detection is important in power line...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0  What is the timeframe of the COVID-19 pandemic...   \n",
       "1           1  What effect does IL-1β have on the adhesion of...   \n",
       "2           2  How does PHC facility attendance relate to bre...   \n",
       "3           3  What are the natural hosts of Influenza A viru...   \n",
       "4           4  What is the importance of component detection ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['Radiological Imaging of Viral Pneumonia Case...   \n",
       "1  ['RA (Figure 6(h) ). As shown in Figure 6 (i),...   \n",
       "2  [\" formula milk or other foods. Of the sample ...   \n",
       "3  ['The Role of Animal Models In Influenza Vacci...   \n",
       "4  [\" two main optimization criteria are the accu...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The COVID-19 pandemic period reached the pande...         simple   \n",
       "1  IL-1β strongly enhances the adhesion of A549 c...         simple   \n",
       "2  There is a significant relationship between PH...         simple   \n",
       "3  Waterfowl and shorebirds are the natural reser...         simple   \n",
       "4  Component detection is important in power line...         simple   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 16, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame where ground_truth is not NaN\n",
    "filtered_df = df[df['ground_truth'].notna()]\n",
    "\n",
    "# Group the questions by evolution_type\n",
    "grouped_questions = filtered_df.groupby('evolution_type')['question'].apply(list).to_dict()\n",
    "\n",
    "\n",
    "# Extracting questions into separate lists based on their evolution_type\n",
    "simple_questions = grouped_questions.get('simple', [])\n",
    "reasoning_questions = grouped_questions.get('reasoning', [])\n",
    "multi_context_questions = grouped_questions.get('multi_context', [])\n",
    "\n",
    "# Displaying the lengths of the lists to show how many questions are in each category\n",
    "len(simple_questions), len(reasoning_questions), len(multi_context_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 16, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ground truths into separate lists corresponding to the question types\n",
    "simple_ground_truths = filtered_df[filtered_df['evolution_type'] == 'simple']['ground_truth'].tolist()\n",
    "reasoning_ground_truths = filtered_df[filtered_df['evolution_type'] == 'reasoning']['ground_truth'].tolist()\n",
    "multi_context_ground_truths = filtered_df[filtered_df['evolution_type'] == 'multi_context']['ground_truth'].tolist()\n",
    "\n",
    "# Displaying the lengths of the lists to confirm the number of ground truths matches the number of questions\n",
    "len(simple_ground_truths), len(reasoning_ground_truths), len(multi_context_ground_truths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions based on retrieval of specific information from the documents \n",
    "simple = simple_questions\n",
    "simple_expected_answer = simple_ground_truths\n",
    "\n",
    "multi_context_query_list = multi_context_questions\n",
    "multi_context_query_list_answers = multi_context_ground_truths\n",
    "\n",
    "reasoning_query_list = reasoning_questions\n",
    "reasoning_query_list_answers = reasoning_ground_truths\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def return_result(query_list):\n",
    "    result_list = []\n",
    "    for query in query_list:\n",
    "    \n",
    "    \n",
    "        # conversational chain for conversational_retriever_chain\n",
    "        chat_history = []\n",
    "        result_from_conversational_chain = conversational_retriever_chain({\"question\": query, \"chat_history\": chat_history})\n",
    "        chat_history.append((query, result_from_conversational_chain[\"answer\"]))\n",
    "\n",
    "        # conversational chain for multiquery retriever\n",
    "        result_multi_query = qa_multi_query({\"query\": query})\n",
    "\n",
    "        # conversational chain for compression retriever\n",
    "        result_compress_query = qa_compress_query({\"query\": query})\n",
    "\n",
    "\n",
    "        # conversational chain for vectordb retriever\n",
    "        result_vectordb_query =  qa_vectordb_query({\"query\": query})\n",
    "\n",
    "        # conversational chain for vectordb retriever with mmr\n",
    "        result_vectordb_mmr_query =  qa_vectordb_query({\"query\": query})\n",
    "\n",
    "        # append the results to the result_list\n",
    "        result_list.append([query, result_multi_query['result'], result_compress_query['result'], result_vectordb_query['result'],result_vectordb_mmr_query['result'],result_from_conversational_chain[\"answer\"]])\n",
    "\n",
    "    return result_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupeshyadav/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For simple questions\n",
    "simple_questions_result = return_result(simple_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>multi_query</th>\n",
       "      <th>compress_query</th>\n",
       "      <th>vectordb_query</th>\n",
       "      <th>vectordb_mmr_query</th>\n",
       "      <th>conversational_retriever_chain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the COVID-19 pandemic impact mental h...</td>\n",
       "      <td>From a South African perspective, the COVID-19...</td>\n",
       "      <td>From a South African perspective, the COVID-19...</td>\n",
       "      <td>From a South African perspective, the COVID-19...</td>\n",
       "      <td>From a South African perspective, the COVID-19...</td>\n",
       "      <td>From a South African perspective, the COVID-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What factors are associated with an increased ...</td>\n",
       "      <td>The factors associated with an increased risk ...</td>\n",
       "      <td>The factors associated with an increased risk ...</td>\n",
       "      <td>The factors associated with an increased risk ...</td>\n",
       "      <td>The factors associated with an increased risk ...</td>\n",
       "      <td>The factors associated with an increased risk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is the impact of coalitions with politica...</td>\n",
       "      <td>The study found that coalitions that include p...</td>\n",
       "      <td>The analysis suggests that coalitions with pol...</td>\n",
       "      <td>The presence of political parties in coalition...</td>\n",
       "      <td>The presence of political parties in coalition...</td>\n",
       "      <td>The presence of political parties in coalition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How did the stocking and sales of AZM change d...</td>\n",
       "      <td>During the COVID-19 pandemic, specifically bet...</td>\n",
       "      <td>During the COVID-19 pandemic, specifically bet...</td>\n",
       "      <td>During the COVID-19 pandemic in Jordan, there ...</td>\n",
       "      <td>During the COVID-19 pandemic in Jordan, there ...</td>\n",
       "      <td>During the COVID-19 pandemic in Jordan, there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How has the shift towards collaborative care i...</td>\n",
       "      <td>The shift towards collaborative care has funda...</td>\n",
       "      <td>The text does not provide specific information...</td>\n",
       "      <td>The text does not provide specific information...</td>\n",
       "      <td>The text does not provide specific information...</td>\n",
       "      <td>The text does not provide specific information...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0  How does the COVID-19 pandemic impact mental h...   \n",
       "1           1  What factors are associated with an increased ...   \n",
       "2           2  What is the impact of coalitions with politica...   \n",
       "3           3  How did the stocking and sales of AZM change d...   \n",
       "4           4  How has the shift towards collaborative care i...   \n",
       "\n",
       "                                         multi_query  \\\n",
       "0  From a South African perspective, the COVID-19...   \n",
       "1  The factors associated with an increased risk ...   \n",
       "2  The study found that coalitions that include p...   \n",
       "3  During the COVID-19 pandemic, specifically bet...   \n",
       "4  The shift towards collaborative care has funda...   \n",
       "\n",
       "                                      compress_query  \\\n",
       "0  From a South African perspective, the COVID-19...   \n",
       "1  The factors associated with an increased risk ...   \n",
       "2  The analysis suggests that coalitions with pol...   \n",
       "3  During the COVID-19 pandemic, specifically bet...   \n",
       "4  The text does not provide specific information...   \n",
       "\n",
       "                                      vectordb_query  \\\n",
       "0  From a South African perspective, the COVID-19...   \n",
       "1  The factors associated with an increased risk ...   \n",
       "2  The presence of political parties in coalition...   \n",
       "3  During the COVID-19 pandemic in Jordan, there ...   \n",
       "4  The text does not provide specific information...   \n",
       "\n",
       "                                  vectordb_mmr_query  \\\n",
       "0  From a South African perspective, the COVID-19...   \n",
       "1  The factors associated with an increased risk ...   \n",
       "2  The presence of political parties in coalition...   \n",
       "3  During the COVID-19 pandemic in Jordan, there ...   \n",
       "4  The text does not provide specific information...   \n",
       "\n",
       "                      conversational_retriever_chain  \n",
       "0  From a South African perspective, the COVID-19...  \n",
       "1  The factors associated with an increased risk ...  \n",
       "2  The presence of political parties in coalition...  \n",
       "3  During the COVID-19 pandemic in Jordan, there ...  \n",
       "4  The text does not provide specific information...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Reasoning based questions\n",
    "import pandas as pd\n",
    "simple_ques_set_one_with_stuff = pd.DataFrame(data=simple_questions_result, \n",
    "columns=['question','multi_query','compress_query','vectordb_query','vectordb_mmr_query',\"conversational_retriever_chain\",\n",
    "         ]).head()\n",
    "\n",
    "simple_ques_set_one_with_stuff.to_csv(\"simple_questions_result.csv\")\n",
    "\n",
    "simple_questions_result_df = pd.read_csv(\"simple_questions_result.csv\")\n",
    "simple_questions_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How does the COVID-19 pandemic impact mental health from a South African perspective?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_questions_result_df[\"question\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# For Reasoning based questions\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m reasoning_questions_result \u001b[39m=\u001b[39m return_result(reasoning_query_list)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reasoning_ques_set_one_with_stuff \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mreasoning_questions_result, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmulti_query\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcompress_query\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvectordb_query\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvectordb_mmr_query\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mconversational_retriever_chain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m          ])\u001b[39m.\u001b[39mhead()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m reasoning_ques_set_one_with_stuff\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mreasoning_questions_result.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m result_multi_query \u001b[39m=\u001b[39m qa_multi_query({\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m: query})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# conversational chain for compression retriever\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m result_compress_query \u001b[39m=\u001b[39m qa_compress_query({\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m: query})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# conversational chain for vectordb retriever\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X52sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m result_vectordb_query \u001b[39m=\u001b[39m  qa_vectordb_query({\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m: query})\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m    379\u001b[0m     inputs,\n\u001b[1;32m    380\u001b[0m     cast(RunnableConfig, {k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m config\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m v \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m}),\n\u001b[1;32m    381\u001b[0m     return_only_outputs\u001b[39m=\u001b[39;49mreturn_only_outputs,\n\u001b[1;32m    382\u001b[0m     include_run_info\u001b[39m=\u001b[39;49minclude_run_info,\n\u001b[1;32m    383\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    154\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:144\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    145\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, question\u001b[39m=\u001b[39;49mquestion, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child()\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer, \u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:550\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    546\u001b[0m         _output_key\n\u001b[1;32m    547\u001b[0m     ]\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    551\u001b[0m         _output_key\n\u001b[1;32m    552\u001b[0m     ]\n\u001b[1;32m    554\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    555\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    556\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m    379\u001b[0m     inputs,\n\u001b[1;32m    380\u001b[0m     cast(RunnableConfig, {k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m config\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m v \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m}),\n\u001b[1;32m    381\u001b[0m     return_only_outputs\u001b[39m=\u001b[39;49mreturn_only_outputs,\n\u001b[1;32m    382\u001b[0m     include_run_info\u001b[39m=\u001b[39;49minclude_run_info,\n\u001b[1;32m    383\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    154\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:137\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    136\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 137\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    138\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    140\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m    141\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:244\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    243\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/llm.py:293\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    279\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \n\u001b[1;32m    281\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m    379\u001b[0m     inputs,\n\u001b[1;32m    380\u001b[0m     cast(RunnableConfig, {k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m config\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m v \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m}),\n\u001b[1;32m    381\u001b[0m     return_only_outputs\u001b[39m=\u001b[39;49mreturn_only_outputs,\n\u001b[1;32m    382\u001b[0m     include_run_info\u001b[39m=\u001b[39;49minclude_run_info,\n\u001b[1;32m    383\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    154\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    100\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 103\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain/chains/llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m callbacks \u001b[39m=\u001b[39m run_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    116\u001b[0m         prompts,\n\u001b[1;32m    117\u001b[0m         stop,\n\u001b[1;32m    118\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    119\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mbind(stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs)\u001b[39m.\u001b[39mbatch(\n\u001b[1;32m    123\u001b[0m         cast(List, prompts), {\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:544\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    542\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    543\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 544\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:408\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    407\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 408\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    409\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    410\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    411\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    412\u001b[0m ]\n\u001b[1;32m    413\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    396\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 398\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    399\u001b[0m                 m,\n\u001b[1;32m    400\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    401\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    402\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    403\u001b[0m             )\n\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:577\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    578\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    579\u001b[0m     )\n\u001b[1;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:441\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    436\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    438\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m: stream} \u001b[39mif\u001b[39;00m stream \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}),\n\u001b[1;32m    439\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 441\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(\n\u001b[1;32m    442\u001b[0m     messages\u001b[39m=\u001b[39;49mmessage_dicts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    443\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_community/chat_models/openai.py:356\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    358\u001b[0m retry_decorator \u001b[39m=\u001b[39m _create_retry_decorator(\u001b[39mself\u001b[39m, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m    360\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    664\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    665\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    666\u001b[0m             {\n\u001b[1;32m    667\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    668\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    669\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    670\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    671\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    672\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    673\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    674\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    675\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    676\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    677\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    678\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    679\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    680\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    681\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    682\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    683\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    684\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    685\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    686\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    687\u001b[0m             },\n\u001b[1;32m    688\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    689\u001b[0m         ),\n\u001b[1;32m    690\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    691\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    692\u001b[0m         ),\n\u001b[1;32m    693\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    694\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    695\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    696\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    890\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    891\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    892\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    893\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    894\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    895\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/openai/_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    915\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mauth\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcustom_auth\n\u001b[1;32m    917\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    919\u001b[0m         request,\n\u001b[1;32m    920\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    921\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    922\u001b[0m     )\n\u001b[1;32m    923\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    924\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[39m=\u001b[39m pool_request\u001b[39m.\u001b[39mwait_for_connection(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[39m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Desktop/Rudranil/rudra/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1263\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1260\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1261\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1262\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1263\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1136\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1137\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1138\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For Reasoning based questions\n",
    "\n",
    "reasoning_questions_result = return_result(reasoning_query_list)\n",
    "\n",
    "reasoning_ques_set_one_with_stuff = pd.DataFrame(data=reasoning_questions_result, \n",
    "columns=['question','multi_query','compress_query','vectordb_query','vectordb_mmr_query',\"conversational_retriever_chain\",\n",
    "         ]).head()\n",
    "\n",
    "reasoning_ques_set_one_with_stuff.to_csv(\"reasoning_questions_result.csv\")\n",
    "\n",
    "reasoning_questions_result_df = pd.read_csv(\"reasoning_questions_result.csv\")\n",
    "reasoning_questions_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_pipeline(retriever, model_name=\"gpt-3.5-turbo\", temperature=0):\n",
    "    \"\"\"\n",
    "    Set up a RAG pipeline.\n",
    "\n",
    "    Args:\n",
    "        retriever: The retriever to use for retrieving context.\n",
    "        model_name (str): The name of the model to use.\n",
    "        temperature (float): The temperature to use for the model.\n",
    "\n",
    "    Returns:\n",
    "        The set up RAG pipeline.\n",
    "    \"\"\"\n",
    "    # Define LLM\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=temperature)\n",
    "\n",
    "    # Define prompt template\n",
    "    template = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Setup RAG pipeline\n",
    "    retrieval = RunnableParallel(\n",
    "        {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    )\n",
    "\n",
    "    chain = retrieval | prompt | llm | StrOutputParser()\n",
    "\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(questions, ground_truth, chain, retriever):\n",
    "    \"\"\"\n",
    "    Create a dataset from questions and ground truths.\n",
    "\n",
    "    Args:\n",
    "        questions (list): The list of questions.\n",
    "        ground_truths (list): The list of ground truths.\n",
    "        chain: The RAG pipeline.\n",
    "        retriever: The retriever to use for retrieving context.\n",
    "\n",
    "    Returns:\n",
    "        The created dataset.\n",
    "    \"\"\"\n",
    "    answers  = []\n",
    "    contexts = []\n",
    "\n",
    "    for question in questions:\n",
    "        answers.append(chain.invoke(question))\n",
    "        contexts.append([docs.page_content for docs in retriever.get_relevant_documents(question)])\n",
    "\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truth\": ground_truth\n",
    "    }\n",
    "\n",
    "    # Convert dict to dataset\n",
    "    dataset = Dataset.from_dict(data)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Evaluate a dataset using various metrics.\n",
    "\n",
    "    Args:\n",
    "        dataset: The dataset to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        The evaluation result as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    result = evaluate(\n",
    "        dataset=dataset, \n",
    "        metrics=[\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df = result.to_pandas()\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retriever(retriever, questions, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate a retriever using a list of questions and ground truths.\n",
    "\n",
    "    Args:\n",
    "        retriever: The retriever to evaluate.\n",
    "        questions (list): The list of questions.\n",
    "        ground_truths (list): The list of ground truths.\n",
    "\n",
    "    Returns:\n",
    "        The evaluation result as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    chain = setup_rag_pipeline(retriever)\n",
    "    dataset = create_dataset(questions, ground_truth, chain, retriever)\n",
    "    df = evaluate_dataset(dataset)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Reranker — Cross Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "#\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Optional, Sequence\n",
    "from langchain.schema import Document\n",
    "from langchain.pydantic_v1 import Extra, root_validator\n",
    "\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "from langchain.retrievers.document_compressors.base import BaseDocumentCompressor\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "# from config import bge_reranker_large\n",
    "\n",
    "class BgeRerank(BaseDocumentCompressor):\n",
    "    model_name:str = 'BAAI/bge-reranker-large'\n",
    "    \"\"\"Model name to use for reranking.\"\"\"\n",
    "    top_n: int = 3\n",
    "    \"\"\"Number of documents to return.\"\"\"\n",
    "    model:CrossEncoder = CrossEncoder(model_name)\n",
    "    \"\"\"CrossEncoder instance to use for reranking.\"\"\"\n",
    "\n",
    "    def bge_rerank(self,query,docs):\n",
    "        model_inputs =  [[query, doc] for doc in docs]\n",
    "        scores = self.model.predict(model_inputs)\n",
    "        results = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "        return results[:self.top_n]\n",
    "\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def compress_documents(\n",
    "        self,\n",
    "        documents: Sequence[Document],\n",
    "        query: str,\n",
    "        callbacks: Optional[Callbacks] = None,\n",
    "    ) -> Sequence[Document]:\n",
    "        \"\"\"\n",
    "        Compress documents using BAAI/bge-reranker models.\n",
    "\n",
    "        Args:\n",
    "            documents: A sequence of documents to compress.\n",
    "            query: The query to use for compressing the documents.\n",
    "            callbacks: Callbacks to run during the compression process.\n",
    "\n",
    "        Returns:\n",
    "            A sequence of compressed documents.\n",
    "        \"\"\"\n",
    "        if len(documents) == 0:  # to avoid empty api call\n",
    "            return []\n",
    "        doc_list = list(documents)\n",
    "        _docs = [d.page_content for d in doc_list]\n",
    "        results = self.bge_rerank(query, _docs)\n",
    "        final_results = []\n",
    "        for r in results:\n",
    "            doc = doc_list[r[0]]\n",
    "            doc.metadata[\"relevance_score\"] = r[1]\n",
    "            final_results.append(doc)\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers.embeddings_redundant_filter import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.document_transformers.long_context_reorder import LongContextReorder\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "#\n",
    "vs_retriever = vectordb.as_retriever(search_kwargs={\"k\":10})\n",
    "#\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever,vs_retriever],\n",
    "                                       weight=[0.5,0.5])\n",
    "#\n",
    "\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embedding)\n",
    "#\n",
    "reordering = LongContextReorder()\n",
    "#\n",
    "reranker = BgeRerank()\n",
    "#\n",
    "pipeline_compressor = DocumentCompressorPipeline(transformers=[redundant_filter,reordering,reranker])\n",
    "#\n",
    "compression_pipeline = ContextualCompressionRetriever(base_compressor=pipeline_compressor,\n",
    "                                                      base_retriever=ensemble_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "  print(\n",
    "      f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n + {d.page_content}\" for i,d in enumerate(docs)])\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      " + 2021) Mental Health, Culture and Resilience-Approaching the COVID-19 Pandemic From a South African Perspective\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      " + COVID-19 pandemic from a South African perspective by highlighting the impact of this pandemic on certain social norms and linking the important role of culture, spirituality, and religion in promoting mental health and resilience. Furthermore, we provide perspectives on how individuals and societies can be supported to continue to practice their spiritual and religious activities without breaking the prescribed guidelines.The management of a patient with COVID-19 drastically deviates from how people have been accustomed to looking after those who are suffering from a medical illness. In SA, the regulations of the Disaster Management Act No. 57 of 2020 prohibit the visitation of the sick in hospital, thereby preventing any physical contact the families may have with those with COVID-19 (11) . Families of hospitalized patients with COVID-19 and other illnesses do not get an opportunity to communicate with their loved ones even in times of imminent death, missing opportunities to practice rituals of dealing with those who are sick and dying that have been established over centuries. Even those who do not receive care in health facilities are subjected to strict quarantine and self-isolation for long periods of time (12) .COVID-19 deaths have been perceived by many as cold and inhumane in nature, forcing frontline workers to make quick decisions about end-of-life care while shielding vulnerable family members from getting the disease (13) . The respondents of a UK-based study\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      " + restricting these may translate into loss of routine pleasurable social activities. For example, identified places where people usually access social support, like churches, schools, and sporting venues, have limited access during hard lockdowns. In a multicultural and ethnically diverse country like SA, there is bound to be a resultant breakdown and significant loss of the social support 3 www.healthline.com>health-news. systems that promote resilience, thus making people susceptible to psychosocial distress and mental health problems.According to indigenous knowledge systems, African spirituality has emphasized that life is interconnected and that, in order to be fully human, one needs to address the holistic development of a person's physical, mental, social, economic, and spiritual well-being (28) . Social connections have thus been identified as a key platform wherein individuals are protected against changes to mental status and behavior (26) . The enforcement of social distancing has led to alterations in connections with friends and family members, factors shown to be protective against mental health disorders and to foster resilience in the face of adversity. We can draw lessons from the concurrent HIV epidemic, which is running a parallel course with COVID-19 in SA. During the devastating spread of HIV, religious, spiritual, and cultural beliefs played a significant role in mitigating against mental health problems among sufferers, their families, and healthcare\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      " + mortality.With the current reports of new mutations that may affect vaccine efficacy in several countries (6) and predictions of possible surges or waves in certain clusters, it is clear that this virus is likely to stay with us for some time. Therefore, non-pharmacological measures remain the most reliable longterm strategies to control the pandemic (7) . In order to reduce the rate of transmission, the strictest measures of public health prevention and infection control are being applied. These measures include strict hygiene routines, self-isolation, quarantine, movement restriction, and social distancing, which were introduced on various communities by most governments with little consideration to the mental, social, physical, and economic preparedness of individuals and families (8) . Several countries, including the UK and USA, have established procedures for psychological crisis interventions to deal with public health emergencies (9) . Similarly, our country needs to develop similar guidelines that can be used to strengthen mental health initiatives during a time of crisis without fuelling the spread of the virus. Such protocols should be relevant to the local context because sociocultural practices are the distinctive spiritual material that characterizes a society as a social group (10) .In this paper, we explore the COVID-19 pandemic from a South African perspective by highlighting the impact of this pandemic on certain social norms and linking the important role\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      " + The coronavirus disease 2019 (COVID-19) is a high-impact widespread pandemic, with an imperfectly understood mode of transmission, poorly elucidated course, and a case fatality that has been ∼2% in South Africa (SA) and an estimated fatality rate of 5-20% worldwide, with country-specific rates varying from 0.5 to 3.6% (1) (2) (3) . Frontline health workers and policy makers have been left perplexed by this disease with regard to its evolution over time and the treatment approaches. We, irrespective of age, gender, or background, are all affected by this so-called invisible enemy. The COVID-19 pandemic, in addition to the mortality and physical morbidity, poses threats to the mental health of the entire population. The disease was first identified in a wholesale market in Wuhan, China, in December 2019 and runs a particularly aggressive course in those with underlying comorbidities such as obesity, diabetes, hypertension, cardiac disease, renal disease, and cancer (4, 5) . To this day, several millions of people worldwide have been infected, while a few millions have succumbed to this virus. COVID-19, compared to other epidemics such as HIV, severe acute respiratory syndrome (SARS), Middle East respiratory syndrome (MERS), Ebola, and H1N1, has run a more severe course because of a rapid spread that resulted in acute morbidity and mortality.With the current reports of new mutations that may affect vaccine efficacy in several countries (6) and predictions of possible surges or\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      " + a1111111111 a1111111111 a1111111111 a1111111111 a1111111111In December 2019, a novel coronavirus called severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) caused an outbreak of coronavirus disease 2019 . In March 2020, World Health Organization (WHO) determined that COVID-19 could be characterized as a pandemic [1] . This crisis has profoundly affected all aspects of the society, including the psychological well-being of people [2] . Previous studies have revealed psychological impact of COVID-19 on anxiety, depressive symptoms, and sleep quality depending on demographic factors and preexisting psychiatric illnesses [3, 4] .Chronic medical comorbidity might play a role in the psychological impact of COVID-19. Patients with chronic medical diseases are more susceptible to contracting COVID-19. They also have higher risk of experiencing severe COVID-19 infection-related complications with poorer prognosis than healthy controls [5] . They also have great fears that a collapse of the healthcare system by COVID-19 may prevent them from receiving appropriate and timely treatment [6] .Likewise, patients undergoing dialysis can have psychological distress during this outbreak. It is known that chronic kidney disease (CKD) is associated with depression and anxiety, making patients more vulnerable to COVID-19-related stress [7] [8] [9] . Moreover, patients with CKD have an increased risk of severe COVID-19 infection-related complications and poorer prognosis including higher\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      " + specific conversations about the experiences of being exposed to a pandemic outbreak, with the aim of reinforcing the relational interactions between self-protection and community protection within a cultural context, like it was done in HIV prevention programs (31) .The issue of society, culture, and religious practices in a changing world deserves special mention within the African context, which is characterized by inequities and vulnerabilities. In adapting to the new norms, we should promote and use innovation to enhance social connection and ritual effectiveness, as was the case in Uganda (32) . Many interesting developments have already transformed how rituals are performed, e.g., funerals are livestreamed, highlighting the value of using technology for establishing connection during religious services and funerals. Sadly, in most African communities, access to technology and Application in response to a pandemicEncourage others to adhere to social distancing. Support others from a distance. Do not stigmatize those with COVID 19 symptoms.We all have a role to play in stopping the pandemic. Wear a mask when in public.Adhere to social distancing. Protect the vulnerable individuals. Disclose your symptoms.Share essential resources, such as water, face masks, and hand sanitizers. Protect your family. Protect your colleagues. Protect your community. Save lives. Take the vaccine.Cooperative economics Sharing of resources.Allocating more resources to vulnerable\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      " + public health event, such as COVID-19, the physical and psychological strain on healthcare professionals cannot be underestimated [44] . It has been documented that the main concerns from healthcare staff during the COVID-19 outbreak in China have included being afraid of bringing the virus to their home and families [45] . Staff articulated a lack of support in how to manage patients when they were unwilling to be quarantined at the hospital, or when patients did not cooperate with medical measures because of panic [45] . Finally, staff articulated concerns about the shortage of PPE and feelings of incapability when faced with critically ill patients [45] and difficult decision-making in the allocation continuous positive airway pressure (CPAP) and ventilators.Experiences of health professionals during the severe acute respiratory syndrome (SARS) outbreak indicate a sequel of depression, anxiety, fear, frustration [46] and post-traumatic stress [44] .Research is currently underway looking into the mental impact of working in the frontline with people infected by COVID-19. Initial data from a large sample (n=1257) in China suggest similar patterns, with half of the sample of frontline staff experiencing depression and anxiety [47] . In fact, being a female nurse indicated a higher risk for depression, anxiety and psychological distress [47] .Caring for deteriorating patients across all ages increases emotional strain and physical exhaustion [48] . This experience can be\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      " + [61] . To shield the high-risk groups worldwide and reduce the burden on acute care and ICU beds, countries are enforcing lockdowns, curfews, and social isolation to mitigate the spread of this disease. Evidence has already underscored that people affected by cancer can experience loneliness [62, 63] prior to the COVID-19 pandemic. Inevitability, behavioural changes in society for people affected by cancer will impact the experience of boredom [64] , sense of connection, social support (including access to emotional, informational, practical and financial) [65] , loneliness and anger [64] . Moreover, a recent study has shown that people affected by cancer during this pandemic are at increased risk of depression [66] . We strongly advocate for services to recognise these impacts and seek to provide support and intervention using safe non-physical support and contact, such as video or digital technologies [67, 68] or nurse -led telephone services [69] .Palliative care services are also affected, facing one of the greatest challenges from the impact of the pandemic. Learning from previous experience on epidemics, the authors have identified issues relating to space and workforce, psycho-social challenges and issues related to the new profile of the patients that will require palliative care services [70] . To date, there is limited evidence on the role of palliative care on managing the COVID-19 pandemic when it should be one of the key components in the strategies. The limited\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      " + General Practitioner perspectives and wellbeing during the COVID-19 Pandemic: 1 a mixed method social media analysis 2 3 4 Pandemic: a mixed methods social media analysis 2 3\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(vs_retriever.get_relevant_documents(\"How does the COVID-19 pandemic impact mental health from a South African perspective?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      " + The coronavirus disease 2019 (COVID-19) is a high-impact widespread pandemic, with an imperfectly understood mode of transmission, poorly elucidated course, and a case fatality that has been ∼2% in South Africa (SA) and an estimated fatality rate of 5-20% worldwide, with country-specific rates varying from 0.5 to 3.6% (1) (2) (3) . Frontline health workers and policy makers have been left perplexed by this disease with regard to its evolution over time and the treatment approaches. We, irrespective of age, gender, or background, are all affected by this so-called invisible enemy. The COVID-19 pandemic, in addition to the mortality and physical morbidity, poses threats to the mental health of the entire population. The disease was first identified in a wholesale market in Wuhan, China, in December 2019 and runs a particularly aggressive course in those with underlying comorbidities such as obesity, diabetes, hypertension, cardiac disease, renal disease, and cancer (4, 5) . To this day, several millions of people worldwide have been infected, while a few millions have succumbed to this virus. COVID-19, compared to other epidemics such as HIV, severe acute respiratory syndrome (SARS), Middle East respiratory syndrome (MERS), Ebola, and H1N1, has run a more severe course because of a rapid spread that resulted in acute morbidity and mortality.With the current reports of new mutations that may affect vaccine efficacy in several countries (6) and predictions of possible surges or\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      " + COVID-19 pandemic from a South African perspective by highlighting the impact of this pandemic on certain social norms and linking the important role of culture, spirituality, and religion in promoting mental health and resilience. Furthermore, we provide perspectives on how individuals and societies can be supported to continue to practice their spiritual and religious activities without breaking the prescribed guidelines.The management of a patient with COVID-19 drastically deviates from how people have been accustomed to looking after those who are suffering from a medical illness. In SA, the regulations of the Disaster Management Act No. 57 of 2020 prohibit the visitation of the sick in hospital, thereby preventing any physical contact the families may have with those with COVID-19 (11) . Families of hospitalized patients with COVID-19 and other illnesses do not get an opportunity to communicate with their loved ones even in times of imminent death, missing opportunities to practice rituals of dealing with those who are sick and dying that have been established over centuries. Even those who do not receive care in health facilities are subjected to strict quarantine and self-isolation for long periods of time (12) .COVID-19 deaths have been perceived by many as cold and inhumane in nature, forcing frontline workers to make quick decisions about end-of-life care while shielding vulnerable family members from getting the disease (13) . The respondents of a UK-based study\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      " + a1111111111 a1111111111 a1111111111 a1111111111 a1111111111In December 2019, a novel coronavirus called severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) caused an outbreak of coronavirus disease 2019 . In March 2020, World Health Organization (WHO) determined that COVID-19 could be characterized as a pandemic [1] . This crisis has profoundly affected all aspects of the society, including the psychological well-being of people [2] . Previous studies have revealed psychological impact of COVID-19 on anxiety, depressive symptoms, and sleep quality depending on demographic factors and preexisting psychiatric illnesses [3, 4] .Chronic medical comorbidity might play a role in the psychological impact of COVID-19. Patients with chronic medical diseases are more susceptible to contracting COVID-19. They also have higher risk of experiencing severe COVID-19 infection-related complications with poorer prognosis than healthy controls [5] . They also have great fears that a collapse of the healthcare system by COVID-19 may prevent them from receiving appropriate and timely treatment [6] .Likewise, patients undergoing dialysis can have psychological distress during this outbreak. It is known that chronic kidney disease (CKD) is associated with depression and anxiety, making patients more vulnerable to COVID-19-related stress [7] [8] [9] . Moreover, patients with CKD have an increased risk of severe COVID-19 infection-related complications and poorer prognosis including higher\n"
     ]
    }
   ],
   "source": [
    "docs = compression_pipeline.get_relevant_documents(\"How does the COVID-19 pandemic impact mental health from a South African perspective?\")\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupeshyadav/Desktop/Rudranil/rudra/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "#\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(),\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=vectordb.as_retriever(search_kwargs={\"k\":5}),\n",
    "                                 return_source_documents=True)\n",
    "\n",
    "naive_response = qa(\"How does the COVID-19 pandemic impact mental health from a South African perspective?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How does the COVID-19 pandemic impact mental health from a South African perspective?',\n",
       " 'result': 'The COVID-19 pandemic has had a significant impact on mental health in South Africa. The strict measures of public health prevention and infection control, such as social distancing and quarantine, have led to a loss of routine pleasurable social activities and a breakdown of social support systems. These changes can make individuals susceptible to psychosocial distress and mental health problems. Additionally, the restrictions on visitation of the sick in hospitals and the perceived cold and inhumane nature of COVID-19 deaths have made it challenging for families to communicate with loved ones and practice traditional rituals, leading to increased emotional distress. Indigenous knowledge systems in South Africa emphasize the importance of social connections for mental well-being, and the enforcement of social distancing has led to alterations in these connections, which can negatively impact mental health. Furthermore, the uncertainty surrounding the pandemic, including the emergence of new mutations and the potential long-term presence of the virus, adds to the mental health challenges faced by individuals and communities in South Africa.',\n",
       " 'source_documents': [Document(page_content='2021) Mental Health, Culture and Resilience-Approaching the COVID-19 Pandemic From a South African Perspective', metadata={'source': 'Covid Dataset/5221.txt'}),\n",
       "  Document(page_content='COVID-19 pandemic from a South African perspective by highlighting the impact of this pandemic on certain social norms and linking the important role of culture, spirituality, and religion in promoting mental health and resilience. Furthermore, we provide perspectives on how individuals and societies can be supported to continue to practice their spiritual and religious activities without breaking the prescribed guidelines.The management of a patient with COVID-19 drastically deviates from how people have been accustomed to looking after those who are suffering from a medical illness. In SA, the regulations of the Disaster Management Act No. 57 of 2020 prohibit the visitation of the sick in hospital, thereby preventing any physical contact the families may have with those with COVID-19 (11) . Families of hospitalized patients with COVID-19 and other illnesses do not get an opportunity to communicate with their loved ones even in times of imminent death, missing opportunities to practice rituals of dealing with those who are sick and dying that have been established over centuries. Even those who do not receive care in health facilities are subjected to strict quarantine and self-isolation for long periods of time (12) .COVID-19 deaths have been perceived by many as cold and inhumane in nature, forcing frontline workers to make quick decisions about end-of-life care while shielding vulnerable family members from getting the disease (13) . The respondents of a UK-based study', metadata={'source': 'Covid Dataset/5221.txt'}),\n",
       "  Document(page_content=\"restricting these may translate into loss of routine pleasurable social activities. For example, identified places where people usually access social support, like churches, schools, and sporting venues, have limited access during hard lockdowns. In a multicultural and ethnically diverse country like SA, there is bound to be a resultant breakdown and significant loss of the social support 3 www.healthline.com>health-news. systems that promote resilience, thus making people susceptible to psychosocial distress and mental health problems.According to indigenous knowledge systems, African spirituality has emphasized that life is interconnected and that, in order to be fully human, one needs to address the holistic development of a person's physical, mental, social, economic, and spiritual well-being (28) . Social connections have thus been identified as a key platform wherein individuals are protected against changes to mental status and behavior (26) . The enforcement of social distancing has led to alterations in connections with friends and family members, factors shown to be protective against mental health disorders and to foster resilience in the face of adversity. We can draw lessons from the concurrent HIV epidemic, which is running a parallel course with COVID-19 in SA. During the devastating spread of HIV, religious, spiritual, and cultural beliefs played a significant role in mitigating against mental health problems among sufferers, their families, and healthcare\", metadata={'source': 'Covid Dataset/5221.txt'}),\n",
       "  Document(page_content='mortality.With the current reports of new mutations that may affect vaccine efficacy in several countries (6) and predictions of possible surges or waves in certain clusters, it is clear that this virus is likely to stay with us for some time. Therefore, non-pharmacological measures remain the most reliable longterm strategies to control the pandemic (7) . In order to reduce the rate of transmission, the strictest measures of public health prevention and infection control are being applied. These measures include strict hygiene routines, self-isolation, quarantine, movement restriction, and social distancing, which were introduced on various communities by most governments with little consideration to the mental, social, physical, and economic preparedness of individuals and families (8) . Several countries, including the UK and USA, have established procedures for psychological crisis interventions to deal with public health emergencies (9) . Similarly, our country needs to develop similar guidelines that can be used to strengthen mental health initiatives during a time of crisis without fuelling the spread of the virus. Such protocols should be relevant to the local context because sociocultural practices are the distinctive spiritual material that characterizes a society as a social group (10) .In this paper, we explore the COVID-19 pandemic from a South African perspective by highlighting the impact of this pandemic on certain social norms and linking the important role', metadata={'source': 'Covid Dataset/5221.txt'}),\n",
       "  Document(page_content='The coronavirus disease 2019 (COVID-19) is a high-impact widespread pandemic, with an imperfectly understood mode of transmission, poorly elucidated course, and a case fatality that has been ∼2% in South Africa (SA) and an estimated fatality rate of 5-20% worldwide, with country-specific rates varying from 0.5 to 3.6% (1) (2) (3) . Frontline health workers and policy makers have been left perplexed by this disease with regard to its evolution over time and the treatment approaches. We, irrespective of age, gender, or background, are all affected by this so-called invisible enemy. The COVID-19 pandemic, in addition to the mortality and physical morbidity, poses threats to the mental health of the entire population. The disease was first identified in a wholesale market in Wuhan, China, in December 2019 and runs a particularly aggressive course in those with underlying comorbidities such as obesity, diabetes, hypertension, cardiac disease, renal disease, and cancer (4, 5) . To this day, several millions of people worldwide have been infected, while a few millions have succumbed to this virus. COVID-19, compared to other epidemics such as HIV, severe acute respiratory syndrome (SARS), Middle East respiratory syndrome (MERS), Ebola, and H1N1, has run a more severe course because of a rapid spread that resulted in acute morbidity and mortality.With the current reports of new mutations that may affect vaccine efficacy in several countries (6) and predictions of possible surges or', metadata={'source': 'Covid Dataset/5221.txt'})]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The COVID-19 pandemic has had a significant impact on mental health in South Africa. The restrictions and regulations, such as prohibiting visitation of the sick in hospitals and strict quarantine measures, have led to increased feelings of isolation and anxiety. Families are unable to communicate with their loved ones in hospitals, missing out on traditional rituals of care and mourning. Frontline workers also face difficult decisions about end-of-life care, adding to their psychological burden. Overall, the pandemic has posed threats to the mental health of the entire population in South Africa.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "#\n",
    "qa_advanced_compressor = RetrievalQA.from_chain_type(llm=ChatOpenAI(),\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=compression_pipeline,\n",
    "                                 return_source_documents=True)\n",
    "#\n",
    "qa_adv_response = qa_advanced_compressor(\"How does the COVID-19 pandemic impact mental health from a South African perspective?\")  \n",
    "qa_adv_response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n",
      "Generating: 100%|██████████| 300/300 [04:25<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import ragas\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "# documents = load your documents\n",
    "\n",
    "# generator with openai models\n",
    "generator = TestsetGenerator.with_openai(critic_llm = \"gpt-4\")\n",
    "\n",
    "# Change resulting question type distribution\n",
    "distributions = {\n",
    "    simple: 0.3,\n",
    "    multi_context: 0.3,\n",
    "    reasoning: 0.4\n",
    "}\n",
    "\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(pages, 300, distributions) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can the serum half-life of nanobody candid...</td>\n",
       "      <td>[ , at the cost of a shortened in vivo half-li...</td>\n",
       "      <td>Linking a nanobody to anti-human serum albumin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of CD4+ cells in the immune s...</td>\n",
       "      <td>[ to training.When 2 groups of trained and unt...</td>\n",
       "      <td>nan</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do functional changes in VSS affect visual...</td>\n",
       "      <td>[ increase in alpha-gamma phase-amplitude coup...</td>\n",
       "      <td>Functional changes in VSS affect visual proces...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the role of RBMs in the neutralization...</td>\n",
       "      <td>[ in each study. In addition, Huo et al. valid...</td>\n",
       "      <td>nan</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the empirical variability among circul...</td>\n",
       "      <td>[ sequences extracted from GISAID to estimate ...</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How can the serum half-life of nanobody candid...   \n",
       "1  What is the role of CD4+ cells in the immune s...   \n",
       "2  How do functional changes in VSS affect visual...   \n",
       "3  What is the role of RBMs in the neutralization...   \n",
       "4  What is the empirical variability among circul...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ , at the cost of a shortened in vivo half-li...   \n",
       "1  [ to training.When 2 groups of trained and unt...   \n",
       "2  [ increase in alpha-gamma phase-amplitude coup...   \n",
       "3  [ in each study. In addition, Huo et al. valid...   \n",
       "4  [ sequences extracted from GISAID to estimate ...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  Linking a nanobody to anti-human serum albumin...         simple   \n",
       "1                                                nan         simple   \n",
       "2  Functional changes in VSS affect visual proces...         simple   \n",
       "3                                                nan         simple   \n",
       "4  The empirical variability among circulating SA...         simple   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can the serum half-life of nanobody candid...</td>\n",
       "      <td>[ , at the cost of a shortened in vivo half-li...</td>\n",
       "      <td>Linking a nanobody to anti-human serum albumin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of CD4+ cells in the immune s...</td>\n",
       "      <td>[ to training.When 2 groups of trained and unt...</td>\n",
       "      <td>nan</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do functional changes in VSS affect visual...</td>\n",
       "      <td>[ increase in alpha-gamma phase-amplitude coup...</td>\n",
       "      <td>Functional changes in VSS affect visual proces...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the role of RBMs in the neutralization...</td>\n",
       "      <td>[ in each study. In addition, Huo et al. valid...</td>\n",
       "      <td>nan</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the empirical variability among circul...</td>\n",
       "      <td>[ sequences extracted from GISAID to estimate ...</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the role of the antiviral response in ...</td>\n",
       "      <td>[-15 is involved in natural killer cell differ...</td>\n",
       "      <td>The antiviral response plays a role in the imm...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the appearance of the classic steric m...</td>\n",
       "      <td>[ bond length and angle values on the accessib...</td>\n",
       "      <td>The appearance of the classic steric map deriv...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What were the psychological distress levels of...</td>\n",
       "      <td>[Psychological distress of patients with end- ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the role of JAK2 and JAK3 inhibitors i...</td>\n",
       "      <td>[BARRIER trials led to the FDA recommendation ...</td>\n",
       "      <td>JAK2 and JAK3 inhibitors have been recommended...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What factors contributed to the increase in cr...</td>\n",
       "      <td>[ period required rapid operational changes th...</td>\n",
       "      <td>The shortage of sterile gowns and the lack of ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the behavior of H5N1 influenza viruses...</td>\n",
       "      <td>[ receptors [153] . However, other investigato...</td>\n",
       "      <td>H5N1 influenza viruses in ferrets can replicat...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What were the clinical symptoms observed in fe...</td>\n",
       "      <td>[ Beyond a mild level of inactivity, overt cli...</td>\n",
       "      <td>The clinical symptoms seen in ferrets did not ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How has the ferret model been used to study in...</td>\n",
       "      <td>[ Beyond a mild level of inactivity, overt cli...</td>\n",
       "      <td>The ferret model has been used to study influe...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What was the Fieldtrip toolbox used for in the...</td>\n",
       "      <td>[us Fastrak digitizer. A luminance-triggered p...</td>\n",
       "      <td>The Fieldtrip toolbox was used for pre-process...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is the significance of the variations in ...</td>\n",
       "      <td>[ bond length and angle values on the accessib...</td>\n",
       "      <td>The significance of the variations in the bond...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What were the mobilization outcomes of the hou...</td>\n",
       "      <td>[ that coalitions that include political parti...</td>\n",
       "      <td>The housing coalitions in Dublin and Lisbon we...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What is the focus of the study regarding the S...</td>\n",
       "      <td>[ where similarities lie between the immune re...</td>\n",
       "      <td>The focus of the study regarding the SARS-CoV-...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What was included in the buffer solution conta...</td>\n",
       "      <td>[IPTG) at an A 610nm of 0.6. All subsequent pr...</td>\n",
       "      <td>The buffer solution containing protease inhibi...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is the prevalence of bovine Noroviruses i...</td>\n",
       "      <td>[en and hindgut of cattle and sheep (Nathan et...</td>\n",
       "      <td>The prevalence of bovine Noroviruses in dairy ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the importance of an empirical subdivi...</td>\n",
       "      <td>[ . The term post-migration living difficultie...</td>\n",
       "      <td>An empirical subdivision is important in study...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   How can the serum half-life of nanobody candid...   \n",
       "1   What is the role of CD4+ cells in the immune s...   \n",
       "2   How do functional changes in VSS affect visual...   \n",
       "3   What is the role of RBMs in the neutralization...   \n",
       "4   What is the empirical variability among circul...   \n",
       "5   What is the role of the antiviral response in ...   \n",
       "6   What is the appearance of the classic steric m...   \n",
       "7   What were the psychological distress levels of...   \n",
       "8   What is the role of JAK2 and JAK3 inhibitors i...   \n",
       "9   What factors contributed to the increase in cr...   \n",
       "10  What is the behavior of H5N1 influenza viruses...   \n",
       "11  What were the clinical symptoms observed in fe...   \n",
       "12  How has the ferret model been used to study in...   \n",
       "13  What was the Fieldtrip toolbox used for in the...   \n",
       "14  What is the significance of the variations in ...   \n",
       "15  What were the mobilization outcomes of the hou...   \n",
       "16  What is the focus of the study regarding the S...   \n",
       "17  What was included in the buffer solution conta...   \n",
       "18  What is the prevalence of bovine Noroviruses i...   \n",
       "19  What is the importance of an empirical subdivi...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [ , at the cost of a shortened in vivo half-li...   \n",
       "1   [ to training.When 2 groups of trained and unt...   \n",
       "2   [ increase in alpha-gamma phase-amplitude coup...   \n",
       "3   [ in each study. In addition, Huo et al. valid...   \n",
       "4   [ sequences extracted from GISAID to estimate ...   \n",
       "5   [-15 is involved in natural killer cell differ...   \n",
       "6   [ bond length and angle values on the accessib...   \n",
       "7   [Psychological distress of patients with end- ...   \n",
       "8   [BARRIER trials led to the FDA recommendation ...   \n",
       "9   [ period required rapid operational changes th...   \n",
       "10  [ receptors [153] . However, other investigato...   \n",
       "11  [ Beyond a mild level of inactivity, overt cli...   \n",
       "12  [ Beyond a mild level of inactivity, overt cli...   \n",
       "13  [us Fastrak digitizer. A luminance-triggered p...   \n",
       "14  [ bond length and angle values on the accessib...   \n",
       "15  [ that coalitions that include political parti...   \n",
       "16  [ where similarities lie between the immune re...   \n",
       "17  [IPTG) at an A 610nm of 0.6. All subsequent pr...   \n",
       "18  [en and hindgut of cattle and sheep (Nathan et...   \n",
       "19  [ . The term post-migration living difficultie...   \n",
       "\n",
       "                                         ground_truth evolution_type  \\\n",
       "0   Linking a nanobody to anti-human serum albumin...         simple   \n",
       "1                                                 nan         simple   \n",
       "2   Functional changes in VSS affect visual proces...         simple   \n",
       "3                                                 nan         simple   \n",
       "4   The empirical variability among circulating SA...         simple   \n",
       "5   The antiviral response plays a role in the imm...         simple   \n",
       "6   The appearance of the classic steric map deriv...         simple   \n",
       "7                                                 nan         simple   \n",
       "8   JAK2 and JAK3 inhibitors have been recommended...         simple   \n",
       "9   The shortage of sterile gowns and the lack of ...         simple   \n",
       "10  H5N1 influenza viruses in ferrets can replicat...         simple   \n",
       "11  The clinical symptoms seen in ferrets did not ...         simple   \n",
       "12  The ferret model has been used to study influe...         simple   \n",
       "13  The Fieldtrip toolbox was used for pre-process...         simple   \n",
       "14  The significance of the variations in the bond...         simple   \n",
       "15  The housing coalitions in Dublin and Lisbon we...         simple   \n",
       "16  The focus of the study regarding the SARS-CoV-...         simple   \n",
       "17  The buffer solution containing protease inhibi...         simple   \n",
       "18  The prevalence of bovine Noroviruses in dairy ...         simple   \n",
       "19  An empirical subdivision is important in study...         simple   \n",
       "\n",
       "    episode_done  \n",
       "0           True  \n",
       "1           True  \n",
       "2           True  \n",
       "3           True  \n",
       "4           True  \n",
       "5           True  \n",
       "6           True  \n",
       "7           True  \n",
       "8           True  \n",
       "9           True  \n",
       "10          True  \n",
       "11          True  \n",
       "12          True  \n",
       "13          True  \n",
       "14          True  \n",
       "15          True  \n",
       "16          True  \n",
       "17          True  \n",
       "18          True  \n",
       "19          True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"trainingmain.csv\")\n",
    "test_questions = test_df[\"question\"].values.tolist()[:51]\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()[:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How can the serum half-life of nanobody candid...</td>\n",
       "      <td>[' , at the cost of a shortened in vivo half-l...</td>\n",
       "      <td>Linking a nanobody to anti-human serum albumin...</td>\n",
       "      <td>The serum half-life of nanobody candidates can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How do functional changes in VSS affect visual...</td>\n",
       "      <td>[' increase in alpha-gamma phase-amplitude cou...</td>\n",
       "      <td>Functional changes in VSS affect visual proces...</td>\n",
       "      <td>Functional changes in Visual Snow Syndrome (VS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the empirical variability among circul...</td>\n",
       "      <td>[' sequences extracted from GISAID to estimate...</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>What is the role of the antiviral response in ...</td>\n",
       "      <td>['-15 is involved in natural killer cell diffe...</td>\n",
       "      <td>The antiviral response plays a role in the imm...</td>\n",
       "      <td>The antiviral response in the immune system pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>What is the appearance of the classic steric m...</td>\n",
       "      <td>[' bond length and angle values on the accessi...</td>\n",
       "      <td>The appearance of the classic steric map deriv...</td>\n",
       "      <td>The appearance of the classic steric map deriv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0  How can the serum half-life of nanobody candid...   \n",
       "1           2  How do functional changes in VSS affect visual...   \n",
       "2           4  What is the empirical variability among circul...   \n",
       "3           5  What is the role of the antiviral response in ...   \n",
       "4           6  What is the appearance of the classic steric m...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [' , at the cost of a shortened in vivo half-l...   \n",
       "1  [' increase in alpha-gamma phase-amplitude cou...   \n",
       "2  [' sequences extracted from GISAID to estimate...   \n",
       "3  ['-15 is involved in natural killer cell diffe...   \n",
       "4  [' bond length and angle values on the accessi...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Linking a nanobody to anti-human serum albumin...   \n",
       "1  Functional changes in VSS affect visual proces...   \n",
       "2  The empirical variability among circulating SA...   \n",
       "3  The antiviral response plays a role in the imm...   \n",
       "4  The appearance of the classic steric map deriv...   \n",
       "\n",
       "                                             answers  \n",
       "0  The serum half-life of nanobody candidates can...  \n",
       "1  Functional changes in Visual Snow Syndrome (VS...  \n",
       "2  The empirical variability among circulating SA...  \n",
       "3  The antiviral response in the immune system pl...  \n",
       "4  The appearance of the classic steric map deriv...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = qa.invoke({\"query\" : question})\n",
    "  answers.append(response[\"result\"])\n",
    "  contexts.append([context.page_content for context in response['source_documents']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answers1 = []\n",
    "contexts1 = []\n",
    "\n",
    "for question1 in test_questions:\n",
    "  response1 = qa.invoke({\"query\" : question1})\n",
    "  answers1.append(response[\"result\"])\n",
    "  contexts1.append([context.page_content for context in response['source_documents']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"answers\"] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>episode_done</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How can the serum half-life of nanobody candid...</td>\n",
       "      <td>[' , at the cost of a shortened in vivo half-l...</td>\n",
       "      <td>Linking a nanobody to anti-human serum albumin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "      <td>The serum half-life of nanobody candidates can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How do functional changes in VSS affect visual...</td>\n",
       "      <td>[' increase in alpha-gamma phase-amplitude cou...</td>\n",
       "      <td>Functional changes in VSS affect visual proces...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "      <td>Functional changes in Visual Snow Syndrome (VS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the empirical variability among circul...</td>\n",
       "      <td>[' sequences extracted from GISAID to estimate...</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>What is the role of the antiviral response in ...</td>\n",
       "      <td>['-15 is involved in natural killer cell diffe...</td>\n",
       "      <td>The antiviral response plays a role in the imm...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "      <td>The antiviral response in the immune system pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>What is the appearance of the classic steric m...</td>\n",
       "      <td>[' bond length and angle values on the accessi...</td>\n",
       "      <td>The appearance of the classic steric map deriv...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           0  How can the serum half-life of nanobody candid...   \n",
       "2           2  How do functional changes in VSS affect visual...   \n",
       "4           4  What is the empirical variability among circul...   \n",
       "5           5  What is the role of the antiviral response in ...   \n",
       "6           6  What is the appearance of the classic steric m...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [' , at the cost of a shortened in vivo half-l...   \n",
       "2  [' increase in alpha-gamma phase-amplitude cou...   \n",
       "4  [' sequences extracted from GISAID to estimate...   \n",
       "5  ['-15 is involved in natural killer cell diffe...   \n",
       "6  [' bond length and angle values on the accessi...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  Linking a nanobody to anti-human serum albumin...         simple   \n",
       "2  Functional changes in VSS affect visual proces...         simple   \n",
       "4  The empirical variability among circulating SA...         simple   \n",
       "5  The antiviral response plays a role in the imm...         simple   \n",
       "6  The appearance of the classic steric map deriv...         simple   \n",
       "\n",
       "   episode_done                                            answers  \n",
       "0          True  The serum half-life of nanobody candidates can...  \n",
       "2          True  Functional changes in Visual Snow Syndrome (VS...  \n",
       "4          True  The empirical variability among circulating SA...  \n",
       "5          True  The antiviral response in the immune system pl...  \n",
       "6          True                                      I don't know.  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df.dropna(subset=['ground_truth'])\n",
    "df = df[['question', 'contexts', 'ground_truth']]\n",
    "\n",
    "test_questions = df[\"question\"].values.tolist()\n",
    "test_groundtruths = df[\"ground_truth\"].values.tolist()\n",
    "\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = qa.invoke({\"query\" : question})\n",
    "  answers.append(response[\"result\"])\n",
    "  contexts.append([context.page_content for context in response['source_documents']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"answers\"] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can the serum half-life of nanobody candid...</td>\n",
       "      <td>[' , at the cost of a shortened in vivo half-l...</td>\n",
       "      <td>Linking a nanobody to anti-human serum albumin...</td>\n",
       "      <td>The serum half-life of nanobody candidates can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do functional changes in VSS affect visual...</td>\n",
       "      <td>[' increase in alpha-gamma phase-amplitude cou...</td>\n",
       "      <td>Functional changes in VSS affect visual proces...</td>\n",
       "      <td>Functional changes in Visual Snow Syndrome (VS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the empirical variability among circul...</td>\n",
       "      <td>[' sequences extracted from GISAID to estimate...</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "      <td>The empirical variability among circulating SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the role of the antiviral response in ...</td>\n",
       "      <td>['-15 is involved in natural killer cell diffe...</td>\n",
       "      <td>The antiviral response plays a role in the imm...</td>\n",
       "      <td>The antiviral response in the immune system pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the appearance of the classic steric m...</td>\n",
       "      <td>[' bond length and angle values on the accessi...</td>\n",
       "      <td>The appearance of the classic steric map deriv...</td>\n",
       "      <td>The appearance of the classic steric map deriv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How can the serum half-life of nanobody candid...   \n",
       "2  How do functional changes in VSS affect visual...   \n",
       "4  What is the empirical variability among circul...   \n",
       "5  What is the role of the antiviral response in ...   \n",
       "6  What is the appearance of the classic steric m...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [' , at the cost of a shortened in vivo half-l...   \n",
       "2  [' increase in alpha-gamma phase-amplitude cou...   \n",
       "4  [' sequences extracted from GISAID to estimate...   \n",
       "5  ['-15 is involved in natural killer cell diffe...   \n",
       "6  [' bond length and angle values on the accessi...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Linking a nanobody to anti-human serum albumin...   \n",
       "2  Functional changes in VSS affect visual proces...   \n",
       "4  The empirical variability among circulating SA...   \n",
       "5  The antiviral response plays a role in the imm...   \n",
       "6  The appearance of the classic steric map deriv...   \n",
       "\n",
       "                                             answers  \n",
       "0  The serum half-life of nanobody candidates can...  \n",
       "2  Functional changes in Visual Snow Syndrome (VS...  \n",
       "4  The empirical variability among circulating SA...  \n",
       "5  The antiviral response in the immune system pl...  \n",
       "6  The appearance of the classic steric map deriv...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"trainingmain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can the serum half-life of nanobody candidates be increased using anti-human serum albumin?',\n",
       " 'answer': 'The serum half-life of nanobody candidates can be increased by linking them to anti-human serum albumin (HSA). This technique has been shown to increase the serum half-life to approximately 6 days in cynomolgus monkeys.',\n",
       " 'contexts': ['antibody concentration/affinity and viral load, there are two other ways in which ADE can be avoided. Both involve the Fc, the interacting partner on the virus-antibody complexes that initiates ADE. Nanobodies lacking the Fc domain would potentially avoid the pitfall of ADE [111] , at the cost of a shortened in vivo half-life. Hence, in such a case, options to elongate the half-life of nanobody candidates should be taken before moving to the clinic. These may include linking a nanobody to anti-human serum albumin (HSA), a technique that has been proven to increase the serum half-life to~6 days in cynomolgus monkeys [112] . Another strategy to circumvent ADE is the introduction of a LALA mutation (Leu234Ala together with Leu235Ala) into the Fc to minimize FcR activation and Fc-mediated toxicity of human antibody candidates against SARS-CoV-2. This has been done with JS016 (currently in clinical trial) which employs a LALA mutation in the Fc to minimize FcγR activation and Fcmediated toxicity, and also with antibody CB6 where CB6-LALA is currently being investigated in clinical trials (Table 1 ) [71] .We are currently experiencing an explosion of research into antibodies to combat COVID-19 that include neutralizing antibodies against SARS-CoV-2 (Table 1 ) and therapeutic antibodies against COVID-19-associated hyperinflammation. To date, 8 neutralizing antibodies against SARS-CoV-2 have entered clinical evaluation -LY-CoV555, JS016, REGN-COV2, TY027, BRII-196, BRII-198, CT-P59,',\n",
       "  'at 4 °C for up to four weeks. For use, plates were emptied and treated with TritonX-100 (1% v/v) in PBS (100 µL/well) for 30 min at RT and after flicking off the supernatant, blocked with 1% fetal calf serum in PBS for 30 min at RT. Subsequently, cells were incubated with MAb or indicated sera (50 µL/well) for 1 h at RT. After washing the plates three times with PBS-Tween, wells were incubated with FITC-conjugated anti-species specific IgG or IgY conjugate (Sigma-Aldrich, country) for 1 h at RT. After final washing three times with PBS-Tween, wells were mounted with glycerol in water 1:5 and inspected under the microscope (Eclipse TS100, Nikon, Minato, Tokyo, Japan) with the appropriate filter (excitation 495 nm, emission 525 nm).Serial dilutions (log 2 ) of MAbs, starting with concentrated supernatants were mixed with equal volume of NDV/NR730/16 (100 µL) containing 400 tissue culture infectious dose 50 (TCID 50 ). For each dilution row, the last well was kept without serum to serve as virus control. For each test a heat inactivated (56 °C, 30 min) NDV reference serum was included as positive neutralization control. After incubation for 30 min at 37 °C, 50 µL of antibody / virus mixture was transferred in triplicate to 100 µL LMH cells that were cultivated without fetal calf serum but with TPCK treated Trypsin (2 µg/mL) (Sigma-Aldrich) in 96well plates (Corning) at a density 10 6 cells/ cm 2 . The plates were incubated at 37 °C with 5% CO 2 atmosphere for four days and SNT',\n",
       "  'Center) in phosphate-buffered saline (PBS) and incubated at 4 • C overnight. The plate was washed five times with 0.1% Tween-20 in PBS (TPBS). The plate was then blocked with 3% nonfat milk in TPBS for 1 h at room temperature (RT). Serial dilutions were performed with the human serum samples from 1:32 through 1:4096 in 1% nonfat milk in TPBS, while mouse sera were diluted at 1:16. Each ELISA plate included a negative control serum collected before 2016 and a positive control (the same serum from a participant with a confirmed Vaccines 2021, 9, 587 3 of 12 positive COVID-19 diagnosis). Diluted sera were then transferred to the ELISA plate and incubated at RT for 2 h. The plate was then washed five times with TPBS, and secondary goat anti-human IgG (Cat# A18811, Invitrogen) or goat anti-mouse IgG (Southern Biotech Cat.# 1030-05) conjugated to horseradish peroxidase (HRP) was added and incubated for 1 h at RT. The plate was then washed again with TPBS five times, and Sigma-Aldrich o-phenylenediamine dihydrochloride (OPD), or TMB, was added for exactly 10 or 3 min (respectively) before being stopped by 3 molar hydrochloric acid (HCL) or 2N sulfuric acid (H2SO4). The plate was read in an ELISA reader at 490 nm or 450 nm respectively.The neutralization titers of human or mouse sera were determined using SARS-CoV-2 under BSL-3 containment essentially as previously described [23] . SARS-CoV-2 (WA/01 strain, BEI Resources) was propagated on Vero E6 cells as previously described [24]',\n",
       "  'by the composition of the viral particle, which is dominated by the highly immunogenic NP protein that fills the entire inner virion [48] . In addition, the M protein, forming an array underneath the viral membrane is abundant in the virion [49] . Both proteins account for ~ 30% of the virus-specific molecular masses in gradient-purified viral preparations when analyzed by nano-LC MALDI-TOF/TOF mass spectrometry, and only about 10% of the virion are HN molecules [11; Karger personal communication]. By disrupting gradient-purified virus by Triton X-100 (2%) and 1 M KCl, Nishikawa and colleagues could increase the fraction of HI reactive HN-specific MAbs, retrieving 9 out of a total of 21 [50] . Our method also used Triton X-100 and KCl disruption, but we subsequently applied ultracentrifugation to enrich HN and deplete M and NP proteins. This procedure was able to pull down a high proportion of the proteins that migrate as a 55 kD band including the NP. The subsequent steps reduced the proportion of the 55 kD proteins further, but were not sufficient to remove all of the proteins: A slight band was still visible by Coomassie-staining (Fig. 1a) and reacted with the polyclonal antibody preparation from a ND vaccinated chicken (Fig. 1b) . This might be a result of incomplete separation of the interaction of the HN protein with the NP protein via the matrix protein [51] . Accordingly, three of the selected MAbs were reactive with the 55 kD band by western blot (Fig. 3) . However,',\n",
       "  'relevant epitopes of the homo-tetrameric HN protein [52] [53] [54] , the approach to generate MAbs reactive with biologically activesites depends on native HN protein with the correct conformation, ideally from virus produced in eukaryotic cells ensuring bona fide glycosylation and folding. Reassuring evidence was obtained through the HI-positive antibody response of two mice immunized with enriched HN preparations. However, in order to select the appropriate antibodies, the screening system has to present the test antigen in its native conformation. When using the indirect ELISA techniques, immobilizing antigen directly to the plastic surfaces of the plates likely interferes with the conformational integrity of the antigen, and important epitopes may be unpredictably masked or exposed [55] . To avoid such structural alterations caused by the coating, Russel and colleagues used NDV infected and formalin fixed cells with indirect immunoperoxidase test to visualize specific reactivity [25] . Having the advantage that already staining pattern in this test may give an indication whether MAbs are directed to outer glycoproteins, the test depends on manual inspection of the plates and is more difficult to standardize; in addition, use of formalin may denature sensitive epitopes. To be able to use ELISA technique for high throughput screening, investigators have used antibody-or poly L-lysine-coated plates to capture and thereby preserve the conformation of a viral protein [56, 57]'],\n",
       " 'ground_truth': 'Linking a nanobody to anti-human serum albumin (HSA) has been proven to increase the serum half-life to~6 days in cynomolgus monkeys.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "response_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/255 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating: 100%|██████████| 255/255 [03:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9245, 'answer_relevancy': 0.9131, 'context_recall': 0.9804, 'context_precision': 0.9087, 'answer_correctness': 0.6154}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]\n",
    "#\n",
    "naive_results = evaluate(response_dataset, metrics,raise_exceptions=False)\n",
    "naive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Compressor technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of fine-tuning in BERT and how does it relate to pre-training?',\n",
       " 'answer': 'The purpose of fine-tuning in BERT is to adapt the pre-trained model to a specific downstream task or dataset. Fine-tuning involves updating the parameters of the pre-trained BERT model using task-specific data to enhance its performance on the specific task. It helps the model learn task-specific patterns and nuances from the new data. \\n\\nFine-tuning is related to pre-training in the sense that the pre-trained BERT model has already learned general language representations from a large corpus of text during the pre-training phase. Fine-tuning builds upon this pre-trained knowledge by further training the model on task-specific data, adjusting the learned parameters to better suit the specific task at hand. This process allows the model to leverage the general language understanding it gained during pre-training and adapt it to the specifics of the downstream task.',\n",
       " 'contexts': ['care was provided in VA facilities before the pandemic.\" it would be tokenized to [\\'most\\', \\'v\\', \\'##a\\', \\'care\\', \\'was\\', \\'provided\\', \\'in\\', \\'v\\', \\'##a\\', \\'facilities\\', \\'before\\', \\'the\\', \\'pan\\', \\'##de\\', \\'##mic\\'] with the tokenizer of BioBERT, and the sentence can be also converted into [\\'most\\', \\'va\\', \\'care\\', \\'was\\', \\'provided\\', \\'in\\', \\'va\\', \\'facilities\\', \\'before\\', \\'the\\', \\'pandemic\\'] using SciBERT\\'s tokenizer. Fig. 1 (b) and Fig. 1 (c) illustrate the extended co-occurrence graph in the wordpiece level for BioBERT and SciBERT, respectively.Since both BioBERT and SciBERT follow the basic structure of BERT, here we only present the inner mechanism of BERT. Given a sample (S, T) from the summarization dataset D, the source word sequence and target word sequence can be represented as S = {w 1 , w 2 , ⋯, w m } with length m and T = {t 1 , t 2 , ⋯, t n } with length n. Then we use BPE tokenizer to obtain corresponding wordpiece sequences of the source sequence as:where w #j i represents the j-th sub-word of the word w i , and k i is the number of sub-words in word w i .In the pre-training process of BERT, the segment token [SEP] is used to separate sentences for the next sentence prediction (NSP) task, and the embedding of [CLS] is used to classify the sentence relationships. To maintain consistency between pre-training and fine-tuning process of BERT, we insert a [CLS] symbol to the head and a [SEP] symbol to the end of the source sequence, before feeding the wordpiece sequence into BERT',\n",
       "  'al. [37] proposed a novel model SemSUM, which leverages the information of original input texts and corresponding semantic dependency graphs to guide abstractive summarization process.Pre-trained language models (PTMs) [38] [39] [40] [41] have achieved significant improvements for a wide range of natural language processing (NLP) tasks. Peters et al. [38] developed Embeddings from Language Models (ELMo), an approach to learn contextualized word representations by training a bidirectional LSTM to optimize a disjoint bidirectional language model objective. Radford et al. [39] proposed to improve language understanding by Generative Pre-Training (GPT), which uses a combination of unsupervised pre-training and supervised fine-tuning. Devlin et al. [31] proposed a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. BERT uses a masked language modeling objective to train a deep bidirectional Transformer encoder, which learns interactions between left and right context. Zhang et al. [40] incorporated knowledge graph into BERT to simultaneously learn lexical, syntactic and knowledge information. PEGASUS [42] is a taskspecific PTM which is trained over massive pre-training corpora and via gap sentences generation task.According to Sinha et al. [43] , the language model pre-trained via Masked Language Model objective on corpora with permuted word orders, shows little differences from PTMs trained on non-permuted',\n",
       "  'scientific abstracts.To further explore how the performance of our proposed models vary with different sequence encoders, we adopt original BERT, and its two domain-specific variations, i.e., SciBERT and BioBERT, as sequence encoder separately. In Table 5 , we present the detailed information of the three pre-trained models, including their corpora for pre-training, sizes of vocabulary, and hyper-parameters for their structures.We only change the type of sequence encoder and keep other settings in Table 2 in this experiment. The curves of training losses and perplexities are presented in Fig. 4 , and the results on the test set are provided in Table 5 .From Fig. 4 , we observe that cross-entropy loss of the three summarization models drop beneath 3.0 within 20,000 fine-tuning steps and continue to decline, the perplexity curves show the same trend. Perplexity is an evaluation metric for language models and reflects the uncertainty when a probabilistic model makes predictions. Among these curves, we find SciBERT-based model offers the worst training performance, and the BioBERT-based model surpasses the other two models in terms of convergence. Table 6 shows the results of three variations of our proposed summarization model on the test set, from which we can make the following observations: 1) SciBERT-based model performs well on the test set, although the converges of its training loss curve is the slowest among the three models, which indicates that the overfitting issue'],\n",
       " 'ground_truth': 'Linking a nanobody to anti-human serum albumin (HSA) has been proven to increase the serum half-life to~6 days in cynomolgus monkeys.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "adv_answers = []\n",
    "adv_contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = qa_advanced_compressor.invoke({\"query\" : question})\n",
    "  adv_answers.append(response[\"result\"])\n",
    "  adv_contexts.append([context.page_content for context in response['source_documents']])\n",
    "\n",
    "#wrap into huggingface dataset\n",
    "response_dataset_advanced_retrieval1 = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : adv_answers,\n",
    "    \"contexts\" : adv_contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "response_dataset_advanced_retrieval1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiquery Techique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of fine-tuning in BERT and how does it relate to pre-training?',\n",
       " 'answer': \"Fine-tuning in BERT is a process where the pre-trained BERT model is further trained on a specific task. The purpose of fine-tuning is to adapt the general language understanding capabilities of the pre-trained BERT model to the specific requirements of the task at hand. This is done by adjusting the model's parameters to minimize the error on the new task. \\n\\nPre-training and fine-tuning are related in the sense that pre-training provides a good initialization of the model parameters, which captures the general properties of the language, while fine-tuning adjusts these parameters to the specifics of the task. This two-step process allows the model to leverage both the general language understanding learned during pre-training and the specific task knowledge learned during fine-tuning. \\n\\nIn the context provided, it is mentioned that fine-tuning the pre-trained models can lead to overfitting on the training set. However, when the BERT-based sequence encoder is replaced with domain-specific pre-trained language models like SciBERT and BioBERT, the model achieves better performance. This suggests that pre-training on in-domain corpora can help with downstream tasks, emphasizing the importance of both pre-training and fine-tuning in achieving good performance.\",\n",
       " 'contexts': ['on the test set, although the converges of its training loss curve is the slowest among the three models, which indicates that the overfitting issue on the training set occurs when fine-tuning the pre-trained models; 2) when the BERTbased sequence encoder is replaced with domain-specific pre-trained language models, i.e., the SciBERT and BioBERT, our proposed abstractive summarization model achieves certain performance gains, which proves that in-domain pre-training corpora can help the downstream tasks. In our case, SciBERT and BioBERT improve the performance significantly as expected, since they are mainly pre-trained on the scientific papers from biomedical domain; 3) SciBERT-based model outperforms BioBERT-based model by 1.40 points on ROUGE-1, which emphasizes the necessity of a domain-specific vocabulary. Though both of two domain-specific pre-trained models are all obtained by training on the biomedical corpora and the corpus of BioBERT is much larger, the BioBERT-bases model is less competitive because it simply inherits the vocabulary from BERT.The feature fusion module learns to merge the features generated by sequence encoder and knowledge encoder. And the quality of fused representations from the feature fusion module is crucial to the summary generation process. In this set of experiments, we analyze the effectiveness of various feature fusion methods in our proposed summarization framework.As shown in Table 7 , we find that the abstractive summarization model',\n",
       "  'to wordpiece-level by connecting the head wordpiece to each other wordpieces with edges.Identical words that appear more than once at different positions of a sentence are highlighted with bordered text boxes, such as va in subgraph (a) and (c), and v in subgraph (b). In our settings, identical words within a sentence share their neighbors to aggregate more contextual information. As shown in Fig. 2 , we connect these identical words with their neighbors using dotted lines with arrows.In this subsection, we first describe the encoding process of the source textual sequences and the inner mechanism of the BERT language model. Then we demonstrate using a graph attention to process and encode linguistic patterns, i.e., the word co-occurrence relationships. After that, we adopt highway networks to alleviate difficulties in back propagating gradients and to merge linguistic features with contextualized embeddings. Finally, we introduce Transformer decoder equipped with the copy mechanism and the learning objective for the abstractive summarization task. Fig. 3 illustrates the overall architecture of our proposed approach.Since BERT is a classic example of pre-trained language models, we chose to utilize the original BERT as the sequence encoder in our proposed approach at first. However, the vanilla BERT that was pre-trained on the general corpora may not achieve the state-of-the-art performance in a specific domain (e.g., legal documents, clinical reports, scientific',\n",
       "  'al. [37] proposed a novel model SemSUM, which leverages the information of original input texts and corresponding semantic dependency graphs to guide abstractive summarization process.Pre-trained language models (PTMs) [38] [39] [40] [41] have achieved significant improvements for a wide range of natural language processing (NLP) tasks. Peters et al. [38] developed Embeddings from Language Models (ELMo), an approach to learn contextualized word representations by training a bidirectional LSTM to optimize a disjoint bidirectional language model objective. Radford et al. [39] proposed to improve language understanding by Generative Pre-Training (GPT), which uses a combination of unsupervised pre-training and supervised fine-tuning. Devlin et al. [31] proposed a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. BERT uses a masked language modeling objective to train a deep bidirectional Transformer encoder, which learns interactions between left and right context. Zhang et al. [40] incorporated knowledge graph into BERT to simultaneously learn lexical, syntactic and knowledge information. PEGASUS [42] is a taskspecific PTM which is trained over massive pre-training corpora and via gap sentences generation task.According to Sinha et al. [43] , the language model pre-trained via Masked Language Model objective on corpora with permuted word orders, shows little differences from PTMs trained on non-permuted',\n",
       "  'and the decoder modules have 768-dimensional hidden states for all models based on our proposed framework in this experiment.In the training process, we adopt two Adam optimizers with β 1 = 0.9, β 2 = 0.99, ε = 10 − 9 to optimize the parameters of pre-trained encoder and the other parameters. As presented in Table 2 , two fairly different learning rates are used for model optimization. Because the pre-trained language model-based sequence encoder are already well-trained, whereas other components in our model are trained from scratch, the learning rate for the untrained parameters should be relatively higher to quickly reach a reasonable distribution. Following [57] , we adopt the NORM learning rate scheduling strategy to enable the value of learning rate to linearly increase for specific steps and exponentially decrease. We obtained the optimal hyper-parameters for comparison methods by tuning them on the CORD-19 validation set. The parameters of all comparison methods were tuned on validation split of the CORD-19 summarization dataset, as was COVIDSum.After tuning the hyper-parameters by evaluating variations of our proposed method on the validation dataset, we obtained a group of best hyper-parameters for COVIDSum, as shown in Table 2 (type_bert and type_fuse are types of models used in our proposed architecture as sequence encoder and feature fusion module, respectively. type_sent_ext denotes the heuristic method of sentence extraction, num_gat represents the number of',\n",
       "  'Psychological distress of patients with end- stage kidney disease undergoing dialysis during the 2019 coronavirus disease pandemic: A cross-sectional study in a University Hospital',\n",
       "  'To appear in: Vaccine',\n",
       "  \"contains supplementary material available at https://doi.org/10.1007/s12599-022-00745-z.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons. org/licenses/by/4.0/.\",\n",
       "  'Hypervariability of accessible and inaccessible conformational space of proteins ☆',\n",
       "  'stands for the layer normalization function.We use a lower triangular matrix to mask the future information, preventing the attention to unpredicted tokens in inference, and the attention weights after masking can be represented as:where α ij is an element of the attention matrix A in the calculation for masked self-attention. Finally, the decoder calculates the external attention mechanism using the encoded representation H and masked self-attention output Ỹ . The external attention mechanism and the feedforward transformation are represented as follows:whererepresent the outputs of external attention module and feedforward transformation. FFN is the positionwise feedforward network that contains two layers of linear transformation and a rectified linear unit (ReLU) as hidden activation function.The probability distribution p over the pre-defined wordpiece vocabulary can be formulated as:where W v , W v , b v and b u are parameters to be learned.In the decoding process, we obtain the output words autoregressively by sampling from the distribution p.Our proposed COVIDSum model is optimized with the negative loglikelihood loss:where T is the length of the target wordpiece sequence and w * t is the ground-truth word which should be predicted at the t-th timestep.Besides CORD-19 summarization dataset, we also conduct statistical analysis of different summarization datasets, including CNN/Daily Mail (CNN/DM) [6] , New York Times (NY Times) [8] , PubMed [50] and arXiv [51] .'],\n",
       " 'ground_truth': 'Linking a nanobody to anti-human serum albumin (HSA) has been proven to increase the serum half-life to~6 days in cynomolgus monkeys.'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_answers = []\n",
    "adv_contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = qa_multi_query.invoke({\"query\" : question})\n",
    "  adv_answers.append(response[\"result\"])\n",
    "  adv_contexts.append([context.page_content for context in response['source_documents']])\n",
    "\n",
    "#wrap into huggingface dataset\n",
    "response_dataset_advanced_retrieval2 = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : adv_answers,\n",
    "    \"contexts\" : adv_contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "response_dataset_advanced_retrieval2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For contextual Compressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 255/255 [02:25<00:00,  1.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9627, 'answer_relevancy': 0.9174, 'context_recall': 0.2369, 'context_precision': 0.0163, 'answer_correctness': 0.3134}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_retrieval_results1 = evaluate(response_dataset_advanced_retrieval1, metrics,raise_exceptions=False)\n",
    "advanced_retrieval_results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For multiquery Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  52%|█████▏    | 132/255 [01:26<01:39,  1.23it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 255/255 [02:57<00:00,  1.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9785, 'answer_relevancy': 0.8149, 'context_recall': 0.1186, 'context_precision': 0.0229, 'answer_correctness': 0.3771}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_retrieval_results2 = evaluate(response_dataset_advanced_retrieval2, metrics,raise_exceptions=False)\n",
    "advanced_retrieval_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Contextual Compresssion with Document Stuffing</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.924540</td>\n",
       "      <td>0.962745</td>\n",
       "      <td>0.038205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.913075</td>\n",
       "      <td>0.917415</td>\n",
       "      <td>0.004340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.236928</td>\n",
       "      <td>-0.743464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.908742</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>-0.892402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.615350</td>\n",
       "      <td>0.313366</td>\n",
       "      <td>-0.301984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  Baseline  \\\n",
       "0        faithfulness  0.924540   \n",
       "1    answer_relevancy  0.913075   \n",
       "2      context_recall  0.980392   \n",
       "3   context_precision  0.908742   \n",
       "4  answer_correctness  0.615350   \n",
       "\n",
       "   Contextual Compresssion with Document Stuffing     Delta  \n",
       "0                                        0.962745  0.038205  \n",
       "1                                        0.917415  0.004340  \n",
       "2                                        0.236928 -0.743464  \n",
       "3                                        0.016340 -0.892402  \n",
       "4                                        0.313366 -0.301984  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(naive_results.items()), columns=['Metric', 'Baseline'])\n",
    "df_comparison = pd.DataFrame(list(advanced_retrieval_results1.items()), columns=['Metric', 'Contextual Compresssion with Document Stuffing'])\n",
    "\n",
    "df_merged1 = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged1['Delta'] = df_merged1['Contextual Compresssion with Document Stuffing'] - df_merged1['Baseline']\n",
    "\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>MultiQuery Retriever</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.924540</td>\n",
       "      <td>0.978472</td>\n",
       "      <td>0.053933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.913075</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>-0.098220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.118627</td>\n",
       "      <td>-0.861765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.908742</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>-0.885866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.615350</td>\n",
       "      <td>0.377078</td>\n",
       "      <td>-0.238273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  Baseline  MultiQuery Retriever     Delta\n",
       "0        faithfulness  0.924540              0.978472  0.053933\n",
       "1    answer_relevancy  0.913075              0.814855 -0.098220\n",
       "2      context_recall  0.980392              0.118627 -0.861765\n",
       "3   context_precision  0.908742              0.022876 -0.885866\n",
       "4  answer_correctness  0.615350              0.377078 -0.238273"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(naive_results.items()), columns=['Metric', 'Baseline'])\n",
    "df_comparison = pd.DataFrame(list(advanced_retrieval_results2.items()), columns=['Metric', 'MultiQuery Retriever'])\n",
    "\n",
    "df_merged2 = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged2['Delta'] = df_merged2['MultiQuery Retriever'] - df_merged2['Baseline']\n",
    "\n",
    "df_merged2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rupeshyadav/Desktop/Rudranil/advnacedrag.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_merged\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merged' is not defined"
     ]
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Window Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.19-py3-none-any.whl (5.6 kB)\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.9-py3-none-any.whl (25 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.19 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.19-py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m486.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m536.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.10-py3-none-any.whl (10.0 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.11-py3-none-any.whl (36 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.2.14)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (2024.2.0)\n",
      "Requirement already satisfied: httpx in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (0.27.0)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (3.2.1)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.13.3)\n",
      "Requirement already satisfied: pandas in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (0.9.0)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDF-1.23.26-cp311-none-macosx_11_0_arm64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m460.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./rudra/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Collecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.3.9-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.9.4)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./rudra/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./rudra/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.6.3)\n",
      "Requirement already satisfied: anyio in ./rudra/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./rudra/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./rudra/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.0.4)\n",
      "Requirement already satisfied: idna in ./rudra/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in ./rudra/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./rudra/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in ./rudra/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./rudra/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./rudra/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./rudra/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.9.0)\n",
      "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-macosx_11_0_arm64.whl (29.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m328.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in ./rudra/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.19->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rudra/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.2.1)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./rudra/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./rudra/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.19->llama-index) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./rudra/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./rudra/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.19->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./rudra/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.19->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./rudra/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.19->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./rudra/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.19->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./rudra/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in ./rudra/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.16.0)\n",
      "Installing collected packages: striprtf, dirtyjson, soupsieve, PyMuPDFb, nltk, greenlet, pymupdf, beautifulsoup4, llamaindex-py-client, bs4, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed PyMuPDFb-1.23.22 beautifulsoup4-4.12.3 bs4-0.0.2 dirtyjson-1.0.8 greenlet-3.0.3 llama-index-0.10.19 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.9 llama-index-core-0.10.19 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.4 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.10 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.11 llama-index-readers-llama-parse-0.1.3 llama-parse-0.3.9 llamaindex-py-client-0.1.13 nltk-3.8.1 pymupdf-1.23.26 soupsieve-2.5 striprtf-0.0.26\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: llama-index 0.10.19\n",
      "Uninstalling llama-index-0.10.19:\n",
      "  Would remove:\n",
      "    /Users/rupeshyadav/Desktop/Rudranil/rudra/bin/llamaindex-cli\n",
      "    /Users/rupeshyadav/Desktop/Rudranil/rudra/lib/python3.11/site-packages/llama_index-0.10.19.dist-info/*\n",
      "    /Users/rupeshyadav/Desktop/Rudranil/rudra/lib/python3.11/site-packages/llama_index/_bundle/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --force-reinstall!\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall llama-index\n",
    "!pip install llama-index --upgrade --no-cache-dir --force-reinstall! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting weaviate-client\n",
      "  Downloading weaviate_client-4.5.3-py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m120.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-vector-stores-weaviate\n",
      "  Downloading llama_index_vector_stores_weaviate-0.1.4-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.30.0 in ./rudra/lib/python3.11/site-packages (from weaviate-client) (2.31.0)\n",
      "Requirement already satisfied: httpx==0.27.0 in ./rudra/lib/python3.11/site-packages (from weaviate-client) (0.27.0)\n",
      "Requirement already satisfied: validators==0.22.0 in ./rudra/lib/python3.11/site-packages (from weaviate-client) (0.22.0)\n",
      "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
      "  Using cached Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in ./rudra/lib/python3.11/site-packages (from weaviate-client) (2.6.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.57.0 in ./rudra/lib/python3.11/site-packages (from weaviate-client) (1.62.0)\n",
      "Collecting grpcio-tools<2.0.0,>=1.57.0 (from weaviate-client)\n",
      "  Downloading grpcio_tools-1.62.1-cp311-cp311-macosx_10_10_universal2.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m95.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hCollecting grpcio-health-checking<2.0.0,>=1.57.0 (from weaviate-client)\n",
      "  Downloading grpcio_health_checking-1.62.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: anyio in ./rudra/lib/python3.11/site-packages (from httpx==0.27.0->weaviate-client) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./rudra/lib/python3.11/site-packages (from httpx==0.27.0->weaviate-client) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./rudra/lib/python3.11/site-packages (from httpx==0.27.0->weaviate-client) (1.0.4)\n",
      "Requirement already satisfied: idna in ./rudra/lib/python3.11/site-packages (from httpx==0.27.0->weaviate-client) (3.6)\n",
      "Requirement already satisfied: sniffio in ./rudra/lib/python3.11/site-packages (from httpx==0.27.0->weaviate-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./rudra/lib/python3.11/site-packages (from httpcore==1.*->httpx==0.27.0->weaviate-client) (0.14.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./rudra/lib/python3.11/site-packages (from llama-index-vector-stores-weaviate) (0.10.19)\n",
      "Collecting weaviate-client\n",
      "  Downloading weaviate_client-3.26.2-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.4/120.4 kB\u001b[0m \u001b[31m86.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cryptography (from authlib<2.0.0,>=1.2.1->weaviate-client)\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (2024.2.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (3.8.1)\n",
      "Requirement already satisfied: numpy in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.13.3)\n",
      "Requirement already satisfied: pandas in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./rudra/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (0.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./rudra/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rudra/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./rudra/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.9.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./rudra/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.16.0)\n",
      "Requirement already satisfied: click in ./rudra/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./rudra/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./rudra/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./rudra/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./rudra/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./rudra/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.0.0)\n",
      "Collecting cffi>=1.12 (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client)\n",
      "  Using cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (176 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./rudra/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./rudra/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./rudra/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./rudra/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (2024.1)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client)\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./rudra/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./rudra/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./rudra/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in ./rudra/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-weaviate) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=4.21.6 in ./rudra/lib/python3.11/site-packages (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client) (4.25.3)\n",
      "Collecting grpcio>=1.62.1 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n",
      "  Using cached grpcio-1.62.1-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "Requirement already satisfied: setuptools in ./rudra/lib/python3.11/site-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (65.5.0)\n",
      "Installing collected packages: pycparser, cffi, cryptography, authlib, weaviate-client, llama-index-vector-stores-weaviate\n",
      "Successfully installed authlib-1.3.0 cffi-1.16.0 cryptography-42.0.5 llama-index-vector-stores-weaviate-0.1.4 pycparser-2.21 weaviate-client-3.26.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install weaviate-client llama-index-vector-stores-weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "Settings.embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Covid Dataset/11303.txt', 'Covid Dataset/3644.txt', 'Covid Dataset/5235.txt', 'Covid Dataset/1053.txt', 'Covid Dataset/8711.txt', 'Covid Dataset/7422.txt', 'Covid Dataset/8077.txt', 'Covid Dataset/7344.txt', 'Covid Dataset/1735.txt', 'Covid Dataset/9369.txt', 'Covid Dataset/5553.txt', 'Covid Dataset/4895.txt', 'Covid Dataset/11465.txt', 'Covid Dataset/3122.txt', 'Covid Dataset/5547.txt', 'Covid Dataset/4881.txt', 'Covid Dataset/2228.txt', 'Covid Dataset/11471.txt', 'Covid Dataset/3136.txt', 'Covid Dataset/4659.txt', 'Covid Dataset/8063.txt', 'Covid Dataset/7350.txt', 'Covid Dataset/1721.txt', 'Covid Dataset/6728.txt', 'Covid Dataset/1047.txt', 'Covid Dataset/8705.txt', 'Covid Dataset/7436.txt', 'Covid Dataset/11317.txt', 'Covid Dataset/3650.txt', 'Covid Dataset/10009.txt', 'Covid Dataset/5221.txt', 'Covid Dataset/3888.txt', 'Covid Dataset/6700.txt', 'Covid Dataset/9433.txt', 'Covid Dataset/4117.txt', 'Covid Dataset/3678.txt', 'Covid Dataset/2566.txt', 'Covid Dataset/10021.txt', 'Covid Dataset/5209.txt', 'Covid Dataset/2200.txt', 'Covid Dataset/10747.txt', 'Covid Dataset/11459.txt', 'Covid Dataset/4671.txt', 'Covid Dataset/7378.txt', 'Covid Dataset/1709.txt', 'Covid Dataset/6066.txt', 'Covid Dataset/9355.txt', 'Covid Dataset/289.txt', 'Covid Dataset/6072.txt', 'Covid Dataset/9341.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# Assuming \"Covid Dataset\" is a directory in the current working directory\n",
    "directory = 'Covid Dataset'\n",
    "\n",
    "def load_text_files(folder_path: str) -> List[str]:\n",
    "    \"\"\" Load texts from a list of text files in the given folder \"\"\"\n",
    "    texts = \"\"\n",
    "\n",
    "    # List all files in the given directory\n",
    "    files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.txt')][:50]\n",
    "\n",
    "    #print(len(files[:80]))\n",
    "    pages = []\n",
    "\n",
    "    # for filename in files:\n",
    "    #     # Construct full file path\n",
    "    #     file_path = os.path.join(folder_path, filename)\n",
    "    #     print(f\"Loading file: {filename}\")\n",
    "    #     # Create a TextLoader instance for the file\n",
    "    #     loader = TextLoader(file_path)\n",
    "    #     # Load the content of the file\n",
    "    #     content = loader.load()\n",
    "    #     #texts = texts+content[0].page_content\n",
    "    #     # print(\"====================\")\n",
    "    #     # print(content[0].page_content)\n",
    "    #     # print(\"======================\")\n",
    "    #     pages.extend(content)\n",
    "\n",
    "    return files\n",
    "\n",
    "# Load all text files\n",
    "files= load_text_files(directory)\n",
    "\n",
    "# Now `texts` variable contains the content of all `.txt` files from \"Covid Dataset\"\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Load data\n",
    "documents = SimpleDirectoryReader(\n",
    "        input_files=files\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=1024)\n",
    "\n",
    "# Extract nodes from documents\n",
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(21597) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/rupeshyadav/.cache/weaviate-embedded: process ID 21597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-03-16T23:28:55+05:30\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-03-16T23:28:55+05:30\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-03-16T23:28:55+05:30\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-03-16T23:28:55+05:30\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-03-16T23:28:55+05:30\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-03-16T23:28:55+05:30\"}\n",
      "/Users/rupeshyadav/Desktop/Rudranil/rudra/lib/python3.11/site-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.5.4.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 86.19%, threshold set to 80.00%\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate\",\"time\":\"2024-03-16T23:28:55+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/objects/segment-1710467073386991000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/objects/segment-1710467073386991000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_node_info/segment-1710466972083193000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_relationships/segment-1710466972083392000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_relationships/segment-1710466972083392000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_node_info/segment-1710466972083193000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_node_info_searchable/segment-1710466972083837000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_relationships_searchable/segment-1710466972083832000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_node_info_searchable/segment-1710466972083837000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_relationships_searchable/segment-1710466972083832000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_creation_date/segment-1710467073546852000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__id/segment-1710467073491723000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_ref_doc_id/segment-1710467073409214000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_creation_date/segment-1710467073546852000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_last_modified_date/segment-1710467073552646000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_content/segment-1710467073561045000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_text/segment-1710467073416944000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__id/segment-1710467073491723000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_ref_doc_id/segment-1710467073409214000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_document_id/segment-1710467073590528000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_name/segment-1710467073595958000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_doc_id/segment-1710467073620255000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_type/segment-1710467073615170000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_type/segment-1710467073629794000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_path/segment-1710467073622421000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_size/segment-1710467073627414000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_content/segment-1710467073561045000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_last_modified_date/segment-1710467073552646000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_text/segment-1710467073416944000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_document_id/segment-1710467073590528000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_doc_id/segment-1710467073620255000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_name/segment-1710467073595958000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_type/segment-1710467073615170000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_type/segment-1710467073629794000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_path/segment-1710467073622421000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_size/segment-1710467073627414000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_creation_date_searchable/segment-1710467073549780000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_ref_doc_id_searchable/segment-1710467073496030000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_creation_date_searchable/segment-1710467073549780000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_text_searchable/segment-1710467073511709000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_ref_doc_id_searchable/segment-1710467073496030000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_text_searchable/segment-1710467073511709000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_type_searchable/segment-1710467073617946000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_type_searchable/segment-1710467073631654000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_path_searchable/segment-1710467073624526000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_last_modified_date_searchable/segment-1710467073556928000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_name_searchable/segment-1710467073599711000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this? Trying to recover...\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_content_searchable/segment-1710467073577377000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_type_searchable/segment-1710467073617946000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_type_searchable/segment-1710467073631654000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_path_searchable/segment-1710467073624526000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_last_modified_date_searchable/segment-1710467073556928000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property_file_name_searchable/segment-1710467073599711000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"AdvancedRetrieval\",\"index\":\"advancedretrieval\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate/advancedretrieval/Zh1qQwS9unfU/lsm/property__node_content_searchable/segment-1710467073577377000.wal\",\"shard\":\"Zh1qQwS9unfU\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard advancedretrieval_Zh1qQwS9unfU in 52.73375ms\",\"time\":\"2024-03-16T23:28:56+05:30\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-03-16T23:28:56+05:30\",\"took\":28638125}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "# Connect to your Weaviate instance\n",
    "client = weaviate.Client(\n",
    "    embedded_options=weaviate.embedded.EmbeddedOptions(), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:692: ResourceWarning: unclosed event loop <_UnixSelectorEventLoop running=False closed=False debug=False>\n",
      "  _warn(f\"unclosed event loop {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=127>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=120>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=135>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=138>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=139>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=142>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=143>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=121>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=124>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=137>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=144>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=148>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=147>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=150>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 86.20%, threshold set to 80.00%\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate\",\"time\":\"2024-03-16T23:29:26+05:30\"}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "\n",
    "index_name = \"AdvancedRetrieval\"\n",
    "\n",
    "# Construct vector store\n",
    "vector_store = WeaviateVectorStore(\n",
    "    weaviate_client = client, \n",
    "    index_name = index_name\n",
    ")\n",
    "\n",
    "# Set up the storage for the embeddings\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Setup the index\n",
    "# build VectorStoreIndex that takes care of chunking documents\n",
    "# and encoding chunks to embeddings for future retrieval\n",
    "index = VectorStoreIndex(\n",
    "    nodes,\n",
    "    storage_context = storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is covid19 and how it affected in southafrica?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kinugawa and Tsuruoka [19] presented a hierarchical encoder-decoder extractive summarizer for academic papers. Collins et al. [15] released a benchmark dataset for summarization of computer science publications named CSPubSum, developed a supervised extractive summarization approach, and proposed a new metric named AbstractROUGE. Yang et al. [20] leveraged data-weighted reconstruction to amplify a scientific paper's abstract. They conducted experiments on the real dataset (AAN 2 and Microsoft datasets 3 ) to confirm the effectiveness of their approach. With the release of the COVID-19 Open Research Dataset (CORD- 19) 4 , researchers began to study automatic text summarization of COVID-19 medical research papers [21] [22] [23] [24] . Park [23] proposed a Continual BERT for extractive summarization of COVID-19 literature. Su et al. [21] obtained a ranked list of relevant snippets from the COVID-19 literature given a query and then extracted the top-ranked relevant results to generate summaries.Different from extractive summarization methods, abstractive summarization methods involve understanding of the content in the original documents, and they aim to create a new paragraph by using natural language generation to summarize the original document. Normally, abstractive summarization methods are more difficult and complex than extractive summarization methods, but they can produce a more flexible and concise summary. Alambo et al. [25] proposed to generate an abstractive summary of a scientific paper by developing salient language unit selection and text generation techniques. Recently, neural methods have led to encouraging results in abstractive summarization [1, 6, 26] . However, these methods focus on summarizing news articles which are relatively short. Researchers began to study neural abstractive summarization approaches for scientific papers. Nikolve et al. [27] is among the first to consider supervised generation of the abstract directly from the full body of the paper. They applied a convolutional encoder-decoder model [28] on PubMed open access subset 5 to perform abstract generation task. Cohan et al. [29] proposed a discourse-aware attention model, which consists of new hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder, to generate abstractive summaries of scientific papers. Ju et al. [30] presented a modified unsupervised pipeline architecture, SciSummPip, that leverages a transformer-based language model for summarizing scientific papers. Tan et al. [22] adopted BERT [31] and GPT-2 [32] to generate abstractive summaries based on CORD-19 dataset. Esteva et al. [24] took BERT as the encoder and extended the original GPT-2 by adding a cross-attention function alongside every existing self-attention function as the decoder, to generate a single abstractive summary for CORD-19 document dataset.Many NLG tasks need to better understand global context under a particular generation process. For example, the summarization task requires structured representation to facilitate the connection of relevant entities, and the preservation of global context (e.g., entity interactions) [33] [34] . In order to help NLG, graph-to-sequence (Graph2Seq) models encode the full structural information contained in the graph via a neural encoder-decoder architecture [35] . Zhu et al. [36] extracted factual relations from the article to build a knowledge graph and applied graph attention networks (GAT) [10] to obtain the representation of each node. Then they proposed a Factual Corrector (FC) model to generate abstractive summaries with higher factual correctness. Huang et al. [33] proposed a knowledge graph-augmented abstractive summarization approach, which encodes each paragraph as a sub-KG using GAT and connects all sub-KGs with a Bi-LSTM. Jin et al. [37] proposed a novel model SemSUM, which leverages the information of original input texts and corresponding semantic dependency graphs to guide abstractive summarization process.Pre-trained language models (PTMs) [38] [39] [40] [41] have achieved significant improvements for a wide range of natural language processing (NLP) tasks. Peters et al. [38] developed Embeddings from Language Models (ELMo), an approach to learn contextualized word representations by training a bidirectional LSTM to optimize a disjoint bidirectional language model objective. Radford et al. [39] proposed to improve language understanding by Generative Pre-Training (GPT), which uses a combination of unsupervised pre-training and supervised fine-tuning. Devlin et al.\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "# The target key defaults to `window` to match the node_parser's default\n",
    "postproc = MetadataReplacementPostProcessor(\n",
    "    target_metadata_key=\"window\"\n",
    ")\n",
    "\n",
    "...\n",
    "\n",
    "senetencewindowretriever = index.as_query_engine( \n",
    "    node_postprocessors = [postproc],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = senetencewindowretriever.query(\n",
    "    \"What is covid19 and how it affected in southafrica?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COVID-19 is a widespread pandemic caused by the coronavirus disease 2019. In South Africa, COVID-19 has had a case fatality rate of approximately 2%. The pandemic has not only led to physical morbidity and mortality but has also posed threats to the mental health of the population. The impact of COVID-19 in South Africa includes strict measures such as hygiene routines, self-isolation, quarantine, movement restrictions, and social distancing being implemented to reduce transmission rates. Additionally, the pandemic has disrupted traditional practices related to caring for the sick and rituals surrounding death, leading to challenges in bereavement and emotional support for families.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Abstractive summarization methods involve understanding the content in the original documents and aim to create a new paragraph using natural language generation to summarize the document. On the other hand, extractive summarization methods select and compile existing sentences or phrases from the original document to create a summary without altering the content. Abstractive methods are typically more complex as they require generating new content, while extractive methods are considered simpler as they rely on selecting and rearranging existing content.', source_nodes=[NodeWithScore(node=TextNode(id_='b87aa059-4713-43be-8559-093e8fd69090', embedding=[-0.026365748, 0.021204561, 0.021354754, -0.022720147, -0.0019098441, 0.017272228, -0.0005188495, 0.0019286183, -0.011066514, -0.054397278, -0.00052482315, 0.052622266, -0.014282016, 0.009564581, -0.016234528, 0.0042429604, 0.020986097, 0.0032752375, 0.0010411126, -0.023225343, -0.017886655, 0.0029936251, -0.025355358, -0.0059326347, -0.0033571613, 0.021668795, 0.022556301, -0.03681101, -0.009134483, 0.009223233, 0.002109533, 0.002234125, 0.0053455154, -0.013162393, -0.012090559, 0.0042088255, 0.002730787, -0.015278753, 0.010929975, -0.018637622, 0.013735859, 0.0140225915, -0.011230362, -0.01271864, -0.0074004326, -0.0076052416, 0.020071285, -0.029956734, -0.01699915, 0.005622008, 0.017927617, 0.03552754, -0.022938611, -0.0038265153, -0.032523673, -0.008390343, 0.0040108436, 0.015360677, -0.006915718, -0.0071546617, 0.047788773, -0.008117264, -0.014937405, 0.019019932, -0.0069054775, -0.022747455, -0.03129482, -0.00040215105, 0.004396567, -0.008683902, 0.02224226, 0.023402844, 0.0011426636, 0.0040893536, 0.030721353, 0.00037718995, -0.016057028, 0.0021624418, -0.021177253, 0.012445562, 0.0069054775, -0.0029509566, 0.012261233, -0.0018671756, 0.024071887, 0.0077213002, 0.003246223, 0.008506401, -0.005871192, -0.012862006, 0.010568146, 0.02519151, 0.015073944, 0.005956529, -0.010356509, 0.033670604, -0.01287566, 0.025082279, -0.00085550436, -0.023757847, -0.020794943, 0.00018006127, -0.02370323, -0.019839168, -0.028372876, 0.013039508, 0.027403448, -0.0015539884, 0.0033742287, 0.010028815, -0.0019815273, 0.026119977, -0.009974199, -0.042136043, 0.0033622815, 0.0006541088, 0.02897365, 0.0029577836, -0.0071137003, -0.009933238, 0.018473774, 0.029274037, 0.016630493, -0.021914566, 0.02748537, -0.005236284, -0.0048676278, -0.001785252, 0.0048300796, -0.020822251, -0.0018552284, 0.021941874, 0.012971238, 0.012984892, -0.0015121733, 0.03640139, -0.00016662067, -0.01112113, -0.03716601, -0.029683655, 0.009182272, 0.016016066, -0.0023467701, -0.015196829, -2.8374583e-05, 0.019443203, 0.02633844, 0.008492747, 0.022843033, 0.008697556, 0.014596056, -0.018405505, -0.021218214, 0.019306663, 0.017995887, -0.0056288345, 0.043282975, 0.01686261, -0.011865269, 0.017900309, 0.0039562276, 0.017531652, 0.002333116, -0.0051884954, 0.002519151, 0.032987908, 0.0039903624, -0.007714473, 0.00018102131, -0.02224226, -0.0018484014, 0.033670604, -0.019975707, 0.02338919, -0.0030192262, 0.009066213, 0.022815725, 0.019634359, -0.028782494, -0.030339044, 0.002333116, 0.0142274005, 0.00634908, 0.022938611, -0.0021385476, -0.020030322, 0.012800564, -0.0055981134, 0.00034710864, -0.009482658, 0.017709153, 0.014691634, 0.00992641, -0.019402241, -0.6374749, -0.015347023, -0.0006481352, -0.026283825, 0.008151399, 0.00522263, 0.0030653083, -0.0114693055, 0.0033622815, 0.043911055, -0.0118789235, -0.018105118, 0.0122885415, -0.013387683, -0.016193567, -0.016876264, -0.020904174, -0.01163998, 0.03618293, 0.03730255, -0.039296024, 0.030147888, -0.027471717, -0.0083630355, -0.0116741145, 0.005089504, -0.006195473, -0.009148137, 0.028645955, 0.018350888, -0.032769445, 0.010731993, 0.021245522, -0.01998936, 0.048935704, -0.0025106173, -0.0076325494, 0.019866476, 0.017777422, 0.036346775, -0.017859347, -0.023361882, 0.007762262, 0.004635511, -0.008219669, 0.019074546, 0.004184931, -0.00017067419, 0.0043214704, -0.010199489, -0.018801467, 0.002565233, -0.0076530306, -0.023798808, 0.00961237, 0.024986701, 0.03459907, -0.053386886, 0.016971841, -0.015114906, 0.022788417, 0.016330106, -0.007100046, -0.02911019, -0.024549775, 0.027840374, 0.0032820646, 1.3393923e-05, 0.004509212, -0.02699383, -0.008042168, 0.013558357, -0.004263441, -0.037220627, 0.0059189806, 0.008820442, 0.003140405, -0.00884775, -0.001028312, 8.3417006e-05, 0.019252049, 0.00032918784, -0.017272228, -0.0013875811, -0.005502536, -0.005878019, -0.036838315, 0.004925657, 0.005970183, -0.00048002115, 0.01717665, 0.019320318, -0.024781892, -0.029956734, -2.7014523e-05, 0.010759301, -0.006311531, -0.0067860056, 0.018050501, -0.027649218, -0.0127459485, -0.023675922, 0.0035397827, -0.013578838, 0.015387985, 0.0013329653, 0.012896141, -0.017640883, 0.025792282, -0.0112167075, -0.003317906, 0.002031023, 0.0051065716, -0.00026283824, 0.02095879, -0.024973046, 0.020480903, -0.01607068, -0.004833493, -0.02147764, 0.00011083155, 0.0069088913, 0.0068235537, -0.0022221778, -0.000113284994, 0.026461326, 0.0035739176, -0.021600526, -0.009967373, -0.016507607, -0.011189399, -0.017599922, 0.015183176, -0.005215803, 0.029246729, -0.0040244972, 0.013257971, 0.0021146531, 0.0015164402, -0.022133028, -0.028755186, -0.0122885415, 0.015838565, 0.009025251, -0.023034189, -0.01825531, -0.0021709756, 0.014309323, 0.013476433, -0.0032735309, -0.023989964, -0.006570956, 0.0013201648, -0.0048573874, -0.0031591791, -0.019333972, 0.015811257, -0.03498138, -0.007291201, -0.01794127, 0.016671455, 0.030093273, -0.010889013, -0.0058814324, -0.005045129, 0.0022119374, 0.003119924, 0.020549173, -0.017203959, -0.032987908, 0.005652729, -0.029055573, -0.0057995087, 0.02581959, -0.01436394, 0.027499026, -0.012117867, -0.010049296, 0.003754832, -0.01269816, -0.0013304052, 0.011428343, 0.0060452796, -0.0027563882, 0.018473774, 0.01755896, -0.0049939267, -0.0101517, -0.0026881185, 0.013005373, 0.020617442, 0.0025635262, -0.0055059493, 0.027348831, -0.00080302206, 0.012739121, 0.0131555665, 0.0065402347, 0.0051543606, 0.022542646, 0.0069259587, 0.010520357, -0.004509212, -0.01832358, 0.011803826, 0.0006848302, 0.008888711, -0.016971841, 0.0021675623, -0.01436394, 0.011967674, -0.011749211, -0.037876014, -0.0003974575, -0.012076905, 0.03102174, -0.002473069, 0.012657197, -0.016057028, -0.0014899856, 0.013804128, -0.017777422, 0.02179168, -0.0036319466, -0.0073662978, 0.014473171, -0.00017984792, 0.018801467, 0.01825531, -0.022979572, -0.00033836157, 0.001619698, 0.041835655, 0.006816727, 0.016698763, 0.008328901, 0.010056123, -0.01776377, 0.03421676, 0.0072707203, -0.012500177, 0.0061272033, 0.010117565, -0.024167465, 0.027649218, -0.008438132, 0.028236337, 0.00066733605, -0.006273983, -0.01474625, -0.025082279, 0.025027663, -0.0044204616, 0.016261837, 0.017859347, -0.009400734, -0.0023860252, -0.0029816781, 0.035309076, 0.03462638, 0.0064036953, -0.022433415, -0.005372823, 0.0018364543, 0.024631698, -0.028946342, -0.014568749, -0.00916179, -0.00968064, -0.010301894, -0.031977516, -0.021682449, 0.0058882595, -0.011844789, 0.020180516, 0.027635565, -0.017572613, 0.006704082, 0.0262019, 0.041507963, -0.038667943, -0.044648368, 0.032332517, -0.012233926, -0.0080012055, -0.01287566, -0.026515942, -0.013353548, -0.03615562, -0.02300688, -0.001097435, -0.0012152002, -0.013223836, 0.0013739272, -0.031349435, 0.01974359, 0.026324786, -0.0010803676, -0.007557453, 0.017081073, 0.00048812816, -0.00050988916, -0.024727276, -0.017599922, 0.047515694, -0.028564032, -0.020030322, -0.0017016216, -0.0072775474, -0.01204277, 0.02363496, 0.010499876, 0.0026591038, 0.013428645, 0.0010419659, 0.004055219, -0.0017562374, 0.011913058, 0.018105118, 0.0032172084, 2.401439e-05, -0.02289765, -0.0005525577, -0.0005192762, 0.04729723, 0.054397278, -0.028017875, 0.024331313, 0.013612973, 0.0052533513, -0.029574422, -0.010691031, -0.012500177, -0.008970635, -0.03320637, -0.03293329, 0.020016668, 0.02158687, 0.01346278, 0.0035124747, -0.014541441, -0.017900309, 0.007919283, -0.0019798207, -0.0049734456, 0.013182874, 0.015292407, 0.028755186, 0.016480299, -0.009127655, 0.028017875, 0.025669398, 0.009851314, -0.026543248, -0.0141181685, 0.02192822, 0.0074823564, 0.024659006, 0.00049196836, 0.0046389243, 0.025273433, 0.009428042, 0.01557914, 0.008601979, 0.019388588, 0.014759904, 0.012704986, 0.00077102066, 0.020139555, -0.035063304, -0.002130014, 0.020863213, -0.008028514, -0.033424832, 0.0037514186, -0.015183176, -0.019593397, -0.024959393, 0.010977764, -0.008246977, -0.0065299943, 0.008178707, -0.013196528, -0.0068781697, -0.006386628, -0.017217612, -0.002029316, -0.0073594707, -0.012773256, 0.01006295, 0.007919283, -0.00855419, -0.009154963, 0.03626485, -0.00081027567, -0.015360677, -0.044402596, 0.01589318, 0.003213795, 0.029902117, 0.018405505, -0.01443221, -0.008547363, -0.01105286, -0.0051441197, -0.009885449, 0.0017289295, -0.04243643, 0.00015083331, -0.011646806, -0.02192822, -0.008677076, -0.0060794144, 0.016220875, -0.0012023996, -0.00010619134, -0.0039596413, 0.015251446, 0.012070078, 0.030393658, 0.016084336, 0.011387382, 0.02050821, -0.023170728, 0.005116812, -0.019197432, -0.01960705, -0.029902117, 0.018678583, -0.015415292, 0.010704685, 0.021559563, 0.023198035, -0.017572613, 0.017873, -0.007536972, -0.0074823564, 0.007871494, 0.015428946, 0.012848353, 0.019893782, 0.012233926, 0.0036046389, -0.026393056, -0.020289747, -0.010315548, 0.027990567, 0.026379403, -0.011810654, 0.040989112, -0.025805937, -0.018569352, -0.031240202, -0.010465741, -0.026898252, 0.03181367, -0.01738146, -0.007141008, -0.04593184, 0.009912756, 0.010472568, 0.0050690235, -0.02307515, -0.0083630355, 0.017709153, -0.0012587222, -0.0086634215, 0.014159131, 0.020139555, -0.026870944, -0.023375537, 0.027608257, 0.006499273, 0.014937405, -0.008683902, 0.008977463, -0.018897045, -0.016671455, 0.0055127763, -0.033943683, -0.0010803676, 0.018705891, 0.04074334, 0.019975707, 0.058875766, 0.002584007, 0.025778629, 0.026625173, -0.011756038, -0.0010709806, -0.009946891, 0.013769994, -0.017231265, -0.0260244, 0.014036245, -0.01166046, -0.0076530306, -0.008786307, 0.008342554, -0.008233323, 0.005482055, -0.021982836, -0.007373125, -0.025273433, -0.040852573, 0.030694045, 0.00839717, 0.02289765, -0.045194525, 0.0010479395, 0.027990567, 0.013196528, 0.021450331, -0.007960244, 0.032223288, 0.0021658554, -0.005454747, 0.00040215105, 0.003833342, -0.010813916, 0.016780686, -0.03115828, -0.010138047, 0.027567295, 0.0070590843, 0.015265099, 0.025846899, -0.0034100702, 0.018897045, 0.006366147, 0.018064156, -0.009578235, 0.0023262892, -0.020726673, -0.02190091, -0.029547116, -0.0039050253, 0.000355429, -0.015838565, 0.003655841, -0.0072024507, 0.02793595, -0.02345746, -0.03216867, 0.00392892, 0.019948399, 0.045412987, 0.0049393107, 0.010499876, 0.02179168, 0.0006058934, -0.0068542752, -0.0071887965, -0.003490287, -0.01794127, 0.009810352, 0.021286484, -0.016261837, -0.005946289, 0.0064617246, 0.012233926, -0.016685108, -0.02595613, 0.022911303, 0.0074823564, 0.011025553, -0.0137085505, 0.0037821399, -0.022160336, 0.004191758, -0.028127106, -0.002213644, 0.005567392, -0.0036592546, 0.006837208, 0.019907437, -0.0051748413, 0.019907437, -0.00242016, -0.018856084, 0.013947494, -0.016289145, -0.010185835, 0.007311682, -0.00048300796, 0.023880731, -0.014404901, 0.00025878474, 0.013380856, 0.00959189, 0.011291804, 0.011680941, -0.014077207, 0.034544457, -0.020153208, -0.024058234, 0.008438132, 0.005946289, 0.0018893633, -0.008042168, -5.7015845e-05, -0.03432599, -0.018350888, -0.004099594, 0.015087598, -0.01377682, -0.0048949355, 0.009434869, 0.0044204616, 0.0011307165, -0.006717736, -0.023798808, -0.00817188, -0.05010994, -0.024781892, -0.006789419, 0.007216105, 0.01897897, -0.0052465242, 0.019197432, -0.008185534, 0.039377946, -0.036892932, -0.01112113, 0.002213644, -0.011046033, -0.012493351, 0.00027819892, -0.009400734, -0.009482658, 0.032632906, -0.027048444, -0.035281766, 0.0047310884, -0.0044341153, 0.015906835, 0.004464837, -0.011578537, 0.010158528, -0.018760506, 0.00017238093, -0.006434417, -0.011578537, 0.019374933, -0.002584007, -0.0045979624, 0.03418945, -0.023744192, 0.01710838, -0.011824308, 0.0054854685, -0.016220875, -0.058602687, -0.02300688, -0.00012491217, 0.016248183, -0.016985495, 0.00871121, 0.006106722, -0.005540084, -0.0044989716, 0.009830833, 0.020317055, -0.011803826, -0.0023860252, -0.015087598, 0.0044921446, -0.010090258, -0.027034791, -0.008260631, -0.009892276, 0.010991418, -0.019880129, -0.008656595, -0.0034322578, 0.04593184, -0.0041303155, -0.027348831, -0.025614781, -0.0027273735, -0.05024648, -0.010213143, -0.014541441, 0.013107778, 0.035281766, 0.010574972, 0.014882789, 0.028946342, -0.015565486, 0.008581498, -0.009796699, 0.013769994, 0.013292106, -0.011407862, -0.023539383, -0.017340498, -0.03195021, -0.011462478, 0.018023195, -0.0011452237, -0.008526882, 0.034025606, -0.0016342053, -0.0040347376, -0.0074550486, 0.014896443, 0.008697556, -0.021423023, 0.028536724, -0.03828563, -0.009666986, 0.015674718, -0.0016077508, -0.00400743, -0.01157171, 0.0026352094, 0.0045126253, 0.009830833, -0.0062057134, -0.027990567, 0.0038981985, -0.0069327853, 0.012998546, 0.010165354, -0.014241054, 0.021013405, 0.021614179, 0.0049393107, -0.029820194, 0.012363638, 0.011284977, -0.0027717487, 0.02807249, 0.0063285986, -0.00574148, -0.022952264, 0.004509212, 0.00438974, 0.00027265202, 0.003748005, -0.013073643, -0.03129482, 0.026652481, 0.018610314, -0.03154059, -0.00959189, 0.0058848457, -0.017203959, 0.002399679, -0.0015932436, 0.0022170576, -0.028400185, 0.0189107, -0.0035773308, -0.009762564, 0.009967373, -0.018105118, 0.014200092, -0.018091464, 0.0053079673, 0.1849289, -0.026570557, 0.011312285, 0.017586268, -0.022378799, -0.01800954, 0.023184381, 0.030175196, -0.028209029, -0.0008418504, 0.016521262, -0.0055981134, -0.023088804, -0.0015480148, 0.023047842, 0.0073594707, -0.03410753, -0.020262439, -0.024822854, -0.0023194621, -0.015906835, -0.028809803, -0.011708249, -0.019525127, 0.016780686, 0.0013517395, -0.010520357, -0.021423023, 0.019525127, 0.0045194523, -0.0043078163, 0.00507585, 0.0042429604, 0.0037718995, -0.023935348, -0.003853823, 0.01904724, -0.002275087, 0.01755896, 0.0019610464, 0.014473171, -0.012022289, -0.0044784904, -0.021641487, -0.004826666, 0.011680941, 0.0016785807, -0.000514156, -0.007666684, 0.011653634, -0.027403448, 0.008588325, 0.028536724, 0.025041316, -0.0045057987, -0.008349381, 0.010506703, 0.030666737, 0.027772104, 0.0105818, -0.031704437, 0.0005760254, -0.010786609, 0.015046637, -0.009332464, 0.019170124, 0.007550626, 0.005205563, 0.00871121, -0.007864666, -0.015387985, -0.039186794, -0.022720147, 0.0023672509, -0.03476292, -0.025628436, 0.056909602, 0.015838565, 0.024099195, 0.036619853, -0.003590985, 0.005652729, -0.017040111, 0.0012954171, -0.00016896744, -0.05207611, 0.002392852, -0.005891673, -0.013783648, -0.02210572, -0.01602972, -0.014951059, -0.008752172, -0.00040129767, 0.014268362, -0.017913962, -0.0031642993, 0.0016572464, 0.015306061, -0.013148739, -0.016848955, 0.073512785, 0.018214349, -0.008704384, 0.0122885415, 0.0024508813, -0.019443203, -0.01800954, 0.019948399, -0.0043692593, 0.013196528, -0.04448452, 0.0046969536, 0.007134181, -0.008704384, 0.0068713427, 0.009673812, -0.0066289855, 0.014473171, 0.0011554642, -0.017736461, -0.037739474, -0.003317906, 0.0006690428, 0.008165053, -0.006717736, 0.010609107, -0.0033759354, -0.02911019, 0.006553889, 0.015483562, -0.022119375, 0.021204561, 0.006444657, 0.004591136, -0.01762723, -0.0035090612, 0.006646053, -0.015592794, 0.006980574, -0.0049290704, 0.0019217914, 0.018760506, 0.0079056285, 0.009339292, -0.0068235537, 0.010042469, 0.0026215555, -0.0078100506, -0.019402241, -0.013210182, -0.014650672, -0.0060998956, -0.0017494104, 0.017736461, -0.015046637, -0.017135689, 0.004014257, -0.013940668, -0.006690428, -0.029028265, -0.001233121, 0.017203959, -0.020617442, -0.009878621, -0.03181367, -0.17422421, 0.009762564, -0.004741329, -0.038039863, 0.01269816, 0.020412633, 0.025109585, -0.007100046, -0.0039767087, -0.009728429, 0.02998404, -0.010861705, -0.041999504, -0.016726071, -0.020494556, 0.0021658554, -0.025273433, 0.013285278, 0.030175196, 0.03970564, 0.035363693, -0.03667447, 0.0047686365, -3.5628236e-05, 0.023334574, 0.0051407064, -0.011680941, 0.012998546, -0.017026456, -0.015524524, 0.0037411782, -0.002578887, -0.0025328049, -0.009352946, 0.00074541953, 0.009482658, 0.009428042, -0.0069327853, -0.008950154, 0.030830584, 0.027894989, 0.012691332, 0.006301291, -0.011517094, -0.013203355, 0.012821045, 0.01679434, -0.024577083, -0.002360424, -0.019661667, -0.017982231, -0.0018142666, 0.019511472, 0.0062091267, -0.012664025, 0.016644146, 0.025409972, -0.004632097, -0.002459415, -0.016097989, -0.00310115, -0.014841828, 0.015469908, 0.011018725, -0.012152002, -0.013585665, -0.0039186794, 0.00853371, -0.036073696, 0.007584761, -0.02474093, 0.012670851, -0.0027990567, -0.008629287, 0.0065811966, 0.031458665, -0.023689577, 0.0055946996, 0.026038054, -0.014691634, -0.016534915, 0.013810955, -0.008124092, -0.0033964163, 0.010800263, 0.004836906, 0.012759602, -0.0128415255, -0.0073594707, -0.020016668, 0.026556903, -0.0013577131, 0.031759053, -0.0021982836, -0.005792682, 0.0024918432, -0.0014695048, 0.0021658554, 0.011080168, 0.00065581553, 0.010622761, 0.010950455, -0.002300688, -0.0058097495, 0.037985247, 0.012766429, -0.016848955, 0.014459517, 0.040197182, -0.011134784, -0.012752775, -3.5628236e-05, 0.014896443, -0.008854576, 0.0071137003, 0.03692024, -0.026816327, -0.0010718339, 0.03413484, -0.033943683, 0.0298475, -0.006816727, -0.0005755987, 0.00037612324, -0.03091251, -0.027635565, -0.117642306, 0.0121315215, 0.00446825, 0.015920488, -0.024249388, 0.019784551, -0.015852218, 0.025764976, -0.0041303155, 0.027430754, -0.02987481, -0.007325336, 0.022802072, -0.008997943, 0.040552188, -0.00461503, 0.0048642145, -0.02512324, -0.005215803, 0.03836756, -0.0026591038, -0.013025854, 0.032987908, -0.005581046, 0.0030038657, 0.017354151, -0.030721353, 0.041453347, 0.0028417252, -0.003935747, 0.017094726, -0.0176955, 0.013640281, -0.02321169, -0.0116741145, -0.018036848, -0.017094726, -0.018050501, 0.005700518, -0.022610916, 0.0032632905, 0.0042088255, 0.026966522, 0.0046184435, -0.019320318, -0.008492747, -0.016480299, 0.032250594, 0.010909494, -0.030420966, -0.029246729, -0.025833245, -0.016316453, -0.00020299561, 0.015865872, 0.010301894, 0.01960705, -0.007837359, 0.009557755, -0.02314342, -0.017927617, -0.009598716, -0.015565486, 0.00014517973, 0.019593397, -0.0030584815, -0.006598264, -0.024563428, -0.010527183, -0.019593397, -0.004355605, 0.0029475433, -0.022051105, 0.011803826, -0.0074413945, -0.007816878, -0.024112849, -0.032605596, 0.011380555, -0.019525127, -0.008117264, -0.007625723, -0.011046033, -0.012349984, 0.0017331963, 0.01105286, -0.010752474, -0.019074546, 0.01474625, -0.03216867, 0.02282938, 0.04011526, -0.0076871654, -0.014828173, 0.006195473, 0.00010965816, -0.00317454, 0.011994982, -0.007052257, 0.0074823564, -0.020112246, 0.004963205, -0.05843884, 0.025300741, 0.012807391, -0.02519151, -0.013237489, -0.008267458, 0.0084108235, -0.0038128614, -0.01163998, 0.0021726824, -0.033124447, -0.0025618195, -0.016562223, -0.004150796, -0.026188247, -0.02769018, 0.015019328, -0.013967975, 0.02505497, 0.0077213002, -0.015606447, 0.022911303, -0.00021206267, 0.030857893, -0.025095932, -0.001180212, -0.0013867278, 0.035472922, 0.005157774, -0.023170728, 0.0054581603, -0.024891123, -0.0003360148, 0.010998244, 0.011155264, 0.015374331, 0.009673812, 0.016125297, 0.01884243, 0.06319041, -0.019511472, -0.016521262, 0.004304403, 0.0022767936, -0.006642639, 0.0050348886, -0.014282016, 0.0029048747, 0.0037514186, -0.0031506454, 0.030284427, 0.0237715, 0.005857538, -0.028400185, 0.008786307, 0.019579742, 0.012889314, 0.0058541247, -0.0069191316, -0.028482107, 0.016780686, 0.00454676, 0.022569954, 0.012240753, 0.0013824609, -0.016603185, -0.03347945, -0.012609409, -0.0006515487, -0.021832641, -0.012302196, -0.0025805936, 0.0018620554, 0.038941022, 0.0062910505, -0.002882687, -0.022310529, 0.017408768, -9.583756e-07, 0.028673263, 0.0010180715, -0.01992109, 0.002155615, -0.0013542997, 0.03410753, 0.0059599425, -0.017299535, 0.010431606, -0.017190304, 0.007379952, 0.020644749, 0.0043590185, 0.0041883443, 0.03563677, -0.015278753, 0.0012834698, -0.001916671, -0.021450331, 0.029765578, 0.02883711, 0.0050280616, 0.0041746907, -0.005406958, -0.0085678445, -0.00028395918, 0.0052260435, -0.03476292, -0.02737614, 0.013298932, 0.023594, 0.013517396, 0.0143229775, -0.009380253, 0.005294313, -0.022979572, 0.0125889275, 0.00035436227, -0.02102706, -0.02755364, 0.009182272, 0.0074345674, -0.0031113904, 0.050819945, -0.0052123894, 0.0079534175, 0.015906835, 0.021122636, -0.012124694, 0.028045183, -0.0057551335, -0.015797602, 0.018473774, 0.0001173385, -0.010943629, 0.003894785, -0.005997491, -0.0070659113, 0.012814218, 0.015852218, 0.06635813, 0.049072243, -0.01960705, 0.0021778026, -0.024549775, 0.01105286, 0.014145477, 0.0070044687, -0.01706742, 0.0006003464, 0.007386779, -0.0015548419, -0.0017818385, -0.031212894, -0.0063354257, -0.01949782, 0.011305458, 0.039569102, -0.0027188398, 0.008240149, 0.029956734, -0.01776377, 0.023921695, 0.003945987, -0.035090614, -0.011093822, 0.027731141, 0.000325561, 0.008642941, -0.024112849, 0.018924354, 0.022296876, -0.023853425, -0.018023195, 0.0040791132, 0.01082757, -0.009175444, -0.014637019, 0.014131823, 0.015906835, 0.019402241, 0.0008004619, -0.020835904, -0.016316453, -0.003874304, -0.0082060145, -0.027348831, -0.009284676, -0.011148438], metadata={'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e21f0455-dd6d-44cf-8b58-a8eab2c403e6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}, hash='6f498b28779fb8c46147671c647449cd0b8a88922e1636f41b7a00bb911948fd'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='593d07b4-521c-4812-bc5b-1b1cf57a795c', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}, hash='3396acbe5a4982cd8d7668ec5c0d10c887627008fdebef5c7f2de0447479b0b6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3f2a3c20-f034-481e-8926-5b3ff46ef7c1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='db22c756320383478b32113bb6e858f83a15e439c97e8af0c93bf1514649506b')}, text=\"Kinugawa and Tsuruoka [19] presented a hierarchical encoder-decoder extractive summarizer for academic papers. Collins et al. [15] released a benchmark dataset for summarization of computer science publications named CSPubSum, developed a supervised extractive summarization approach, and proposed a new metric named AbstractROUGE. Yang et al. [20] leveraged data-weighted reconstruction to amplify a scientific paper's abstract. They conducted experiments on the real dataset (AAN 2 and Microsoft datasets 3 ) to confirm the effectiveness of their approach. With the release of the COVID-19 Open Research Dataset (CORD- 19) 4 , researchers began to study automatic text summarization of COVID-19 medical research papers [21] [22] [23] [24] . Park [23] proposed a Continual BERT for extractive summarization of COVID-19 literature. Su et al. [21] obtained a ranked list of relevant snippets from the COVID-19 literature given a query and then extracted the top-ranked relevant results to generate summaries.Different from extractive summarization methods, abstractive summarization methods involve understanding of the content in the original documents, and they aim to create a new paragraph by using natural language generation to summarize the original document. Normally, abstractive summarization methods are more difficult and complex than extractive summarization methods, but they can produce a more flexible and concise summary. Alambo et al. [25] proposed to generate an abstractive summary of a scientific paper by developing salient language unit selection and text generation techniques. Recently, neural methods have led to encouraging results in abstractive summarization [1, 6, 26] . However, these methods focus on summarizing news articles which are relatively short. Researchers began to study neural abstractive summarization approaches for scientific papers. Nikolve et al. [27] is among the first to consider supervised generation of the abstract directly from the full body of the paper. They applied a convolutional encoder-decoder model [28] on PubMed open access subset 5 to perform abstract generation task. Cohan et al. [29] proposed a discourse-aware attention model, which consists of new hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder, to generate abstractive summaries of scientific papers. Ju et al. [30] presented a modified unsupervised pipeline architecture, SciSummPip, that leverages a transformer-based language model for summarizing scientific papers. Tan et al. [22] adopted BERT [31] and GPT-2 [32] to generate abstractive summaries based on CORD-19 dataset. Esteva et al. [24] took BERT as the encoder and extended the original GPT-2 by adding a cross-attention function alongside every existing self-attention function as the decoder, to generate a single abstractive summary for CORD-19 document dataset.Many NLG tasks need to better understand global context under a particular generation process. For example, the summarization task requires structured representation to facilitate the connection of relevant entities, and the preservation of global context (e.g., entity interactions) [33] [34] . In order to help NLG, graph-to-sequence (Graph2Seq) models encode the full structural information contained in the graph via a neural encoder-decoder architecture [35] . Zhu et al. [36] extracted factual relations from the article to build a knowledge graph and applied graph attention networks (GAT) [10] to obtain the representation of each node. Then they proposed a Factual Corrector (FC) model to generate abstractive summaries with higher factual correctness. Huang et al. [33] proposed a knowledge graph-augmented abstractive summarization approach, which encodes each paragraph as a sub-KG using GAT and connects all sub-KGs with a Bi-LSTM. Jin et al. [37] proposed a novel model SemSUM, which leverages the information of original input texts and corresponding semantic dependency graphs to guide abstractive summarization process.Pre-trained language models (PTMs) [38] [39] [40] [41] have achieved significant improvements for a wide range of natural language processing (NLP) tasks. Peters et al. [38] developed Embeddings from Language Models (ELMo), an approach to learn contextualized word representations by training a bidirectional LSTM to optimize a disjoint bidirectional language model objective. Radford et al. [39] proposed to improve language understanding by Generative Pre-Training (GPT), which uses a combination of unsupervised pre-training and supervised fine-tuning. Devlin et al.\", start_char_idx=4333, end_char_idx=8953, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8594198200000001), NodeWithScore(node=TextNode(id_='fc9a9139-df8c-43d3-a07b-3284bc7d71c2', embedding=[-0.01134552, 0.012940659, 0.012042962, -0.004650765, 0.011525059, 0.025052674, 0.015647564, -0.0069122734, -0.008921735, -0.04145983, 8.286442e-05, 0.038393848, -0.011663167, 0.014874162, -0.0208404, 0.0036840138, 0.031377994, 0.018147307, 0.017746795, -0.022221474, -0.02249769, -0.011842706, -0.03659845, -0.013382603, 0.003908438, 0.0109657245, 0.02720715, -0.022649607, -0.0016382985, 0.011014062, 0.012560864, 0.0034233362, -0.015081324, 0.004819947, -0.011787463, 0.011580302, 0.014183626, 0.00506854, 0.007243731, -0.026585666, 0.02985881, 0.015661374, -0.019984135, -0.013948843, 0.008265725, 0.008279536, 0.013658818, -0.018658305, -0.01462557, 0.023132984, 0.00816905, 0.024224032, -0.0048544738, 0.00025118276, -0.02081278, -9.137474e-06, 0.012070583, 0.020163674, -0.013175442, -0.0046921973, 0.030880805, -0.0068466724, -0.016766233, 0.0025170066, -0.0116424505, -0.02682045, -0.016780045, 0.01577186, -0.003392262, 0.011752936, 0.017387716, 0.024486436, -0.017484391, 0.003825574, 0.03115702, 0.0029485922, -0.03231712, -0.012118921, -0.0051410464, 0.008410738, 0.0006745681, -0.0036322235, -0.0027500628, 0.014653191, 0.026599478, 0.018741168, 0.013824547, 0.031654205, -0.012001529, 0.000595588, 0.02137902, 0.01061355, 0.021710478, 0.008983884, 0.006729281, 0.011138358, -0.0055208416, 0.01782966, 0.0062113786, -0.016572883, -0.01502608, -0.0047025555, -0.034582082, -0.014321733, -0.018672114, -0.008459075, 0.012837079, -0.0134447515, -0.0065152147, -0.0084521705, 0.009046032, 0.030079782, -0.009011505, -0.02513554, -0.012754215, -0.012988998, 0.028809195, 0.0021372114, -0.010862144, -0.014238869, -0.003801405, 0.01107621, 0.0028346535, -0.018174928, 0.033118144, -0.0048751896, -0.012471095, -0.016379533, 0.006225189, -0.028836817, 0.010116364, 0.015799481, 0.014294112, 0.013693345, 0.00041453788, 0.04068643, -0.012747309, -0.026806638, -0.020785159, -0.028809195, 0.020011757, 0.01332736, -0.00958465, -0.01744296, 0.008279536, 0.033725817, 0.025453186, 0.010820712, 0.011925571, -0.003974039, 0.019017383, -0.039885405, -0.0024617638, 0.021890016, 0.015039891, -0.000116528085, 0.028394872, 0.0043296656, -0.02043989, -0.0025308174, -0.00062666216, 0.030466484, 0.0036771086, -0.0016512461, 0.011462911, 0.020674672, 0.02383733, -0.0007725381, -0.0004553227, -0.0150537025, -0.015067513, 0.040796913, -0.007678769, 0.012788742, 0.008783628, 0.0037288987, 0.028698709, 0.0070434753, -0.026903315, -0.040465456, -0.0029106126, 0.02215242, 0.030825563, -0.00042640648, -0.0128647005, -0.010896671, 0.026502803, -0.011815084, 0.015039891, -0.0068225036, -0.0034854845, -0.00054379774, 0.008970073, -0.0061803046, -0.634189, -0.012837079, -0.00094776176, -0.0274005, 0.004112147, 0.00020295309, -0.0017073522, 0.012484905, 0.008714574, 0.05344755, -0.027455743, -0.021406641, 0.014984649, -0.00059299846, -0.015523267, -0.014183626, -0.01115217, -0.014473652, 0.003942965, 0.028643467, -0.037399475, 0.022387203, -0.03356009, 0.0031661112, -0.007333501, 0.00937749, 0.009121991, -0.03187518, 0.009771096, -0.0010772374, -0.026806638, 0.008735291, 0.025646538, -0.016738612, 0.053088468, -0.009771096, -0.00091755076, 0.014294112, 0.021972882, 0.022787714, -0.02063324, -0.0204537, -0.007651148, -0.007934268, -0.0055242945, 0.0038393845, -0.013375698, -0.0007949805, 0.01557851, -0.005113425, -0.017594878, -0.010081837, -0.00340262, -0.01575805, 0.014404598, 0.014515083, 0.03996827, -0.029582597, 0.01276112, -0.028588224, 0.013672628, 0.006760355, -0.0067258286, -0.024983622, -0.01577186, 0.019984135, -0.0052722483, -0.0088733975, 0.008300252, -0.030300755, 0.004384909, 0.00740946, -0.0022908559, -0.02195907, 0.0029675819, 0.016572883, 0.01153887, 0.0020060095, -0.013658818, 0.019114058, 0.015509456, -0.014901784, -0.021075184, 0.003549359, -0.017304853, -0.00019874513, -0.03284193, 0.022442445, -0.023630168, -0.015343728, 0.0061319666, 0.025246026, -0.019307408, -0.023892574, 0.022249095, 0.0060456498, 0.0032524283, 0.0052204584, 0.021365209, -0.031626586, -0.0069985907, -0.025176972, 0.01802301, -0.007374933, 0.023353955, 0.010275188, 0.007913551, -0.01689053, 0.014238869, -0.014169815, -0.0059317113, -0.0055864425, 0.0026102292, 0.006556647, -0.0047819675, -0.0266271, 0.009833244, 0.009405111, -0.009363679, -0.02085421, -0.00041194836, 0.013154726, -0.0003301629, -0.009722758, 0.0033093975, 0.016780045, 0.013002808, 0.0006240726, -0.020536564, -0.024886945, 0.00061846204, -0.017111503, 0.011262655, -0.016572883, 0.0114491, 0.013209969, 0.026129913, -0.0012809457, 0.0064392556, -0.02213861, -0.024445003, -0.004488489, 0.016103318, -0.02288439, -0.045464944, -0.015896156, -0.014390787, 0.007844498, 0.009632988, -0.01265754, -5.864168e-05, -0.016103318, 0.012208691, -0.0113524245, -0.01557851, -0.018423522, -0.008431454, -0.03129513, -0.011504343, -0.02382352, 0.009349869, 0.03397441, -0.001393158, 0.0062769796, -0.0063840128, -0.014860352, 0.013064956, 0.017360095, 0.0019904724, -0.028312009, 0.002993477, -0.028919682, -0.013272117, 0.0043883612, -0.00909437, 0.025107918, -0.038393848, 0.0073265955, -0.014010992, -0.021517126, 0.0018437332, 0.015329917, 0.0057521714, -0.006829409, 0.020384647, 0.02027416, 0.009957541, -0.011587207, -0.010516875, 0.016296668, 0.002563618, -0.0047750617, -0.009639894, 0.009363679, 0.00049287063, -0.0038946276, 0.025729401, -0.010634267, -0.008624804, 0.019031195, 0.034692567, 0.027662905, -0.0033594614, -0.01520562, 0.00047862832, 0.001640025, 0.016559072, -0.028974924, 0.011587207, -0.007078002, 0.008024038, -0.018851655, -0.03996827, 0.002311572, -0.010682604, 0.029693082, -0.004012019, 0.014929405, -0.006183757, 0.007858309, -0.0015312653, -0.016089508, 0.03093605, 0.012843984, 0.015840914, -0.0070227594, 0.0049856757, 0.01782966, 0.042730417, -0.004281328, 0.0035424537, 0.020329403, 0.03262096, 0.012519432, 0.0096122725, 0.0106756985, 0.012788742, -0.018064443, 0.015619942, -0.0008597183, -0.0008437497, 0.0014207795, 0.009840149, -0.021696666, 0.023699222, 0.0027742316, 0.034388732, -0.0058177724, -0.015343728, -0.0030711624, -0.007471608, 0.016186183, 0.0015234968, 0.013645007, 0.023657791, -0.02403068, 0.0041363155, 0.012595391, 0.03560408, 0.050795887, 0.0075751888, -0.023906384, -0.0039567756, -0.004087978, 0.02103375, -0.02252531, -0.00326106, -0.000583072, -0.018644493, -0.002140664, -0.023768276, -0.016089508, 0.023616359, -0.004391814, 0.016959583, 0.019196924, -0.018285414, -0.0049338853, 0.013368793, 0.05101686, -0.02947211, -0.028753953, 0.022028124, 0.004519563, -0.0015787397, 0.0042122747, -0.012906133, 0.00010665556, -0.0112557495, -0.0062079257, 0.0028657278, -0.011193601, -0.012878511, -0.0034509576, -0.022939632, 0.02066086, 0.01799539, -0.02177953, 0.011815084, 0.014280301, -0.007243731, -0.011787463, -0.03024551, -0.02291201, 0.04054832, -0.019017383, -0.0028381061, -0.008555751, -0.0089355465, -0.0018661757, 0.024624541, -0.014225058, -0.010551402, -0.0027690525, 0.006152683, 0.026295641, -0.00010978456, -0.007927363, 0.033283874, 0.016420964, 0.0036909191, -0.025149351, -0.0014104214, -0.020108432, 0.03286955, 0.056209695, -0.021185668, 0.023685412, 0.026779016, 0.0056244223, -0.019417895, -0.023878762, -0.013078767, -0.01201534, -0.018009199, -0.03568694, 0.0026033237, 0.016545262, 0.012319176, 0.0044297935, 0.005790151, -0.037233744, 0.005576085, -0.0025273648, -0.014128383, 0.0013223779, 0.021641424, 0.03204091, 0.004043093, 0.009432733, 0.03673656, 0.02738669, 0.012167258, -0.031405613, -0.00060551445, 0.012498716, 0.002054347, 0.010786185, -0.0019196923, 0.010641172, 0.014763677, -0.02494219, 0.012036056, -0.0036460343, 0.011697694, 0.009833244, 0.008086186, -0.005399998, 0.01463938, -0.010185418, -0.0010219945, 0.023574926, -0.01483273, -0.025066486, -0.0016771413, -0.00092359295, -0.03096367, -0.021309966, 0.0021009583, -0.00239271, -0.007837593, 0.0042985915, -0.010855239, -0.017291041, -0.014998459, -0.019680299, 0.0112557495, -0.0058833733, -0.012263933, -0.009046032, -0.011504343, -0.01258158, -0.03245523, 0.026198966, 0.001726342, -0.015896156, -0.048669033, 0.012036056, 0.020163674, 0.0412941, 0.010461632, -0.010648077, -0.005855752, -0.024541678, -0.012616107, -0.00882506, 0.00760281, -0.0379519, -0.0020767895, -0.014390787, -0.034499217, -0.01107621, -0.0033560088, 0.005617517, 0.002699999, 0.012367514, 0.008597183, -0.0047336295, 0.02552224, 0.016420964, -0.00079541205, -0.0008899293, 0.004650765, -0.037427094, 0.0067569027, -0.017470581, -0.007374933, -0.017940147, 0.006767261, -0.015233242, 0.008383117, 0.006760355, 0.005980049, 0.0042295377, 0.020357024, -0.025038864, 0.0056209695, -0.0044297935, 0.012823269, 0.014887974, 0.028021984, 0.012339893, 0.006601532, -0.019735541, -0.022760093, -0.009626083, 0.019638866, 0.033311494, -0.0013482731, 0.029334003, -0.030300755, -0.0075268513, -0.029693082, 0.0024186051, -0.02063324, 0.038034767, 0.014570327, -0.020177485, -0.01970792, -0.015509456, 0.005065087, -0.017498203, -0.024306895, 0.0025808814, 0.0016357091, -0.0030556254, -0.008410738, 0.0050443714, 0.008245009, -0.022760093, -0.022925822, 0.027842443, 0.003093605, -0.009543219, 0.007658053, -0.005023655, -0.028367251, -0.01613094, 0.006832862, -0.02550843, 0.002140664, 0.022387203, 0.016904341, 0.026640909, 0.053613275, -0.020992318, 0.018644493, 0.038808167, -0.00632877, 0.023699222, -0.0021130426, 0.0025549862, -0.022649607, -0.0063425805, 0.01463938, 0.004526469, -0.00815524, -0.003922249, 0.022994876, 0.006567005, 0.014708434, -0.016351912, -0.012837079, -0.01933503, -0.02760766, 0.027151907, -0.00666368, 0.011676977, -0.039305355, -0.007968795, 0.021075184, 0.007540662, 0.0087767225, 0.0010858692, 0.04018924, 0.003053899, -0.005130688, -0.001756553, -0.008465981, -0.009439638, 0.012312271, -0.029030167, 0.0062113786, 0.021130426, -0.0053896396, 0.0023340143, 0.0040948833, -0.013279023, 0.024886945, 0.0013465468, 0.0020526205, -0.030190269, 0.0155647, 0.0009374037, -0.01313401, -0.02833963, 0.009860866, 0.007354217, -0.016849099, 0.0079066465, -0.0050858036, 0.01370025, -0.020149864, -0.032013286, 0.009639894, 0.006653322, 0.044360083, 0.012263933, 0.03364295, 0.012381325, -0.001478612, -0.011676977, -0.0029296023, 0.0018420069, -0.004699103, 0.02364398, 0.019459328, -0.041045506, -0.009370584, 0.0010582476, 0.012519432, -0.016103318, -0.04018924, 0.029361624, 0.01894833, 0.014432219, -0.02085421, -0.014611758, -0.0334496, 0.0095501235, -0.025660347, 0.006259716, 0.013209969, -0.0041017886, 0.0070849075, 0.030825563, -0.008686953, 0.017981578, 0.011048589, -0.020481322, -0.018326847, 0.0033611879, -0.0036322235, -0.011020968, 0.001802301, 0.022359582, -0.027317636, 0.0059040897, -0.00019302662, -0.008569562, -0.011925571, 0.01426649, -0.0064427084, 0.03223426, -0.04203988, -0.0163381, -0.004578259, -0.01191176, -0.0015010544, -0.0011445647, -0.002684462, -0.022621986, -0.008528129, -0.0016477935, 0.007298974, 0.019486949, 0.0038186684, 0.012650634, 0.0076649585, 0.0042571593, -0.012843984, -0.00326106, -0.00038540585, -0.038752925, -0.016669558, 0.003942965, 0.0072713527, 0.031239884, -0.0074647027, -0.012063677, 0.011877233, 0.02327109, -0.045299213, -0.009750379, 0.0038842694, -0.0022235285, -0.014722245, 0.0022235285, -0.0012308819, -0.011435289, 0.023022497, -0.033118144, -0.03212377, 0.0007000317, -0.005372376, 0.005527747, 0.014307923, -0.015371349, 0.01520562, -0.009267004, 0.014335544, -0.007582094, -0.01821636, 0.014611758, 0.00253427, -0.015550889, 0.041763667, -0.023132984, 0.02064705, 0.0033024922, 0.01933503, -0.014100761, -0.042150367, -0.009508692, -0.018009199, 0.013548332, -0.010371863, -0.0060249334, -0.00054077664, -0.007754728, -0.0135069, 0.017567256, 0.013769303, -0.017746795, 0.005614064, -0.012408947, -0.00023586147, -0.006587721, -0.019638866, -0.008956262, -0.0088733975, 0.0059317113, -0.024472624, -0.00445051, -0.00030210984, 0.037869036, 0.021848584, -0.012823269, -0.019265976, -0.009322247, -0.052839875, -0.0082588205, -0.006052555, 0.005945522, 0.019252166, 0.0034267888, 0.0016857729, 0.028367251, -0.010213039, 0.023298712, -0.009046032, -0.0021216744, 0.00080490694, -0.0020819684, 0.0058971844, -0.009398206, -0.034858298, 0.0065152147, 0.016048076, 0.019859837, -0.0055968007, 0.039139625, -0.010862144, -0.011407668, -0.0005735771, 0.012595391, 0.039084382, 0.0018834391, 0.0077340123, -0.043586683, -0.015343728, 0.020163674, -0.00022183494, -0.0228982, -0.0041259574, 0.0025221857, 0.0010358052, 0.0065946262, -0.015440403, -0.012843984, 0.0091288965, -0.018962141, 0.004195011, 0.015288484, -0.017139124, 0.015398971, 0.03339436, 0.013859074, -0.011525059, 0.025287457, 0.0006219147, -0.0039636814, 0.034471598, -0.006553194, 0.0030901523, -0.014763677, 0.014722245, -0.006049102, 0.011221223, -0.009916108, -0.0023460987, -0.039636813, 0.027165718, 0.026350884, -0.019045005, -0.0011842706, -0.01838209, -0.010468538, 0.0059489743, -0.004378003, 0.008051659, -0.029306382, 0.024348328, -0.0037323514, -0.014791299, 0.013168537, -0.007236826, 0.024224032, -0.017953956, 0.009260098, 0.19578099, -0.028104847, 0.010364957, 0.018464955, -0.0074785133, -0.018299226, 0.024500245, 0.018699737, -0.01951457, 0.014970838, 0.01763631, -0.0009581198, -0.019846028, -0.00210959, 0.020370835, 0.0019766616, -0.039553948, -0.0183959, -0.019224545, 0.01502608, 0.004105241, -0.024182599, 0.0018143854, -0.021365209, 0.033339117, -0.010012783, -0.013334266, -0.021282343, 0.0015675186, 0.019583624, -0.012498716, 0.004533374, 0.0037461622, 0.007920457, -0.033173386, 0.0022822241, 0.0059627853, -0.0014225058, 0.02345063, -0.0050167497, 0.021240912, -0.005779793, -0.019417895, -0.014611758, -0.0026723775, 0.014860352, 0.0084521705, 0.012098204, -0.012160353, 0.002589513, -0.02535651, -0.0014950122, 0.02421022, 0.021116614, -0.005368924, -0.0068190508, 0.0033180292, 0.009039126, 0.025632726, 0.011027873, -0.036902286, 0.004305497, -0.0007427586, 0.017512012, -0.011200507, 0.018230172, -0.0036322235, 0.019155491, 0.003129858, 0.0013655365, -0.010213039, -0.023132984, -0.014915595, -0.0067879767, -0.030576969, -0.023036307, 0.04673553, 0.018161118, 0.03173707, 0.029140653, 0.010351147, -0.00058522995, -0.002867454, -0.013354981, -0.013279023, -0.051348317, 0.0015968663, 0.00059774594, -0.01033043, 0.0048095887, -0.016172372, -0.02741431, -0.0114145735, -0.01040639, 0.008831966, -0.0026775564, 0.008569562, 0.022953443, -0.0022045388, -0.011828896, -0.03173707, 0.058115575, 0.021448072, -0.00027880422, 0.009916108, 0.012381325, -0.021627612, -0.004861379, 0.033173386, 0.008134523, 0.014017897, -0.039940648, -0.0054483353, 0.021088993, 0.0060145757, 0.005065087, 0.0080033215, -0.024279274, 0.011214318, -0.0025860602, -0.002655114, -0.027151907, 0.0025170066, 0.023671601, 0.020205107, -0.0027379785, 3.1913723e-06, -0.015799481, -0.022401014, 0.0030159194, 0.014093856, -0.023188226, 0.017871093, 0.0051617627, -0.0033232083, -0.0018316489, -0.010627361, -0.021296155, -0.018616872, 0.01304424, 0.010447822, -0.017871093, 0.017180556, 0.001539897, -0.0017384264, -0.014031707, 0.01858925, 0.008369306, -0.020536564, -0.03623937, 0.0036736557, -0.030107405, -0.010268282, 0.0019852933, 0.019031195, -0.028919682, -0.0228982, -0.0187826, -0.014749866, -0.00563478, -0.02479027, 0.013203064, -0.007879025, -0.018893087, -0.015302296, -0.027331447, -0.17655645, 0.0051514045, 0.021116614, -0.035051648, 0.012049867, 0.01818874, 0.028560601, 0.0024703953, 0.0043434766, -0.006152683, 0.034637325, -0.008231198, -0.029969297, -0.019859837, -0.012705877, 0.0032248069, -0.026033238, 0.01575805, 0.02985881, 0.02554986, 0.024541678, -0.038587198, 0.015633753, 0.004239896, 0.017912524, -0.014957027, -0.0006931263, 0.017208178, 0.0036736557, -0.029334003, -0.006283885, 0.015523267, 0.011055494, -0.0013042514, 0.012346798, 0.010530686, 0.009405111, 0.009253193, 0.0011065853, 0.012277745, 0.037399475, 0.014252679, -0.00032347333, -0.017553445, -0.021599991, 0.01707007, 0.0067430916, -0.015992831, 0.023505872, -0.0024220578, -0.008017132, 0.016987205, 0.01875498, -0.0027880424, -0.013651912, 0.010661888, 0.006667133, 0.014501273, 0.0024168787, -0.010938103, -0.003513106, -0.017553445, 0.028035793, 0.024293084, -0.0089355465, -0.019680299, -0.0036322235, 0.008762912, -0.03491354, 0.005824678, -0.0167248, 0.012919944, -0.014252679, -0.0021631066, 0.004526469, 0.03568694, -0.023492062, 0.012636824, 0.004937338, -0.01763631, -0.003245523, 0.016586693, -0.02103375, -0.015979022, 0.0036080547, -0.012491811, 0.012823269, -0.005527747, -0.0030193722, -0.015979022, 0.013465468, -0.011614829, 0.0322895, -0.009923014, 0.0034941162, 0.009273909, 0.023367764, 0.0060456498, 0.011221223, -0.0029848453, -0.006349486, 0.014404598, -0.018962141, 0.005945522, 0.04651456, 0.0015813293, -0.027497176, 0.019638866, 0.029610218, -0.0070089484, -0.013196158, -0.006863936, 0.022953443, 0.004371098, -0.008645521, 0.034968782, -0.01153887, -0.0010263103, 0.02233196, -0.011925571, 0.023022497, -0.010005878, -0.0191693, 0.011870327, -0.030300755, -0.035880294, -0.144847, -0.008072375, 0.012263933, 0.017622499, -0.022801526, 0.011069305, -0.000893382, 0.037924282, -0.012892322, 0.034029655, -0.022635797, -0.016641937, 0.006656775, 0.0136381015, 0.025149351, -0.0022701398, 0.009142707, -0.006435803, 0.0058695627, 0.039940648, -0.005907542, -0.023630168, 0.043117117, -0.0017211629, 0.010862144, -0.0030193722, -0.021544749, 0.028477738, -0.008417644, 0.011663167, 0.027179528, -0.0150537025, 0.02403068, -0.010371863, -0.01040639, -0.013037335, -0.016379533, -0.025812266, 0.0034906636, -0.040216863, 0.0023012138, 0.010351147, 0.015633753, 0.003932607, -0.017898714, -0.004864832, -0.024251653, 0.029527353, -0.009577746, -0.030576969, -0.010233755, -0.022483878, -0.018050632, -0.019017383, 0.024624541, 0.02253912, 0.016545262, 0.0031540268, -0.005835036, -0.0074647027, -0.015550889, -0.02682045, -0.022746282, 0.02137902, 0.023478251, -0.009598462, -0.020315593, -0.015095134, -0.005810867, -0.016213804, -0.0018920709, 0.014487462, -0.0066360584, 0.025480809, -0.029416868, 0.00015213389, -0.017166745, -0.020191295, 0.011746031, -0.01361048, -0.011511249, -0.0017297947, -0.0061354195, -0.02119948, -0.0045817117, 0.0103856735, -0.00834859, -0.021517126, 0.0074577974, -0.024721218, 0.016862908, 0.042122744, 0.0001222466, -0.019183112, -0.00031484163, 0.0017850376, -0.016517641, 0.024279274, -0.003311124, -0.011849611, -0.04018924, -0.0046611233, -0.04430484, 0.02741431, -0.0024393213, -0.038891032, 0.004788873, -0.02476265, 0.0074923243, -0.0006888105, -0.013582859, 0.017525824, -0.014183626, 0.007899741, -0.023381576, -0.016365722, -0.009715852, -0.029886432, 0.020868022, -0.016904341, 0.016393343, 0.019763162, -0.009681326, 0.006152683, 0.006073271, 0.020370835, -0.026350884, 0.00038432688, -0.013209969, 0.045879263, 0.012381325, -0.025453186, 0.0040292824, -0.023588737, -0.0032317122, 0.016282858, -0.01304424, 0.004730177, 0.02008081, 0.0064392556, 0.021337587, 0.031654205, -0.034002032, -0.021945259, 0.0020060095, -0.005641686, 0.002271866, 0.0208404, -0.020591807, 0.004547185, -0.0047336295, 0.0032938605, 0.034941163, 0.019224545, 0.0030349093, -0.02814628, -0.012001529, 0.00022658239, -0.013493089, -0.0032351648, -0.0151503775, -0.027828634, 0.018906897, -0.009784906, 0.022621986, 0.010799996, 0.012257028, -0.008970073, -0.023671601, -0.0012412398, -0.0058212252, -0.012478, -0.018824033, -0.0077961604, -0.0137347765, 0.032952417, 0.018050632, 0.0063391277, -0.00384629, 0.029499732, 0.018893087, 0.03922249, 0.0049200747, -0.028270576, -0.0041294103, -0.005942069, 0.026530424, 0.019790785, 0.005303323, 0.010924292, -0.007941173, 0.0027345258, 0.02271866, 0.013852168, 0.017111503, 0.023464441, -0.021461884, 0.017028637, -0.008307158, -0.009232477, 0.022318149, 0.026709963, -0.01361048, 0.010627361, -0.013900505, -0.025397943, 7.509588e-05, 0.014390787, -0.01970792, -0.04469154, 0.020260349, 0.023768276, 0.003093605, 0.018271605, 0.00787212, 0.010544497, -0.016269047, 0.008700764, 0.005679665, -0.031046534, -0.022456257, 0.016296668, 0.0010988166, 0.0011428384, 0.025342701, 0.0044436045, 0.028505359, 0.016296668, 0.02476265, -0.023298712, 0.04087978, -0.000280099, 0.0104823485, -7.860251e-05, 0.006325317, -0.0007867804, 0.0039049855, -0.012139637, -0.005503578, 0.013127104, 0.017884903, 0.08330636, 0.013941938, -0.019210733, -0.012560864, -0.02535651, 0.01276112, 0.008300252, 0.017180556, -0.024610732, -0.017815849, -0.002751789, -0.0014492641, -0.00036512132, -0.039056763, -0.015992831, -0.021075184, -0.0006102619, 0.0131892525, -0.011594113, 0.019307408, 0.0315161, -0.02908541, 0.025757022, -0.00018622914, -0.02833963, -0.009211761, 0.024500245, -0.011096926, -0.013051146, -0.04126648, 0.004788873, 0.016752422, -0.034250624, -0.0079757, 0.0045402795, 0.0014449483, -0.03115702, -0.011297182, 0.019196924, 0.023588737, -0.0032075434, 0.010565213, -0.024058303, -0.02571559, -0.009059843, -0.007033117, -0.028643467, -0.005986954, -0.0212271], metadata={'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e21f0455-dd6d-44cf-8b58-a8eab2c403e6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}, hash='6f498b28779fb8c46147671c647449cd0b8a88922e1636f41b7a00bb911948fd'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5003574d-f499-478d-9e67-fb978d004a0f', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}, hash='b27dc2a49a07951fd9a9e42980b6159cf8827e4cdbc12c0648d5e140af8eb6af'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c94d639f-15ba-465e-8ed8-ce5dbb8e7814', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1bb822d262016830bc707991c8441eec6eee031cea5638135a32747f70b079f9')}, text='ROUGE-2 values drop 1.34 and 4.40 points when the sentence extraction method is replaced with Heuristic2 or Heuristic3. From this observation, we infer that the essential information is distributed throughout sections in a paper, but relatively more concentrated in the Introduction, followed by the Conclusion section.Thus, we can safely conclude that Heuristic1 is the best method to extract sentences. More specifically, we deem that most COVID-19 related scientific papers address the salient points in the Introduction sections, and the sentences at the beginning and the end of each section in a scientific paper are less informative for the composition of scientific abstracts.To further explore how the performance of our proposed models vary with different sequence encoders, we adopt original BERT, and its two domain-specific variations, i.e., SciBERT and BioBERT, as sequence encoder separately. In Table 5 , we present the detailed information of the three pre-trained models, including their corpora for pre-training, sizes of vocabulary, and hyper-parameters for their structures.We only change the type of sequence encoder and keep other settings in Table 2 in this experiment. The curves of training losses and perplexities are presented in Fig. 4 , and the results on the test set are provided in Table 5 .From Fig. 4 , we observe that cross-entropy loss of the three summarization models drop beneath 3.0 within 20,000 fine-tuning steps and continue to decline, the perplexity curves show the same trend. Perplexity is an evaluation metric for language models and reflects the uncertainty when a probabilistic model makes predictions. Among these curves, we find SciBERT-based model offers the worst training performance, and the BioBERT-based model surpasses the other two models in terms of convergence. Table 6 shows the results of three variations of our proposed summarization model on the test set, from which we can make the following observations: 1) SciBERT-based model performs well on the test set, although the converges of its training loss curve is the slowest among the three models, which indicates that the overfitting issue on the training set occurs when fine-tuning the pre-trained models; 2) when the BERTbased sequence encoder is replaced with domain-specific pre-trained language models, i.e., the SciBERT and BioBERT, our proposed abstractive summarization model achieves certain performance gains, which proves that in-domain pre-training corpora can help the downstream tasks. In our case, SciBERT and BioBERT improve the performance significantly as expected, since they are mainly pre-trained on the scientific papers from biomedical domain; 3) SciBERT-based model outperforms BioBERT-based model by 1.40 points on ROUGE-1, which emphasizes the necessity of a domain-specific vocabulary. Though both of two domain-specific pre-trained models are all obtained by training on the biomedical corpora and the corpus of BioBERT is much larger, the BioBERT-bases model is less competitive because it simply inherits the vocabulary from BERT.The feature fusion module learns to merge the features generated by sequence encoder and knowledge encoder. And the quality of fused representations from the feature fusion module is crucial to the summary generation process. In this set of experiments, we analyze the effectiveness of various feature fusion methods in our proposed summarization framework.As shown in Table 7 , we find that the abstractive summarization model with highway networks achieves the highest ROUGE scores, and other variations of highway networks also show satisfactory results. We propose that two learnable gates in the highway networks enable the feature fusion module to learn control the information flows, which not only eases the back propagation of gradients, but also merges the output features from sequence encoder and knowledge encoder. We are surprised to find that the abstractive summarization framework with residual networks performs poorest. We attribute it to the fact that the highway networks are more suitable for abstractive summarization task, although the residual connections usually outperform highway networks in computer vision field.A word in the sequence can connect more other words when increasing window size. To verify whether the word co-occurrence graph with more edges would lead to better abstractive summarization performance, we conduct experiments on word co-occurrence graphs with different window sizes. We construct the word cooccurrence graph using a strategy in which the same words in different positions of the sentence share their neighbors. Though this scheme allows diverse information to propagate to identical words and alleviate the polysemy problem to some extent, the number of edges surges as the window size increases because their neighbors are shared.To this end, we restrict the number of neighbors for each node in the word co-occurrence graph to five times of the corresponding window size at most.', start_char_idx=37173, end_char_idx=42196, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8232606)], metadata={'b87aa059-4713-43be-8559-093e8fd69090': {'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}, 'fc9a9139-df8c-43d3-a07b-3284bc7d71c2': {'file_path': 'Covid Dataset/10009.txt', 'file_name': '10009.txt', 'file_type': 'text/plain', 'file_size': 58063, 'creation_date': '2024-03-03', 'last_modified_date': '2024-01-14'}})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 85.98%, threshold set to 80.00%\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate\",\"time\":\"2024-03-16T23:31:26+05:30\"}\n"
     ]
    }
   ],
   "source": [
    "adv_answers = []\n",
    "adv_contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = senetencewindowretriever.query(f\"{question}\")\n",
    "  adv_answers.append(response.response)\n",
    "  adv_contexts.append([response.source_nodes[0].text])\n",
    "\n",
    "#wrap into huggingface dataset\n",
    "response_dataset_advanced_retrieval3 = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : adv_answers,\n",
    "    \"contexts\" : adv_contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the difference between extractive summarization methods and abstractive summarization methods?',\n",
       " 'answer': 'Abstractive summarization methods involve understanding the content in the original documents and aim to create a new paragraph using natural language generation to summarize the original document. On the other hand, extractive summarization methods do not involve understanding the content but rather select and compile existing sentences or phrases from the original document to create a summary. Abstractive summarization methods are typically more complex as they require generating new content, while extractive summarization methods are considered less complex as they rely on extracting and rearranging existing content.',\n",
       " 'contexts': [\"Kinugawa and Tsuruoka [19] presented a hierarchical encoder-decoder extractive summarizer for academic papers. Collins et al. [15] released a benchmark dataset for summarization of computer science publications named CSPubSum, developed a supervised extractive summarization approach, and proposed a new metric named AbstractROUGE. Yang et al. [20] leveraged data-weighted reconstruction to amplify a scientific paper's abstract. They conducted experiments on the real dataset (AAN 2 and Microsoft datasets 3 ) to confirm the effectiveness of their approach. With the release of the COVID-19 Open Research Dataset (CORD- 19) 4 , researchers began to study automatic text summarization of COVID-19 medical research papers [21] [22] [23] [24] . Park [23] proposed a Continual BERT for extractive summarization of COVID-19 literature. Su et al. [21] obtained a ranked list of relevant snippets from the COVID-19 literature given a query and then extracted the top-ranked relevant results to generate summaries.Different from extractive summarization methods, abstractive summarization methods involve understanding of the content in the original documents, and they aim to create a new paragraph by using natural language generation to summarize the original document. Normally, abstractive summarization methods are more difficult and complex than extractive summarization methods, but they can produce a more flexible and concise summary. Alambo et al. [25] proposed to generate an abstractive summary of a scientific paper by developing salient language unit selection and text generation techniques. Recently, neural methods have led to encouraging results in abstractive summarization [1, 6, 26] . However, these methods focus on summarizing news articles which are relatively short. Researchers began to study neural abstractive summarization approaches for scientific papers. Nikolve et al. [27] is among the first to consider supervised generation of the abstract directly from the full body of the paper. They applied a convolutional encoder-decoder model [28] on PubMed open access subset 5 to perform abstract generation task. Cohan et al. [29] proposed a discourse-aware attention model, which consists of new hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder, to generate abstractive summaries of scientific papers. Ju et al. [30] presented a modified unsupervised pipeline architecture, SciSummPip, that leverages a transformer-based language model for summarizing scientific papers. Tan et al. [22] adopted BERT [31] and GPT-2 [32] to generate abstractive summaries based on CORD-19 dataset. Esteva et al. [24] took BERT as the encoder and extended the original GPT-2 by adding a cross-attention function alongside every existing self-attention function as the decoder, to generate a single abstractive summary for CORD-19 document dataset.Many NLG tasks need to better understand global context under a particular generation process. For example, the summarization task requires structured representation to facilitate the connection of relevant entities, and the preservation of global context (e.g., entity interactions) [33] [34] . In order to help NLG, graph-to-sequence (Graph2Seq) models encode the full structural information contained in the graph via a neural encoder-decoder architecture [35] . Zhu et al. [36] extracted factual relations from the article to build a knowledge graph and applied graph attention networks (GAT) [10] to obtain the representation of each node. Then they proposed a Factual Corrector (FC) model to generate abstractive summaries with higher factual correctness. Huang et al. [33] proposed a knowledge graph-augmented abstractive summarization approach, which encodes each paragraph as a sub-KG using GAT and connects all sub-KGs with a Bi-LSTM. Jin et al. [37] proposed a novel model SemSUM, which leverages the information of original input texts and corresponding semantic dependency graphs to guide abstractive summarization process.Pre-trained language models (PTMs) [38] [39] [40] [41] have achieved significant improvements for a wide range of natural language processing (NLP) tasks. Peters et al. [38] developed Embeddings from Language Models (ELMo), an approach to learn contextualized word representations by training a bidirectional LSTM to optimize a disjoint bidirectional language model objective. Radford et al. [39] proposed to improve language understanding by Generative Pre-Training (GPT), which uses a combination of unsupervised pre-training and supervised fine-tuning. Devlin et al.\"],\n",
       " 'ground_truth': 'Abstractive summarization methods involve understanding the content in the original documents and aim to create a new paragraph by using natural language generation to summarize the original document. Extractive summarization methods, on the other hand, involve extracting and condensing important information from the original document without generating new text.'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dataset_advanced_retrieval3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 255/255 [01:40<00:00,  2.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9108, 'answer_relevancy': 0.9405, 'context_recall': 0.1622, 'context_precision': 0.0196, 'answer_correctness': 0.2709}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_retrieval_results3 = evaluate(response_dataset_advanced_retrieval3, metrics,raise_exceptions=False)\n",
    "advanced_retrieval_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Sentence Window Retiever</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.924540</td>\n",
       "      <td>0.910764</td>\n",
       "      <td>-0.013776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.913075</td>\n",
       "      <td>0.940459</td>\n",
       "      <td>0.027384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.162232</td>\n",
       "      <td>-0.818161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.908742</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-0.889134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.615350</td>\n",
       "      <td>0.270894</td>\n",
       "      <td>-0.344457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  Baseline  Sentence Window Retiever     Delta\n",
       "0        faithfulness  0.924540                  0.910764 -0.013776\n",
       "1    answer_relevancy  0.913075                  0.940459  0.027384\n",
       "2      context_recall  0.980392                  0.162232 -0.818161\n",
       "3   context_precision  0.908742                  0.019608 -0.889134\n",
       "4  answer_correctness  0.615350                  0.270894 -0.344457"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(naive_results.items()), columns=['Metric', 'Baseline'])\n",
    "df_comparison = pd.DataFrame(list(advanced_retrieval_results3.items()), columns=['Metric', 'Sentence Window Retiever'])\n",
    "\n",
    "df_merged3 = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged3['Delta'] = df_merged3['Sentence Window Retiever'] - df_merged3['Baseline']\n",
    "\n",
    "df_merged3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuned model vs RAG Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>gen_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of fine-tuning in BERT and...</td>\n",
       "      <td>[' before the pandemic.\" it would be tokenized...</td>\n",
       "      <td>The purpose of fine-tuning in BERT is to adapt...</td>\n",
       "      <td>\\nFine-tuning in BERT refers to the process of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the impact of IL-1β treatment on the M...</td>\n",
       "      <td>[' stimulation, the IL-1β expression in the pr...</td>\n",
       "      <td>IL-1β treatment results in a significant incre...</td>\n",
       "      <td>The IL-1β treatment in A549 cells leads to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the role of cytokine storm in the seve...</td>\n",
       "      <td>[' (CALR) 68 69 that endow mutated CALR protei...</td>\n",
       "      <td>The cytokine storm can contribute to the sever...</td>\n",
       "      <td>Cytokine storm plays a significant role in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What mental health challenges do Canadian Vete...</td>\n",
       "      <td>[\"Media coverage of Canadian Veterans, with a ...</td>\n",
       "      <td>Canadian Veterans face challenges such as post...</td>\n",
       "      <td>\\nCanadian Veterans face various mental health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can the DCA model predict new SARS-CoV-2 varia...</td>\n",
       "      <td>[\"2 variants are significantly better accordin...</td>\n",
       "      <td>Yes, the DCA model can predict new SARS-CoV-2 ...</td>\n",
       "      <td>\\nThe DCA model can predict new SARS-CoV-2 var...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of fine-tuning in BERT and...   \n",
       "1  What is the impact of IL-1β treatment on the M...   \n",
       "2  What is the role of cytokine storm in the seve...   \n",
       "3  What mental health challenges do Canadian Vete...   \n",
       "4  Can the DCA model predict new SARS-CoV-2 varia...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [' before the pandemic.\" it would be tokenized...   \n",
       "1  [' stimulation, the IL-1β expression in the pr...   \n",
       "2  [' (CALR) 68 69 that endow mutated CALR protei...   \n",
       "3  [\"Media coverage of Canadian Veterans, with a ...   \n",
       "4  [\"2 variants are significantly better accordin...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The purpose of fine-tuning in BERT is to adapt...   \n",
       "1  IL-1β treatment results in a significant incre...   \n",
       "2  The cytokine storm can contribute to the sever...   \n",
       "3  Canadian Veterans face challenges such as post...   \n",
       "4  Yes, the DCA model can predict new SARS-CoV-2 ...   \n",
       "\n",
       "                                         gen_answers  \n",
       "0  \\nFine-tuning in BERT refers to the process of...  \n",
       "1  The IL-1β treatment in A549 cells leads to the...  \n",
       "2  Cytokine storm plays a significant role in the...  \n",
       "3  \\nCanadian Veterans face various mental health...  \n",
       "4  \\nThe DCA model can predict new SARS-CoV-2 var...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finedtuned_df = pd.read_csv(\"finedtunedanswers.csv\")\n",
    "#df = df.dropna(subset=['ground_truth'])\n",
    "finedtuned_df= finedtuned_df[['question', 'contexts', 'ground_truth','gen_answers']]\n",
    "\n",
    "\n",
    "finedtuned_df.head()\n",
    "# test_questions = finedtuned_df[\"question\"].values.tolist()\n",
    "# test_groundtruths = finedtuned_df[\"ground_truth\"].values.tolist()\n",
    "\n",
    "# answers = df[\"gena\"]\n",
    "# contexts = []\n",
    "\n",
    "# for question in test_questions:\n",
    "#   response = qa.invoke({\"query\" : question})\n",
    "#   answers.append(response[\"result\"])\n",
    "#   contexts.append([context.page_content for context in response['source_documents']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_answers = finedtuned_df['gen_answers'].to_list()[:51]\n",
    "test_questions = finedtuned_df['question'].to_list()[:51]\n",
    "#contexts = finedtuned_df['contexts'].to_list()[:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finedtuned_contexts = finedtuned_df['contexts'].to_list()[:51]\n",
    "\n",
    "len(finedtuned_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of fine-tuning in BERT and how does it relate to pre-training?',\n",
       " 'answer': '\\nFine-tuning in BERT refers to the process of adapting the pre-trained BERT model to a specific task or domain by adding task-specific layers on top of the pre-trained weights. This process allows the model to learn task-specific representations while still leveraging the knowledge gained during pre-training.\\n\\nPre-training and fine-tuning are closely related in BERT. During pre-training, the model is',\n",
       " 'contexts': ['on the test set, although the converges of its training loss curve is the slowest among the three models, which indicates that the overfitting issue on the training set occurs when fine-tuning the pre-trained models; 2) when the BERTbased sequence encoder is replaced with domain-specific pre-trained language models, i.e., the SciBERT and BioBERT, our proposed abstractive summarization model achieves certain performance gains, which proves that in-domain pre-training corpora can help the downstream tasks. In our case, SciBERT and BioBERT improve the performance significantly as expected, since they are mainly pre-trained on the scientific papers from biomedical domain; 3) SciBERT-based model outperforms BioBERT-based model by 1.40 points on ROUGE-1, which emphasizes the necessity of a domain-specific vocabulary. Though both of two domain-specific pre-trained models are all obtained by training on the biomedical corpora and the corpus of BioBERT is much larger, the BioBERT-bases model is less competitive because it simply inherits the vocabulary from BERT.The feature fusion module learns to merge the features generated by sequence encoder and knowledge encoder. And the quality of fused representations from the feature fusion module is crucial to the summary generation process. In this set of experiments, we analyze the effectiveness of various feature fusion methods in our proposed summarization framework.As shown in Table 7 , we find that the abstractive summarization model',\n",
       "  'al. [37] proposed a novel model SemSUM, which leverages the information of original input texts and corresponding semantic dependency graphs to guide abstractive summarization process.Pre-trained language models (PTMs) [38] [39] [40] [41] have achieved significant improvements for a wide range of natural language processing (NLP) tasks. Peters et al. [38] developed Embeddings from Language Models (ELMo), an approach to learn contextualized word representations by training a bidirectional LSTM to optimize a disjoint bidirectional language model objective. Radford et al. [39] proposed to improve language understanding by Generative Pre-Training (GPT), which uses a combination of unsupervised pre-training and supervised fine-tuning. Devlin et al. [31] proposed a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. BERT uses a masked language modeling objective to train a deep bidirectional Transformer encoder, which learns interactions between left and right context. Zhang et al. [40] incorporated knowledge graph into BERT to simultaneously learn lexical, syntactic and knowledge information. PEGASUS [42] is a taskspecific PTM which is trained over massive pre-training corpora and via gap sentences generation task.According to Sinha et al. [43] , the language model pre-trained via Masked Language Model objective on corpora with permuted word orders, shows little differences from PTMs trained on non-permuted',\n",
       "  'to wordpiece-level by connecting the head wordpiece to each other wordpieces with edges.Identical words that appear more than once at different positions of a sentence are highlighted with bordered text boxes, such as va in subgraph (a) and (c), and v in subgraph (b). In our settings, identical words within a sentence share their neighbors to aggregate more contextual information. As shown in Fig. 2 , we connect these identical words with their neighbors using dotted lines with arrows.In this subsection, we first describe the encoding process of the source textual sequences and the inner mechanism of the BERT language model. Then we demonstrate using a graph attention to process and encode linguistic patterns, i.e., the word co-occurrence relationships. After that, we adopt highway networks to alleviate difficulties in back propagating gradients and to merge linguistic features with contextualized embeddings. Finally, we introduce Transformer decoder equipped with the copy mechanism and the learning objective for the abstractive summarization task. Fig. 3 illustrates the overall architecture of our proposed approach.Since BERT is a classic example of pre-trained language models, we chose to utilize the original BERT as the sequence encoder in our proposed approach at first. However, the vanilla BERT that was pre-trained on the general corpora may not achieve the state-of-the-art performance in a specific domain (e.g., legal documents, clinical reports, scientific',\n",
       "  'scientific abstracts.To further explore how the performance of our proposed models vary with different sequence encoders, we adopt original BERT, and its two domain-specific variations, i.e., SciBERT and BioBERT, as sequence encoder separately. In Table 5 , we present the detailed information of the three pre-trained models, including their corpora for pre-training, sizes of vocabulary, and hyper-parameters for their structures.We only change the type of sequence encoder and keep other settings in Table 2 in this experiment. The curves of training losses and perplexities are presented in Fig. 4 , and the results on the test set are provided in Table 5 .From Fig. 4 , we observe that cross-entropy loss of the three summarization models drop beneath 3.0 within 20,000 fine-tuning steps and continue to decline, the perplexity curves show the same trend. Perplexity is an evaluation metric for language models and reflects the uncertainty when a probabilistic model makes predictions. Among these curves, we find SciBERT-based model offers the worst training performance, and the BioBERT-based model surpasses the other two models in terms of convergence. Table 6 shows the results of three variations of our proposed summarization model on the test set, from which we can make the following observations: 1) SciBERT-based model performs well on the test set, although the converges of its training loss curve is the slowest among the three models, which indicates that the overfitting issue',\n",
       "  'on the general corpora may not achieve the state-of-the-art performance in a specific domain (e.g., legal documents, clinical reports, scientific literature). Domain-oriented variants of BERT are randomly initialized the parameters of BERT while remaining its architecture and then pretrained on the domain-specific corpora. In such a manner, domain knowledge would be integrated into the domain-specific BERT models, which significantly improves performance on the downstream tasks. Since we focus on abstractive summarization of scientific literature in biomedical field, we adopt BioBERT [45] and SciBERT [9] as sequence Fig. 2 . Illustration of the construction of word co-occurrence graphs based on a sentence. The sliding window size is 3, and the direction of the edge follows the relative order of wordpieces in corresponding sentence. encoders separately. In this way, we further investigate the effectiveness of domain-oriented pre-trained language models in our proposed abstractive summarization approach.All the variations of BERT tokenize the textual input to sub-words by matching strings in their corresponding pre-defined vocabularies using BPE algorithm [46] . BioBERT takes original wordpiece vocabulary of BERT, while SciBERT trains its exclusive vocabulary on its scientific corpora. For example, given a sentence \"Most VA care was provided in VA facilities before the pandemic.\" it would be tokenized to [\\'most\\', \\'v\\', \\'##a\\', \\'care\\', \\'was\\', \\'provided\\', \\'in\\', \\'v\\', \\'##a\\','],\n",
       " 'ground_truth': 'Linking a nanobody to anti-human serum albumin (HSA) has been proven to increase the serum half-life to~6 days in cynomolgus monkeys.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "finetuned_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : finetuned_answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "finetuned_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
       "    num_rows: 51\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 153/153 [03:50<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    #context_recall,\n",
    "    #context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    #context_recall,\n",
    "    #context_precision,\n",
    "    answer_correctness,\n",
    "]\n",
    "#\n",
    "finetuned_results = evaluate(finetuned_dataset, metrics,raise_exceptions=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base vs FineTuned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Finetunedonllama2</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.924540</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>-0.163564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.913075</td>\n",
       "      <td>0.926899</td>\n",
       "      <td>0.013824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.615350</td>\n",
       "      <td>0.314780</td>\n",
       "      <td>-0.300571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  Baseline  Finetunedonllama2     Delta\n",
       "0        faithfulness  0.924540           0.760976 -0.163564\n",
       "1    answer_relevancy  0.913075           0.926899  0.013824\n",
       "2  answer_correctness  0.615350           0.314780 -0.300571"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(naive_results.items()), columns=['Metric', 'Baseline'])\n",
    "df_comparison = pd.DataFrame(list(finetuned_results.items()), columns=['Metric', 'Finetunedonllama2'])\n",
    "\n",
    "df_merged1 = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged1['Delta'] = df_merged1['Finetunedonllama2'] - df_merged1['Baseline']\n",
    "\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ContextualCompressorVSFineTuned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>ContextualCompressor</th>\n",
       "      <th>Finetunedonllama2</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.962745</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>-0.201769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.917415</td>\n",
       "      <td>0.926899</td>\n",
       "      <td>0.009484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.313366</td>\n",
       "      <td>0.314780</td>\n",
       "      <td>0.001413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  ContextualCompressor  Finetunedonllama2     Delta\n",
       "0        faithfulness              0.962745           0.760976 -0.201769\n",
       "1    answer_relevancy              0.917415           0.926899  0.009484\n",
       "2  answer_correctness              0.313366           0.314780  0.001413"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(advanced_retrieval_results1.items()), columns=['Metric', 'ContextualCompressor'])\n",
    "df_comparison = pd.DataFrame(list(finetuned_results.items()), columns=['Metric', 'Finetunedonllama2'])\n",
    "\n",
    "df_merged1 = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged1['Delta'] = df_merged1['Finetunedonllama2'] - df_merged1['ContextualCompressor']\n",
    "\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiQueryVsFine Tuned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>mulitquery</th>\n",
       "      <th>Finetunedonllama2</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.978472</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>-0.217497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>0.926899</td>\n",
       "      <td>0.112044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.377078</td>\n",
       "      <td>0.314780</td>\n",
       "      <td>-0.062298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  mulitquery  Finetunedonllama2     Delta\n",
       "0        faithfulness    0.978472           0.760976 -0.217497\n",
       "1    answer_relevancy    0.814855           0.926899  0.112044\n",
       "2  answer_correctness    0.377078           0.314780 -0.062298"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(advanced_retrieval_results2.items()), columns=['Metric', 'mulitquery'])\n",
    "df_comparison = pd.DataFrame(list(finetuned_results.items()), columns=['Metric', 'Finetunedonllama2'])\n",
    "\n",
    "df_merged1 = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged1['Delta'] = df_merged1['Finetunedonllama2'] - df_merged1['mulitquery']\n",
    "\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceWindowRetrievervsFineTuned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>sentencewindowRetriever</th>\n",
       "      <th>Finetunedonllama2</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.910764</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>-0.149788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.940459</td>\n",
       "      <td>0.926899</td>\n",
       "      <td>-0.013560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.270894</td>\n",
       "      <td>0.314780</td>\n",
       "      <td>0.043886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  sentencewindowRetriever  Finetunedonllama2     Delta\n",
       "0        faithfulness                 0.910764           0.760976 -0.149788\n",
       "1    answer_relevancy                 0.940459           0.926899 -0.013560\n",
       "2  answer_correctness                 0.270894           0.314780  0.043886"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 86.19%, threshold set to 80.00%\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate\",\"time\":\"2024-03-16T23:41:27+05:30\"}\n",
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 86.20%, threshold set to 80.00%\",\"path\":\"/Users/rupeshyadav/.local/share/weaviate\",\"time\":\"2024-03-17T09:02:26+05:30\"}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.DataFrame(list(advanced_retrieval_results3.items()), columns=['Metric', 'sentencewindowRetriever'])\n",
    "df_comparison = pd.DataFrame(list(finetuned_results.items()), columns=['Metric', 'Finetunedonllama2'])\n",
    "\n",
    "df_merged1 = pd.merge(df_original, df_comparison, on='Metric')\n",
    "\n",
    "df_merged1['Delta'] = df_merged1['Finetunedonllama2'] - df_merged1['sentencewindowRetriever']\n",
    "\n",
    "df_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rudra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
